<properties
   pageTitle="Service Fabric クラスター リソース マネージャー - 管理の統合 | Microsoft Azure"
   description="クラスター リソース マネージャーと Service Fabric 管理の統合ポイントの概要"
   services="service-fabric"
   documentationCenter=".net"
   authors="masnider"
   manager="timlt"
   editor=""/>

<tags
   ms.service="Service-Fabric"
   ms.devlang="dotnet"
   ms.topic="article"
   ms.tgt_pltfrm="NA"
   ms.workload="NA"
   ms.date="03/10/2016"
   ms.author="masnider"/>


# Service Fabric クラスター管理とクラスター リソース マネージャーの統合
リソース マネージャーは、管理操作 (アプリケーションのアップグレードなど) を処理する Service Fabric の主要コンポーネントではありませんが、関係はあります。リソース マネージャーで管理を支援する手段として最初に挙げられるのが、クラスターとそのクラスター内のサービスの望ましい状態を、リソース割り当てと分散の観点からトラックし、不具合が発生している場合は、Service Fabric 正常性サブシステムを介して変更する、というものです。統合についても、アップグレードのしくみと関係している部分があります。具体的にはアップグレード中に、リソース マネージャーの動作の一部が変更され、特別な処理が実行されます。ここでは、この両方について説明します。

## 正常性の統合
リソース マネージャーは、サービスに対して定義されたルールを常にトラックし、そのルールを満たしていない場合は、正常性に関する警告とエラーを出力します。たとえば、ノードの容量が超過している場合、リソース マネージャーがその状況を解決できないと、正常性の警告によって容量超過のノードとメトリックが通知されます。

リソース マネージャーが正常性の警告を出力するのは、これだけでありません。この警告は、ユーザーが配置の制約 ("NodeColor == Blue" など) を定義している場合、その制約に違反していることが検出されたときにも出力されます。この制約の警告は、カスタム制約だけでなく、リソース マネージャーによって適用される既定の制約 (障害ドメインとアップグレード ドメイン分散など) に対しても出力されます。ここでは、この正常性レポートの例を 1 つ取り上げます。このケースでは、システム サービスのパーティションの 1 つについて、そのレプリカが一時的にまとめられている障害ドメインの数が少なすぎるため、正常性レポートが生成されました。これは、障害が重なったことが原因で発生する可能性があります。

```posh
PS C:\Users\User > Get-WindowsFabricPartitionHealth -PartitionId '00000000-0000-0000-0000-000000000001'


PartitionId           : 00000000-0000-0000-0000-000000000001
AggregatedHealthState : Warning
UnhealthyEvaluations  :
                        Unhealthy event: SourceId='System.PLB', Property='ReplicaConstraintViolation_FaultDomain', HealthState='Warning', ConsiderWarningAsError=false.

ReplicaHealthStates   :
                        ReplicaId             : 130766528804733380
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528804577821
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528854889931
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528804577822
                        AggregatedHealthState : Ok

                        ReplicaId             : 130837073190680024
                        AggregatedHealthState : Ok

HealthEvents          :
                        SourceId              : System.PLB
                        Property              : ReplicaConstraintViolation_FaultDomain
                        HealthState           : Warning
                        SequenceNumber        : 130837100116930204
                        SentAt                : 8/10/2015 7:53:31 PM
                        ReceivedAt            : 8/10/2015 7:53:33 PM
                        TTL                   : 00:01:05
                        Description           : The Load Balancer has detected a Constraint Violation for this Replica: fabric:/System/FailoverManagerService Secondary Partition 00000000-0000-0000-0000-000000000001 is
                        violating the Constraint: FaultDomain Details: Node -- 3d1a4a68b2592f55125328cd0f8ed477  Policy -- Packing
                        RemoveWhenExpired     : True
                        IsExpired             : False
                        Transitions           : Ok->Warning = 8/10/2015 7:13:02 PM, LastError = 1/1/0001 12:00:00 AM
```

この正常性メッセージによって、次のことがわかります。

1.	レプリカ自体はすべて正常である (これは Service Fabric の最優先事項です)。
2.	現在、障害ドメイン分散制約に違反している (特定の障害ドメインに含まれるレプリカの数が、このパーティションに対して許容されているレプリカ数を超えています)。
3.	違反が発生しているレプリカが含まれるノード (ID 3d1a4a68b2592f55125328cd0f8ed477 のノード)。
4.	発生日時 (2015 年 8 月 10 日午後 7 時 13 分 02 秒)。運用環境で発生するアラートの有用なデータです。問題が発生していることと、その問題について確認する必要があることを通知しています。このケースでは、たとえば、リソース マネージャーが障害ドメインにレプリカをまとめるしかないと判断した理由がわかるかどうかを、確かめたいと思うでしょう。他の障害ドメインのすべてのノードが停止して、予備のドメインが他になかったのかもしれません。十分なドメインが稼働していた場合は、他の障害ドメインのノードが、なんらかの原因で (たとえば、サービスの InvalidDomain ポリシーにより) 無効になっていた可能性もあります。

この状況で、ユーザーがサービスを作成する必要があるとします。リソース マネージャーはサービスを配置する場所を見つけようとしていますが、有効なソリューションがないようです。多くの理由が考えられますが、通常は、次の 2 つの状況のいずれかが原因です。

1.	一時的な状態によって、このサービス インスタンスまたはレプリカを正しく配置できない。
2.	サービスの要件の構成が誤っているため、その要件を満たすことができない。

それぞれの状況で、リソース マネージャーから正常性レポートが生成されます。このレポートに記載されいてる情報を使用して、何が発生しているか、また、なぜサービスを配置できないのかを判断できます。このプロセスを、"制約除外シーケンス" と呼んでいます。このプロセスでは、サービスに影響する構成済み制約を確認して、その制約によって除外されたものを確認します。このようにして、配置できないものがある場合は、どのノードがどのような理由で除外されたかを確認できます。この正常性レポートに記載されているさまざまな制約と、そのチェック対象について説明しましょう。(前述のとおり) 制約は既定でソフト レベルまたは最適化レベルで設定されているため、こうした制約によってノードが除外されるケースは、それほど多くありません。これが発生するのは、制約の設定が変更されているか、ハード制約の場合ですので、ここでは完全を期すために、これらの制約除外について説明します。

-	ReplicaExclusionStatic と ReplicaExclusionDynamic: これは内部制約です。検索中、2 つのレプリカをノードに配置する必要があると判断したことを示します (この配置は許可されていません)。ReplicaExclusionStatic と ReplicaExclusionDynamic はほぼ同じルールです。ReplicaExclusionDynamic 制約は、"このレプリカをここに配置できませんでした。提案のみのソリューションが、レプリカをここに既に配置したからです" という意味です。この点が、ReplicaExclusionStatic と異なります。ReplicaExclusionStatic は、提案された競合ではなく実際の競合を示します。ノードには既に実際にレプリカが存在します。紛らわしいですよね。 はい。これは重要なのでしょうか。 いいえ。しかし、あえて言うのであれば、制約除外シーケンスに ReplicaExclusionStatic 制約または ReplicaExclusionDynamic 制約が含まれている場合、リソース マネージャーは、すべてのレプリカを配置するノードが十分には存在しないと判断します。最初の段階でさらに他の制約を見れば、通常は、極端に少なくなった経緯がわかります。
-	PlacementConstraint: このメッセージが表示された場合、サービスの配置の制約に一致しなかったために、ノードが除外されたことを意味します。現在構成されている配置の制約をこのメッセージの一部としてトレースします。
-	NodeCapacity: この制約が表示された場合、指定されたノードにレプリカを配置すると、そのノードが容量超過になるため、レプリカを配置できなかったことを意味します。
-	Affinity: この制約は、影響を受けるノードにレプリカを配置すると、アフィニティ制約違反が発生するため、レプリカを配置できなかったことを示します。
-	FaultDomain と UpgradeDomain: 指定されたノードにレプリカを配置することで、特定の障害ドメインまたはアップグレード ドメインにまとめられる場合は、この制約によってそのノードが除外されます。
-	PreferredLocation: この制約は既定でのみ指定される最適化であるため、通常、これによりノードがソリューションから削除されることはありません。また、優先される場所の制約は、通常、アップグレード中 (アップグレードの開始時にあった場所にレプリカを戻すとき) にしか存在しません (存在できる場合でも)。

## アップグレード
リソース マネージャーは、アプリケーションとクラスターのアップグレード中、そのアップグレードを円滑に進めるだけでなく、クラスターのルールとパフォーマンスが損なわれるのを防ぐのにも役立ちます。

### ルール適用の維持
主に注意しなければならないのは、ルール、つまり配置の制約などに関連する厳密な制御は、アップグレード中も適用されるという点です。言うまでもないと思われるかもしれませんが、明確にする目的で、あえて取り上げます。良い面は、特定のワークロードが特定のノードで実行されないようにする場合、特に操作しなくても、これがアップグレード中も適用されます (つまり実行されません)。このため、環境が高度に制約されていると、アップグレードに時間がかかることがあります。更新プログラムを適用するためにサービスを停止する必要がある場合、そのサービスを配置できる場所のオプションがわずかしかないためです。

### スマート置換
リソース マネージャーは、アップグレードの開始時にクラスターの現在の配置のスナップショットを取り、アップグレードが完了したら、その状態に戻そうとします。その理由はシンプルです。まず、これにより、アップグレードの一環として行われる各サービスの移行 (影響を受けるノードから出して戻す移動) の数がわずかになります。また、アップグレード自体がクラスターのレイアウトに大きな影響を及ぼさなくなります。アップグレード前のクラスターが適切に配置されていれば、アップグレード後の配置も適切になります。

### 動きの軽減
アップグレード中、リソース マネージャーは、アップグレード中のエンティティに対する分散をオフにします。2 つの異なるアプリケーション インスタンスがあり、一方でアップグレードが開始された場合、そのアプリケーション インスタンスの分散は一時停止されますが、もう一方については停止されません。事後対応型分散を防ぐことで、リソース マネージャーが、アップグレードに反応 ("問題が発生。 ノードが空である。 何でもいいから詰め込もう" のように反応) するのを回避できます。つまり、アップグレードが完了してサービスがノードに戻る必要があるときに、クラスターのサービスを取り消すという余分な動きが発生するのを防ぐことができます。対象のアップグレードがクラスター アップグレードの場合は、アップグレード中 (制約チェック – ルールの適用 – アクティブ状態を維持)、クラスター全体の分散が一時停止されます。

### ルールの緩和
クラスター全体に制約がある場合やクラスターがいっぱいである場合でもアップグレードを完了させる必要があるという点も、アップグレード中に生じる一般的な問題です。実際のところ、この方法は既に説明しているのですが、アップグレード中はこれがますます重要です。アップグレードがクラスターで順番に行われている間、クラスターの 5 ～ 20% が一度に停止し、ワークロードが別の場所に移動する必要があるためです。ここで、前に説明したバッファー容量の概念が実際に役立ちます。バッファー容量は通常の操作では考慮されますが、アップグレード中は、リソース マネージャーによって合計容量がいっぱいになるまで使用されます。

## 次のステップ
- 最初から開始し、[Service Fabric クラスター リソース マネージャーの概要を確認する](service-fabric-cluster-resource-manager-introduction.md)

<!---HONumber=AcomDC_0316_2016-->