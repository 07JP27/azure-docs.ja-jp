---
title: "Service Fabric クラスター リソース マネージャー - 管理の統合 | Microsoft Docs"
description: "クラスター リソース マネージャーと Service Fabric 管理の統合ポイントの概要"
services: service-fabric
documentationcenter: .net
author: masnider
manager: timlt
editor: 
ms.assetid: 956cd0b8-b6e3-4436-a224-8766320e8cd7
ms.service: Service-Fabric
ms.devlang: dotnet
ms.topic: article
ms.tgt_pltfrm: NA
ms.workload: NA
ms.date: 08/19/2016
ms.author: masnider
translationtype: Human Translation
ms.sourcegitcommit: 219dcbfdca145bedb570eb9ef747ee00cc0342eb
ms.openlocfilehash: f13e38b4c01bc718f6f25f92461e332e1aa30136


---
# <a name="cluster-resource-manager-integration-with-service-fabric-cluster-management"></a>Service Fabric クラスター管理とクラスター リソース マネージャーの統合
Service Fabric クラスター リソース マネージャーは、管理操作 (アプリケーションのアップグレードなど) を処理する Service Fabric の主要コンポーネントではありませんが、関係はあります。 クラスター リソース マネージャーが管理を支援する最初の方法は、クラスターとクラスター内部のサービスの目的とする状態をリソース管理や負荷分散の観点から追跡し、クラスターを目的の構成にできない場合 (十分な容量がない場合や、サービスを配置する必要のある規則の競合など) に正常性レポートを送信することによって行います。 統合の別の部分は、アップグレードがどのように機能するかに関連します。アップグレードの実行中、クラスター リソース マネージャーの動作が変わります。 ここでは、この両方について説明します。

## <a name="health-integration"></a>正常性の統合
クラスター リソース マネージャーは常に、サービスに対して定義した規則を、ノード上やクラスター内で使用可能な容量と同様に追跡し、規則が順守されない場合や容量が十分でない場合に、正常性に関する警告およびエラーを出力します。 たとえば、ノードの容量が超過している場合、クラスター リソース マネージャーがその状況を解決できないと、正常性の警告によって容量超過のノードとメトリックが通知されます。

リソース マネージャーが正常性の警告を出力するのは、これだけでありません。この警告は、ユーザーが配置の制約 ("NodeColor == Blue" など) を定義している場合、その制約に違反していることが検出されたときにも出力されます。 この制約の警告は、カスタム制約だけでなく、自動的に適用される既定の制約 (障害ドメインとアップグレード ドメイン制約など) に対しても出力されます。

ここでは、この正常性レポートの例を 1 つ取り上げます。 このケースでは、システム サービスのパーティションの 1 つについて、そのレプリカが一時的にまとめられているアップグレード ドメインの数が少なすぎるため、正常性レポートが生成されました。これは、障害が重なる場合に発生する可能性があります。

```posh
PS C:\Users\User > Get-WindowsFabricPartitionHealth -PartitionId '00000000-0000-0000-0000-000000000001'


PartitionId           : 00000000-0000-0000-0000-000000000001
AggregatedHealthState : Warning
UnhealthyEvaluations  :
                        Unhealthy event: SourceId='System.PLB', Property='ReplicaConstraintViolation_UpgradeDomain', HealthState='Warning', ConsiderWarningAsError=false.

ReplicaHealthStates   :
                        ReplicaId             : 130766528804733380
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528804577821
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528854889931
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528804577822
                        AggregatedHealthState : Ok

                        ReplicaId             : 130837073190680024
                        AggregatedHealthState : Ok

HealthEvents          :
                        SourceId              : System.PLB
                        Property              : ReplicaConstraintViolation_UpgradeDomain
                        HealthState           : Warning
                        SequenceNumber        : 130837100116930204
                        SentAt                : 8/10/2015 7:53:31 PM
                        ReceivedAt            : 8/10/2015 7:53:33 PM
                        TTL                   : 00:01:05
                        Description           : The Load Balancer has detected a Constraint Violation for this Replica: fabric:/System/FailoverManagerService Secondary Partition 00000000-0000-0000-0000-000000000001 is
                        violating the Constraint: UpgradeDomain Details: Node -- 3d1a4a68b2592f55125328cd0f8ed477  Policy -- Packing
                        RemoveWhenExpired     : True
                        IsExpired             : False
                        Transitions           : Ok->Warning = 8/10/2015 7:13:02 PM, LastError = 1/1/0001 12:00:00 AM
```

この正常性メッセージによって、次のことがわかります。

1. レプリカ自体はすべて正常である (これは Service Fabric の最優先事項です)。
2. 現在、アップグレード ドメイン分散制約に違反していること (特定のアップグレード ドメインに含まれるレプリカの数が、このパーティションに対して許容されているレプリカ数を超えています)
3. 違反が発生しているレプリカが含まれるノード (ID 3d1a4a68b2592f55125328cd0f8ed477 のノード)。
4. 発生日時 (2015 年 8 月 10 日午後 7時 13分 02 秒)

これは運用環境で発生するアラートの有用なデータです。問題が発生していることと、その問題について確認する必要があることを通知しています。 このケースでは、たとえば、リソース マネージャーがアップグレード ドメインにレプリカをまとめるしかないと判断した理由がわかるかどうかを、確かめたいと思うでしょう。 他のアップグレード ドメインのすべてのノードが停止して、予備のドメインが他になかったのかもしれません。十分なドメインが稼働していた場合は、他のアップグレード ドメインのノードが、なんらかの原因 (サービスの配置ポリシーや容量不足など) によって無効になっていた可能性もあります。

この状況で、ユーザーがサービスを作成する必要があるとします。リソース マネージャーはサービスを配置する場所を見つけようとしていますが、有効なソリューションがないようです。 多くの理由が考えられますが、通常は、次の 2 つの状況のいずれかが原因です。

1. 一時的な状態によって、このサービス インスタンスまたはレプリカを正しく配置できない。
2. サービスの要件の構成が誤っているため、その要件を満たすことができない。

それぞれの状況で、クラスター リソース マネージャーから正常性レポートが生成されます。このレポートに記載されいてる情報を使用して、何が発生しているか、また、なぜサービスを配置できないのかを判断できます。 このプロセスを、"制約除外シーケンス" と呼んでいます。 このプロセスでは、サービスに影響する構成済み制約を確認して、その制約によって除外されたものを記録します。 このようにして、配置できないサービスがある場合は、どのノードがどのような理由で除外されたかを確認できます。

## <a name="constraint-types"></a>制約の種類
この正常性レポートに記載されているさまざまな制約と、そのチェック対象について説明しましょう。 (この記事ではさらに制約の優先順位について詳細に説明します) 制約は既定でソフト レベルまたは最適化レベルで設定されているため、こうした一部の制約によってノードが除外されるケースは、それほど多くありません。 ただし、これらの制約に関連する正常性メッセージが発生するのは、ハード制約として、またはノードを除去するために実行する頻度の低いケースで構成される場合ですので、ここでは完全を期すために、これらの制約除外について説明します。

* ReplicaExclusionStatic と ReplicaExclusionDynamic: これは内部制約です。検索中、同じパーティションから 2 つのステートフル レプリカまたはステートレス インスタンスを同じノードに配置する必要があるという状況に至ったことを示します (この配置は許可されていません)。 ReplicaExclusionStatic と ReplicaExclusionDynamic はほぼ同じルールです。 ReplicaExclusionDynamic 制約は、"このレプリカをここに配置できませんでした。提案のみのソリューションが、レプリカをここに既に配置したからです" という意味です。 この点が、ReplicaExclusionStatic と異なります。ReplicaExclusionStatic は、提案された競合ではなく実際の競合を示します。ノードには既に実際にレプリカが存在します。 紛らわしいですよね。 はい。 これは重要なのでしょうか。 いいえ。 しかし、あえて言うと、制約除外シーケンスに ReplicaExclusionStatic 制約または ReplicaExclusionDynamic 制約が含まれている場合、クラスター リソース マネージャーは、すべてのレプリカを配置するノードが十分には存在しないと判断します。 最初の段階でさらに他の制約を見れば、通常は、極端に少なくなった経緯がわかります。
* PlacementConstraint: このメッセージが表示された場合、サービスの配置の制約に一致しなかったために、ノードが除外されたことを意味します。 現在構成されている配置の制約をこのメッセージの一部としてトレースします。 配置の制約が指定された場合、これは通常通り標準ですが、配置の制約にバグがあるため、多数のノードを削除する場合は、ここでその結果を確認することができます。
* NodeCapacity: この制約が表示された場合、指定されたノードにレプリカを配置すると、そのノードが容量超過になるため、レプリカを配置できなかったことを意味します。
* Affinity: この制約は、影響を受けるノードにレプリカを配置すると、アフィニティ制約違反が発生するため、レプリカを配置できなかったことを示します。
* FaultDomain と UpgradeDomain: 指定されたノードにレプリカを配置することで、特定の障害ドメインまたはアップグレード ドメインにまとめられる場合は、この制約によってそのノードが除外されます。 この制約について説明するいくつかの例については、「 [fault and upgrade domain constraints and resulting behavior (障害ドメインとアップグレード ドメインの制約および行われる動作)](service-fabric-cluster-resource-manager-cluster-description.md)
* PreferredLocation: この制約は既定でのみ指定される最適化であるため、通常、これによりノードがソリューションから削除されることはありません。 また、優先される場所の制約は、通常、アップグレード中 (アップグレードの開始時にあった場所にレプリカを戻すとき) にしか存在しません (存在できる場合でも)。

### <a name="constraint-priorities"></a>制約の優先順位
これらすべての制約のうち、配置の制約がシステムにおいて最も重要であると考えることもあるでしょう。 配置の制約さえ守られている限り、他の制約 (アフィニティや容量など) に違反してもかまわないと思うかもしれません。

実際に、制約に優先順位を付けることができます。 制約はいくつかの適用レベルで構成できます。適用レベルは “ハード” （０）、“ソフト” (1)、“最適化” (2)、および “オフ” (-1) に要約されます。 制約の多くは既定で “ハード” に定義され (たとえば容量の場合、通常はほとんどの人が緩和しても構わないとは考えないため)、ほぼすべての制約が “ハード” または “ソフト” に定義されます。 ただし、より詳細な状況では、この定義を変更できます。 たとえば、ノード容量の問題を解決するためにアフィニティが違反されるようにするには、アフィニティの優先度を “ソフト” (1) に変更し、容量の制約は “ハード” (0) のままにします。 一部の制約で他の制約よりも違反の警告が頻繁に表示される場合にも、優先度が役立ちます。特定の制約については、一時的に緩和 (違反) しても構わないこともあるためです。 優先度レベルは、指定された制約が常に違反されるまたは違反されないことを意味するものではありません。これはどの制約が優先的に適用されるかを示し、すべての制約を充足することができない場合に適切なトレードオフを行うことができるようにするためのものです。

さまざまな制約の構成と既定の優先順位の値を次に示します。

ClusterManifest.xml

```xml
        <Section Name="PlacementAndLoadBalancing">
            <Parameter Name="PlacementConstraintPriority" Value="0" />
            <Parameter Name="CapacityConstraintPriority" Value="0" />
            <Parameter Name="AffinityConstraintPriority" Value="0" />
            <Parameter Name="FaultDomainConstraintPriority" Value="0" />
            <Parameter Name="UpgradeDomainConstraintPriority" Value="1" />
            <Parameter Name="PreferredLocationConstraintPriority" Value="2" />
        </Section>
```

ここでは、アップグレード ドメインと障害ドメインに対して制約が定義されています。また、アップグレード ドメインの制約はソフトです。 さらに、優先度が定義された “PreferredLocation” というものがあります。 これらについて以下で説明します。

まず、リソース マネージャー エンジン内の制約として、障害マネージャーおよびアップグレード マネージャー間でサービスが継続されるようにモデル化します。 これまでに、障害ドメインおよびアップグレード ドメインに関して配置を厳密に行う必要があることが何度かありました。さらに、これらの制約を完全 (ただし一時的) に無視する必要があることもありました。そのため、全般的にこの設計の選択および制約のインフラストラクチャの柔軟性は役立っています。 ただし、ほとんどの場合、アップグレード ドメインの制約はソフト制約として定義します。つまり、アップグレードの実行中など、リソース マネージャーが一時的にいくつかのレプリカを処理するためにアップグレード ドメインにまとめる必要がある場合、または一度に多くの障害や (ハード制約から) 制約の違反が生じた場合、これらを許容します。 こうした状況は、適切な配置を阻害する多数の障害やその他の変化がない限り発生せず、環境が正しく構成されていれば、安定した状態ではアップグレード ドメインが常に完全に優先されます。

PreferredLocation 制約は少し異なり、この制約だけが “最適化” に設定されているのはそのためです。 この制約はアップグレードの実行中に、サービスをアップグレード前にあった場所に戻そうとする場合に使用します。 これが実際には機能しない場合がある理由はさまざまですが、この最適化は有益であるため、設定されています。 これについては、クラスター リソース マネージャーによるアップグレードの支援についての説明において、さらに詳細に説明します。

## <a name="upgrades"></a>アップグレード
クラスター リソース マネージャーは、アプリケーションとクラスターのアップグレード中、そのアップグレードを円滑に進めるだけでなく、クラスターのルールとパフォーマンスが損なわれるのを防ぐのにも役立ちます。

### <a name="keep-enforcing-the-rules"></a>ルール適用の維持
主に注意しなければならないのは、ルール、つまり配置の制約などに関連する厳密な制御は、アップグレード中も適用されるという点です。 言うまでもないと思われるかもしれませんが、明確にする目的で、あえて取り上げます。 良い面は、特定のワークロードが特定のノードで実行されないようにする場合、この規則はアップグレード中も自動的に適用されることです。 このため、環境が高度に制約されていると、アップグレードに時間がかかることがあります。更新プログラムを適用するためにサービスを停止する必要がある場合、そのサービス (またはサービスが含まれるノード) を配置できる場所の選択肢がわずかしかないためです。

### <a name="smart-replacements"></a>スマート置換
リソース マネージャーは、アップグレードの開始時にクラスターの現在の配置のスナップショットを取り、アップグレードが完了したら、その状態に戻そうとします。 その理由はシンプルです。まず、これにより、アップグレードの一環として行われる各サービスのレプリカまたはインスタンスの移行 (影響を受けるノードから出して戻す移動) の数がわずかになります。 また、アップグレード自体がクラスターのレイアウトに大きな影響を及ぼさなくなります。アップグレード前のクラスターが適切に配置されていれば、アップグレード後の配置も適切になるか、少なくともアップグレード前より不適切にはなりません。

### <a name="reduced-churn"></a>動きの軽減
アップグレード中、クラスター リソース マネージャーは、アップグレード中のエンティティに対する分散をオフにします。 2 つの異なるアプリケーション インスタンスがあり、一方でアップグレードが開始された場合、そのアプリケーション インスタンスの分散は一時停止されますが、もう一方については停止されません。 事後対応型分散を阻止することにより、アップグレードそのものに対する不要な反応 (“問題が発生。 ノードが空である。 何でもいいから詰め込もう" のような反応) を回避できます。つまり、アップグレードが完了してサービスがノードに戻る必要があるときに、クラスターのサービスを取り消すという余分な動きが発生するのを防ぐことができます。 対象のアップグレードがクラスター アップグレードの場合は、アップグレード中 (制約チェック – ルールの適用 – アクティブ状態を維持、先を見越した再調整のみ無効)、クラスター全体の分散が一時停止されます。

### <a name="relaxed-rules"></a>ルールの緩和
クラスター全体に制約がある場合やクラスターがいっぱいである場合でもアップグレードを完了させる必要があるという点も、アップグレード中に生じる一般的な問題です。 アップグレード中はクラスターの容量を管理できることが通常よりもますます重要になります。アップグレードがクラスターで順番に行われている間、容量の 5 ～ 20% が一度に停止し、ワークロードが別の場所に移動する必要があるためです。 ここで、[バッファー容量](service-fabric-cluster-resource-manager-cluster-description.md#buffered-capacity)の概念が実際に役立ちます。バッファー容量は通常の操作では考慮され (いくらかのオーバーヘッドが残され) ますが、アップグレード中は、クラスター リソース マネージャーによって合計容量がいっぱいになるまで (バッファーがなくなるまで) 使用されます。

## <a name="next-steps"></a>次のステップ
* 最初から開始して、 [Service Fabric クラスター リソース マネージャーの概要を確認するにはこちらを参照してください](service-fabric-cluster-resource-manager-introduction.md)




<!--HONumber=Nov16_HO3-->


