<properties
   pageTitle="Azure Service Fabric クラスター リソース マネージャーでクラスターの均衡をとる | Microsoft Azure"
   description="Service Fabric クラスター リソース マネージャーを使用してクラスターの均衡をとる方法について説明します。"
   services="service-fabric"
   documentationCenter=".net"
   authors="masnider"
   manager="timlt"
   editor=""/>

<tags
   ms.service="Service-Fabric"
   ms.devlang="dotnet"
   ms.topic="article"
   ms.tgt_pltfrm="NA"
   ms.workload="NA"
   ms.date="08/19/2016"
   ms.author="masnider"/>

# Service Fabric クラスターの均衡をとる
Service Fabric クラスター Resource Manager は、動的な負荷をレポートしたり、クラスター内の変更に応答したり、制約違反を修正したり、必要に応じてクラスターの再調整を行ったりしますが、これらはどのくらいの頻度で実行され、何によってトリガーされるのでしょうか。 これには、いくつかのコントロールが関係します。

均衡化に関する最初のコントロールは、一連のタイマーです。これらのタイマーによって、クラスター Resource Manager がクラスターの状態について対応する必要のある事柄を確認する頻度が制御されます。3 つの異なる作業のカテゴリがあり、それぞれに対応する独自のタイマーがあります。次に例を示します。

1.	配置: この段階では、不足している任意のステートフル レプリカまたはステートレスなインスタンスの配置が処理されます。これは、新しいサービスと、失敗し再作成する必要のあるステートフルなレプリカやステートレスなインスタンスの処理の両方に対応します。レプリカまたはインスタンスの削除も、ここで処理もされます。
2.	制約チェック: この段階では、システム内のさまざまな配置の制約 (ルール) 違反の確認および修正が行われます。ルールとは、たとえば、ノードに過剰な負荷がかかっていないこと、およびサービスを配置する上での制約が満たされている (これについては後述します) ことを確認することです。
3.	分散: この段階では、さまざまなメトリックの構成済みの望ましい均衡レベルを基準に、先を見越しての再調整が必要であるかが確認され、必要な場合、クラスターをより均衡にする編成が検出されます。

## クラスター リソース マネージャーの手順とタイマーを構成する
クラスター Resource Manager が行うことのできる、これらの異なる修正はいずれも、その頻度を制御する別々のタイマーによって管理されています。たとえば、1 時間ごとにクラスターに新しいサービスのワークロードを配置し、数秒ごとに定期的に均衡の状態を確認することのみしたい場合、その動作を構成できます。それぞれのタイマーが作動したとき、タスクがスケジュールされます。既定では、Resource Manager は 1/10 秒ごとにその状態をスキャンして更新を適用し (ノードがダウンしていることを検知するなど、前回のスキャン以降に発生したすべての変更をバッチ処理します)、1 秒ごとに配置および制約チェック フラグを設定し、5 秒ごとに均衡化フラグを設定します。

ClusterManifest.xml:

``` xml
        <Section Name="PlacementAndLoadBalancing">
            <Parameter Name="PLBRefreshGap" Value="0.1" />
            <Parameter Name="MinPlacementInterval" Value="1.0" />
            <Parameter Name="MinConstraintCheckInterval" Value="1.0" />
            <Parameter Name="MinLoadBalancingInterval" Value="5.0" />
        </Section>
```

現在は、これらの操作を一度に 1 つずつのみ、順番に実行しています (これらの構成を ”最小間隔” と呼ぶのはこのためです)。たとえば、クラスターの均衡をとる前に、新しいレプリカを作成する保留中の要求に対応します。指定されている既定の時間間隔からわかるように、スキャンの実行および確認事項のチェックは非常に頻繁に行われます。これは、これらの処理の後に作成される変更セットが通常は小さいことを意味します。クラスターの何時間もの変更をスキャンして、それらを一度に修正するのでなく、同時にさまざまな現象が発生する一部のバッチを除き、発生するたびに処理しようとしています。これにより、Service Fabric リソース マネージャーは、クラスター内で発生することに非常に早く対応できます。

これらのタスクのほとんどは単純なものですが (制約の違反があれば修正し、作成すべきサービスがあれば作成する)、クラスター Resource Manager は、クラスターが不均衡であるかどうかを判断するために追加の情報も必要とします。そのために、他に、*分散しきい値*と*アクティビティしきい値*という 2 つの構成要素があります。

## 分散しきい値
分散しきい値は、事前対応型の再調整をトリガーする主要コントロールです (タイマーはクラスター Resource Manager がどのくらいの頻度で確認するかを決めるだけで、何かが実行されるということではありません)。分散しきい値は、特定のメトリックがどのようなときに、クラスター Resource Manager によってクラスターの均衡が崩れていると判断され、均衡化がトリガーされるのかを定義します。

分散しきい値は、クラスター定義の一部としてメトリックごとに定義されます。メトリックについて詳しくは、「[Service Fabric のリソース使用量と負荷をメトリックで管理する](service-fabric-cluster-resource-manager-metrics.md)」をご覧ください。

ClusterManifest.xml

``` xml
    <Section Name="MetricBalancingThresholds">
      <Parameter Name="MetricName1" Value="2"/>
      <Parameter Name="MetricName2" Value="3.5"/>
    </Section>
```

メトリックの分散しきい値は割合で規定されます。最も負荷がかかっているノードの負荷量を、最も負荷がかかっていないノードの負荷量で割ったものがこの割合を超過する場合、クラスターは不均衡であると見なされ、クラスター Resource Manager の次回の確認時に、均衡化がトリガーされます (既定では、上述の MinLoadBalancingInterval によって制御されているとおり 5 秒ごと)。

![分散しきい値の例][Image1]

この単純な例では、各サービスはいくつかのメトリックの 1 つの単位を消費しています。一番上の例では、ノードに対する最大の負荷は 5 で最小は 2 です。このメトリックの分散しきい値は 3 だとします。そのため、上の例では、クラスターは均衡がとれていると見なされ、クラスター Resource Manager による確認時に均衡化はトリガーされません (クラスター内の割合は 5/2 = 2.5 であり、指定された分散しきい値 3 より小さいため)。

下の例では、ノードに対する最大の負荷は 10 で最小は 2 であり、割合は 5 になります。クラスターはそのメトリックに対して指定されている分散しきい値 3 を超えています。その結果、グローバルな再調整の実行が、次回の均衡化タイマーの作動時にスケジュールされます。均衡化の検索が開始されても、何かが移動するわけではありません。クラスターが不均衡である場合がありますが、状況は改善されません。ただし、このような状況では (少なくとも既定では) 負荷の一部はほぼ確実に Node3 に分散されます。最大限まで許可するアプローチはとっていないので、負荷の一部は Node2 にも分散される可能性があります。ノード間の全体的な相違が最小化されますが、負荷の大部分は Node3 に流れることが推測されます。

![分散しきい値のアクション例][Image2]

分散しきい値を下回ることは明確な目標ではありません。しきい値はクラスター Resource Manager にクラスターを確認して、改善ができることがある場合はそれを判断するように通知する*トリガー*にすぎません。

## アクティビティしきい値
ノードが相対的に不均衡であるにもかかわらず、クラスターの負荷*全体*が低い場合があります。これは単に、その日のその時間帯のため、またはクラスターが新しくて現在起動中であるためである場合があります。このいずれかの場合は、移動のためにネットワークおよびコンピューティング リソースを消費するだけになってしまい、得るものが少ないので、クラスターの均衡をとるためにあまり時間をかけたくないでしょう。これを避けるため、Resource Manager には、アクティビティしきい値と呼ばれるもう 1 つのコントロールがあります。これは、アクティビティのいくつかの絶対的な下限を指定します。アクティビティしきい値以上の負荷がどのノードにもない場合、分散しきい値が満たされても、均衡化はトリガーされません。

以下のノードで、以下が合計で消費されているとレポートされているとします。また、このメトリックに対して分散しきい値 3 を維持しているが、同時にアクティビティしきい値が 1536 であるとしましょう。最初の例において、分散しきい値ではクラスターは不均衡ですが、アクティビティしきい値を満たすノードはないので、そのまま変更はありません。下の例では、Node1 がアクティビティしきい値を大幅に上回っているので、均衡化が実行されます (メトリックに対する分散しきい値とアクティビティしきい値の両方が超過しているため)。

![アクティビティしきい値の例][Image3]

分散しきい値同様、アクティビティしきい値もクラスター定義でメトリックごとに定義します。

ClusterManifest.xml

``` xml
    <Section Name="MetricActivityThresholds">
      <Parameter Name="Memory" Value="1536"/>
    </Section>
```

分散しきい値とアクティビティしきい値はメトリックに関連付けられています。分散処理は、分散とアクティビティしきい値の両方が同じメトリックを超えた場合にのみトリガーされることに注意してください。分散しきい値がメモリーしきい値を超え、アクティビティしきい値が CPU しきい値を超えても、残りのしきい値 (CPU しきい値に対する分散しきい値およびメモリーしきい値に対するアクティビティしきい値) が超過しない限り、分散処理はトリガーされません。

## 同時にサービスの均衡をとる
クラスターが不均衡かどうかということは、クラスター全体で判断しますが、それを修正するには、個々のサービス レプリカとインスタンスを移動させる必要があるというを念頭に置く必要があります。ご理解いただけましたでしょうか。 メモリが 1 つのノードに集中している場合、複数のレプリカやインスタンスが原因である可能性があるため、影響している不均衡なメトリックを使用するすべてのステートフルなレプリカまたはステートレスなインスタンスを移動する必要がある場合があります。

しかし、電話やチケットでのお問い合わせで、均衡が崩れていないサービスが移動されたと訴えられるお客様が時折いらっしゃいます。そのサービスのすべてのメトリックの均衡がたとえ完全に取れていても、他のサービスに不均衡がある場合、なぜサービスが移動してしまうのでしょうか。 確認してみましょう。

4 つのサービス、Service1、Service2、Service3、Service4 を例にとります。Service1 は Metric1 と Metric2、Service2 は Metric2 と Metric3、Service3 は Metric3 と Metric4、Service4 は Metric99 に対してレポートを行います。これで、お分かりいただけたでしょうか。チェーンがあります。 クラスター Resource Manager の観点からすると、実際には 4 つの独立したサービスがあるわけではなく、関連する複数のサービス (Service1、Service2、および Service3) と、独立したサービスが 1 つあります。

![同時にサービスの均衡をとる][Image4]

したがって、Metric1 の不均衡は Service3 に属するレプリカやインスタンスが移動する原因になる可能性があります。Metric1 の不均衡の度合いによっては、またそれを修正するためにクラスターでどのような変更を行う必要があったのかによっては、通常は非常に少ないこのような移動が、多くなる場合があります。また、メトリック 1、2、または 3 の不均衡によって Service4 で移動が発生することは確実にありません。Service4 に属するレプリカまたはインスタンスを移動しても、メトリック 1、2、または 3 の均衡には絶対に影響しません。

クラスター Resource Manager は、サービスの追加または削除や、メトリック構成の変更の可能性があるため、関連するサービスを自動的に検出します (たとえば、均衡化を 2 回実行する間に Service2 が再構成されて Metric2 が削除される可能性があります)。これによって、Service1 と Service2 間のチェーンが崩れます。2 グループのサービスでなく、3 グループになります。

![同時にサービスの均衡をとる][Image5]

## 次のステップ
- メトリックは、Service Fabric クラスター リソース マネージャーが管理するクラスターの利用量と容量を表します。メトリックの詳細とその構成方法については、[この記事](service-fabric-cluster-resource-manager-metrics.md)を参照してください。
- 移動コストは、特定のサービスが他のサービスよりも高額になっていることをクラスター リソース マネージャーに警告する信号の 1 つです。移動コストの詳細については、[この記事](service-fabric-cluster-resource-manager-movement-cost.md)を参照してください。
- クラスター リソース マネージャーにはスロットルがいくつかあります。クラスターのチャーン (激しい動き) を落ち着かせるようにスロットルを構成できます。通常は必要ありませんが、必要であれば、[ここ](service-fabric-cluster-resource-manager-advanced-throttling.md)で詳細を確認できます。


[Image1]: ./media/service-fabric-cluster-resource-manager-balancing/cluster-resrouce-manager-balancing-thresholds.png
[Image2]: ./media/service-fabric-cluster-resource-manager-balancing/cluster-resource-manager-balancing-threshold-triggered-results.png
[Image3]: ./media/service-fabric-cluster-resource-manager-balancing/cluster-resource-manager-activity-thresholds.png
[Image4]: ./media/service-fabric-cluster-resource-manager-balancing/cluster-resource-manager-balancing-services-together1.png
[Image5]: ./media/service-fabric-cluster-resource-manager-balancing/cluster-resource-manager-balancing-services-together2.png

<!---HONumber=AcomDC_0824_2016-->