<properties
   pageTitle="Azure Service Fabric クラスター リソース マネージャーでクラスターの均衡をとる | Microsoft Azure"
   description="Service Fabric クラスター リソース マネージャーを使用してクラスターの均衡をとる方法について説明します。"
   services="service-fabric"
   documentationCenter=".net"
   authors="masnider"
   manager="timlt"
   editor=""/>

<tags
   ms.service="Service-Fabric"
   ms.devlang="dotnet"
   ms.topic="article"
   ms.tgt_pltfrm="NA"
   ms.workload="NA"
   ms.date="05/20/2016"
   ms.author="masnider"/>

# Service Fabric クラスターの均衡をとる
Service Fabric クラスター リソース マネージャーは、動的な負荷をレポートしたり、クラスター内の変更に応答したり、バランス計画を生成しますが、これらはいつ実行されるのでしょうか。 サービス作成時の既定の負荷値でクラスターにサービスが配置されるとき、何が実際再調整をトリガーするのでしょうか。 これには、いくつかのコントロールが関係します。

クラスター リソース マネージャーが、クラスターの状態で解決する必要のある事柄を確認する頻度を制御する、一連のタイマーの均衡を制御する最初のコントロールのセットがあります。常に実行している異なる段階の作業にこれらのタイマーは関連します。次のとおりです。

1.	配置: この段階では、不足している任意のステートフル レプリカまたはステートレスなインスタンスの配置が処理されます。これは、新しいサービスと、失敗し再作成する必要のあるレプリカやインスタンスの処理の両方に対応します。レプリカまたはインスタンスの削除も、ここで処理もされます。
2.	制約チェック: この段階では、システム内のさまざまな配置の制約 (ルール) 違反の確認および修正が行われます。ルールとは、たとえば、ノードに過剰な負荷がかかっていないこと、およびサービスを配置する上での制約が満たされている (これについては後述します) ことを確認することです。
3.	分散: この段階では、さまざまなメトリックの構成済みの望ましい均衡レベルを基準に、先を見越しての再調整が必要であるかが確認され、必要な場合、クラスターをより均衡にする編成が検出されます。

## クラスター リソース マネージャーの手順とタイマーを構成する
これらの異なる段階は、その頻度を制御する別のタイマーによって制御されます。たとえば、1 時間ごとにクラスターに新しいサービスのワークロードを配置し、数秒ごとに定期的に均衡の状態を確認することのみしたい場合、それを強制できます。各タイマーが起動されると、リソース マネージャーのその責務に対応する必要があることが示されたフラグが設定され、ステート マシンを介して次の全体のスイープの際に取り上げられます (このために、これらの構成は ”最小間隔” で定義されます)。既定では、リソース マネージャーは、1/10 秒ごとにその状態をスキャンして更新を適用し、1 秒ごとに配置および制約チェック フラグを設定し、5 秒ごとに分散フラグを設定します。

ClusterManifest.xml:

``` xml
        <Section Name="PlacementAndLoadBalancing">
            <Parameter Name="PLBRefreshGap" Value="0.1" />
            <Parameter Name="MinPlacementInterval" Value="1.0" />
            <Parameter Name="MinConstraintCheckInterval" Value="1.0" />
            <Parameter Name="MinLoadBalancingInterval" Value="5.0" />
        </Section>
```

今日は、これらのアクションを 1 度に 1 つずつ連続して実行します。つまり、たとえば、クラスターの均衡をとる前に、新しいレプリカを作成する要求に対応します。指定されている既定の時間間隔からわかるように、スキャンの実行および確認事項の確認は非常に頻繁に行われます。これは、これらの処理後に作成される変更セットが通常は小さいことを意味します。 クラスターの何時間もの変更をスキャンして、それらを一度に修正するのでなく、同時にさまざまな現象が発生する一部のバッチを除き、発生するたびに処理しようとしています。これにより、Service Fabric リソース マネージャーは、クラスター内で発生することに非常に早く対応できます。

基本として、クラスター リソース マネージャーは、いつクラスターが不均衡であるか、また問題を解決するためにどのレプリカを移動する必要があるかも知っている必要があります。そのために、他に、*分散しきい値*と*アクティビティしきい値*という 2 つの主要な構成要素があります。

## 分散しきい値
分散しきい値は、先を見越した再調整をトリガーする主要コントロールです。分散しきい値は、特定のメトリックがどのようなときに、リソース マネージャーによってクラスターの均衡が崩れていると判断され、再調整がトリガーされるのかを定義します。分散しきい値は、クラスター定義の一部としてメトリックごとに定義されます。

ClusterManifest.xml

``` xml
    <Section Name="MetricBalancingThresholds">
      <Parameter Name="MetricName1" Value="2"/>
      <Parameter Name="MetricName2" Value="3.5"/>
    </Section>
```

メトリックの分散しきい値は割合で規定されます。最も負荷がかかっているノードの負荷量を、最も負荷がかかっていないノードの負荷量で割ったものがこの割合を超過する場合、クラスターは不均衡であると見なされ、リソース マネージャーのステート ノードの次回の実行時に、分散がトリガーされます。

![分散しきい値の例][Image1]

この単純な例では、各サービスはいくつかのメトリックの 1 つの単位のみを消費しています。一番上の例では、ノードに対する最大の負荷は 5 で最小は 2 です。このメトリックの分散しきい値は 3 だとします。そのため、一番上の例では、クラスターは分散されていると見なされ、分散はトリガーされません (クラスター内の割合は 5/2 = 2.5 であり、指定された分散しきい値 3 より小さいため)。

下の例では、ノードに対する最大の負荷は 10 で最小は 2 (結果の割合は 5)であるため、設計されている分散しきい値の 3 を超過しています。その結果、グローバル再調整は、タイマーが次回起動し、負荷がほぼ確実に Node3 に分散される場合に行われます。最長マッチのみを処理するわけではないので、ノード間全体の違いを最小化できるよう一部は Node2 に分散される可能性もありますが、負荷の大半は Node3 に分散されることを想定しています。

![分散しきい値のアクション例][Image2]

分散しきい値を下回ることは明確な目標ではありません。しきい値は Service Fabric クラスター リソース マネージャーにクラスターを確認して、可能な改善を決定するように通知する*トリガー*にすぎません。

## アクティビティしきい値
ノードが相対的に不均衡であるにもかかわらず、クラスターの負荷全体が低い場合があります。これは単に、その日のその時間帯のため、またはクラスターが新しくて現在起動中であるためである場合があります。これらのいずれの場合は、移動のために、ネットワークおよびコンピューティング リソースを消費するだけになってしまい、得るものが少ないので、分散にはあまり時間をかけたくないでしょう。リソース マネージャーには、アクティビティしきい値と呼ばれるもう 1 つのコントロールがあります。これでは、アクティビティのいくつかの絶対的な下限を指定します。アクティビティしきい値以上の負荷がどのノードにもない場合、分散しきい値が満たされても、分散はトリガーされません。以下のノードで、以下が合計で消費されているとレポートされているとします。また、分散しきい値 3 は満たされていますが、同時にアクティビティしきい値は 1536 であるとします。1 番目の例では、分散しきい値ではクラスターは不均衡ですが、アクティビティしきい値を満たすノードはないので、そのままにされます。下の例では、Node1 はアクティビティしきい値を大幅に超過しているので、分散処理が実行されます。

![アクティビティしきい値の例][Image3]

分散しきい値同様、アクティビティしきい値もクラスター定義でメトリックごとに定義します。

ClusterManifest.xml

``` xml
    <Section Name="MetricActivityThresholds">
      <Parameter Name="Memory" Value="1536"/>
    </Section>
```

分散しきい値とアクティビティしきい値はメトリックに関連付けられています。分散処理は、分散とアクティビティしきい値の両方が同じメトリックを超えた場合にのみトリガーされることに注意してください。分散しきい値がメモリーしきい値を超え、アクティビティしきい値が CPU しきい値を超えても、残りのしきい値 (CPU しきい値に対する分散しきい値およびメモリーしきい値に対するアクティビティしきい値) が超過しない限り、分散処理はトリガーされません。

## 同時にサービスの均衡をとる
クラスターが不均衡かどうかということは、クラスター全体で判断しますが、それを修正するには、個々のサービス レプリカとインスタンスを移動させる必要があるというを念頭に置く必要があります。ご理解いただけましたでしょうか。 メモリーが 1 つのノードに集中している場合、複数のレプリカやインスタンスが原因である可能性があるため、影響している均衡を崩しているメトリックを使用するすべてのレプリカまたはインスタンスを移動する必要がある場合があります。

しかし、電話やチケットでのお問い合わせで、均衡が崩れていないサービスが移動されたと訴えられるお客様が時折いらっしゃいます。そのサービスのすべてのメトリックの均衡が完全に取れているときに、他が不均衡の場合、どうしてそのようになるのでしょうか。 確認してみましょう。

例として、S1、S2、S3、および S4 の 4 つのサービスがあります。S1 では、M1 と M2 を、S2 では M2 および M3 を、S3 では M3 と M4 を、S4 ではメトリック M99 がレポートされます。これで、お分かりいただけたでしょうか。チェーンがあります。 リソース マネージャーの視点から見ると、実際には 4 つの独立したサービスはありません。関連する多数の (S1、S2、および S3) サービスと、単独のサービスがあるのです。

![同時にサービスの均衡をとる][Image4]

したがって、Metric1 の不均衡が原因で Service3 のレプリカやインスタンスが移動している可能性があります。Metric1 の不均衡の度合いによっては、またそれを修正するためにクラスターでどのような変更を行う必要があったのかによっては、通常は非常に少ないこのような移動が、多くなる場合があります。また、メトリック 1、2、または 3 の不均衡によって Service4 で移動が発生することは確実にありません。Service4 に属するレプリカまたはインスタンスを移動しても、メトリック 1、2、または 3 の均衡には絶対に影響しません。

リソース マネージャーは、サービスの追加または削除や、メトリック構成の変更の可能性のため、実行のたびに関連するサービスを自動的に検出します (たとえば、Service2 を 2 回分散した間に、Metric2 が再構成されなくなる場合があります)。これによって、Service1 と Service2 間のチェーンが崩れます。2 グループのサービスでなく、3 グループになります。

![同時にサービスの均衡をとる][Image5]

## 次のステップ
- メトリックは、Service Fabric クラスター リソース マネージャーが管理するクラスターの利用量と容量を表します。メトリックの詳細とその構成方法については、[この記事](service-fabric-cluster-resource-manager-metrics.md)を参照してください。
- 移動コストは、特定のサービスが他のサービスよりも高額になっていることをクラスター リソース マネージャーに警告する信号の 1 つです。移動コストの詳細については、[この記事](service-fabric-cluster-resource-manager-movement-cost.md)を参照してください。
- クラスター リソース マネージャーにはスロットルがいくつかあります。クラスターのチャーン (激しい動き) を落ち着かせるようにスロットルを構成できます。通常は必要ありませんが、必要であれば、[ここ](service-fabric-cluster-resource-manager-advanced-throttling.md)で詳細を確認できます。


[Image1]: ./media/service-fabric-cluster-resource-manager-balancing/cluster-resrouce-manager-balancing-thresholds.png
[Image2]: ./media/service-fabric-cluster-resource-manager-balancing/cluster-resource-manager-balancing-threshold-triggered-results.png
[Image3]: ./media/service-fabric-cluster-resource-manager-balancing/cluster-resource-manager-activity-thresholds.png
[Image4]: ./media/service-fabric-cluster-resource-manager-balancing/cluster-resource-manager-balancing-services-together1.png
[Image5]: ./media/service-fabric-cluster-resource-manager-balancing/cluster-resource-manager-balancing-services-together2.png

<!---HONumber=AcomDC_0810_2016-->