<properties
   pageTitle="Azure Load Balancer の概要 | Microsoft Azure"
   description="Azure Load Balancer の機能の概要、アーキテクチャ、実装。ロード バランサーの動作とクラウドでの活用について説明します。"
   services="load-balancer"
   documentationCenter="na"
   authors="sdwheeler"
   manager="carmonm"
   editor="tysonn" />
<tags
   ms.service="load-balancer"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="infrastructure-services"
   ms.date="05/19/2016"
   ms.author="sewhee" />


# Azure Load Balancer の概要

Azure Load Balancer は、アプリケーションに高可用性と優れたネットワーク パフォーマンスを提供します。これは、負荷分散セットで定義されているクラウド サービスや仮想マシンの正常なサービス インスタンス間で着信トラフィックを分散する、第 4 層 (TCP、UDP) のロード バランサーです。

次のように構成できます。

- 仮想マシンへの着信インターネット トラフィックを負荷分散します。これは、[インターネットに接続する負荷分散](load-balancer-internet-overview.md)と呼ばれます。
- 仮想ネットワーク内の仮想マシン間、クラウド サービス内の仮想マシン間、クロスプレミスの仮想ネットワーク内のオンプレミスのコンピューターと仮想マシン間で、トラフィックを負荷分散します。これは、[内部負荷分散](load-balancer-internal-overview.md)と呼ばれます。
- 外部トラフィックを特定の仮想マシンに転送します。

インターネットから到達できるようにするには、クラウド内のすべてのリソースにパブリック IP アドレスが必要です。Microsoft Azure のクラウド インフラストラクチャは、そのリソースに対してルーティング不可能な IP アドレスを使用します。インターネットとの通信には、ネットワーク アドレス変換 (NAT) とパブリック IP アドレスを使用します。

ロード バランサーがそれぞれが異なる方法で構成されているため、Azure クラシックと Resource Manager の[デプロイ モデル](../resource-manager-deployment-model.md)は異なることを理解する必要があります。

### Azure クラシック デプロイ モデル

このモデルでは、パブリック IP アドレスと FQDN がクラウド サービスに割り当てられます。クラウド サービス境界内にデプロイされた仮想マシンは、ロード バランサーを使用するためにグループ化できます。ロード バランサーはポート変換を実行し、クラウド サービスのパブリック IP アドレスを利用して、ネットワーク トラフィックの負荷を分散します。

ポート変換は、パブリック IP アドレスに割り当てられたパブリック ポートと、特定の仮想マシンにトラフィックを送信するために割り当てられたローカル ポート間の 1 対 1 の関係を持つエンドポイントを通じて実行されます。負荷分散は、ロード バランサー エンドポイントを使用して実行されます。これらのエンドポイントは、パブリック IP アドレスと、負荷分散されたネットワーク トラフィックに応答するクラウド サービス内のすべての仮想マシンに割り当てられたローカル ポート間の 1 対多の関係を持ちます。

このデプロイ モデルでロード バランサーが使用するパブリック IP アドレスのドメイン ラベルは、<クラウド サービス名>.cloudapp.net です。次の図は、このモデルの Azure Load Balancer を示しています。

![クラシック デプロイ モデルの Azure Load Balancer](./media/load-balancer-overview/asm-lb.png)

### Azure Resource Manager デプロイ モデル

このモデルでは、クラウド サービスを作成して仮想マシンに負荷を分散する必要はありませんが、ロード バランサーを明示的に作成する必要があります。

パブリック IP アドレスは独自のリソースであり、ドメイン ラベルまたは DNS 名に関連付けることができます。この場合、パブリック IP アドレスはロード バランサー リソースに関連付けられます。このようにして、ロード バランサーの規則と着信 NAT 規則は、負荷分散されたネットワーク トラフィックを受信するリソースのインターネット エンドポイントとしてパブリック IP アドレスを使用します。

プライベートまたはパブリック IP アドレスは、仮想マシンに接続されたネットワーク インターフェイス リソースに割り当てられます。ネットワーク インターフェイスがロード バランサーのバックエンド IP アドレス プールに追加されると、ロード バランサーは作成された負荷分散規則に基づいて、負荷分散されたネットワーク トラフィックを送信し始めます。

次の図は、このモデルの Azure Load Balancer を示しています。

![リソース マネージャーの Azure Load Balancer](./media/load-balancer-overview/arm-lb.png)

## ロード バランサーの機能

### ハッシュベースの分散

ロード バランサーは、ハッシュベースの分散アルゴリズムを使用します。既定では、5 つの組 (ソース IP、ソース ポート、接続先 IP、接続先ポート、およびプロトコルの種類) のハッシュを使用して、使用可能なサーバーにトラフィックをマップします。これは、トランスポート セッション*内*でのみ持続性を提供します。TCP または UDP の同じセッション内のパケットは、負荷分散されたエンドポイントの背後にある同じデータセンター IP インスタンスに送信されます。クライアントが接続を閉じてから開き直すか、同じソース IP から新しいセッションを開始すると、ソース ポートが変更されます。これにより、トラフィックは別のデータセンター IP エンドポイントに送信される可能性があります。

詳細については、[ロード バランサーの分散モード](load-balancer-distribution-mode.md)に関するページをご覧ください。次の図は、ハッシュベースの分散を示しています。

![ハッシュベースの分散](./media/load-balancer-overview/load-balancer-distribution.png)

### ポート フォワーディング

ロード バランサーでは、受信通信の管理方法を制御できます。この通信には、他のクラウド サービスや仮想ネットワークのインターネット ホストや仮想マシンから開始されたトラフィックを含めることができます。この制御は、エンドポイントで表されます (入力エンドポイントとも呼ばれます)。

エンドポイントはパブリック ポートでリッスンし、内部ポートにトラフィックを転送します。内部エンドポイントと外部エンドポイントには同じポートをマップしたり、別のポートを使用することもできます。たとえば、パブリック エンドポイントをポート 80 にマップしているときに、Web サーバーがポート 81 をリッスンするように構成できます。パブリック エンドポイントを作成すると、ロード バランサー インスタンスの作成がトリガーされます。

Azure ポータルを使用して作成した仮想マシンのエンドポイントは、既定で、リモート デスクトップ プロトコル (RDP) とリモート Windows PowerShell セッションのトラフィック用に使用および構成されます。これらのエンドポイントを使用して、インターネット経由で仮想マシンをリモートで管理することができます。


### 自動再構成

ロード バランサーは、インスタンスがスケール アップまたはスケール ダウンされると、すぐに自身を再構成します。たとえば、クラウド サービス内の Web/worker ロールのインスタンス数を増やしたり、同じ負荷分散セットに仮想マシンを追加したりすると、この再構成が行われる場合があります。


### サービスの監視

ロード バランサーでは、さまざまなインスタンスの正常性をプローブできます。プローブで応答できない場合、ロード バランサーは異常なインスタンスへの新しい接続の送信を停止します。既存の接続は影響を受けません。

次の 3 種類のプローブがサポートされています。

- **ゲスト エージェント プローブ (PaaS VM の場合のみ)****:** ロード バランサーは、仮想マシン内のゲスト エージェントを使用します。リッスンを行い、インスタンスが準備完了状態の場合 (つまり、インスタンスがビジー、リサイクル中、停止中などの状態でない場合) にだけ、HTTP 200 OK 応答を返します。ゲスト エージェントが HTTP 200 OK で応答できない場合、ロード バランサーは、そのインスタンスを応答不能と見なし、インスタンスへのトラフィックの送信を停止します。ロード バランサーは、インスタンスへの ping を続けます。ゲスト エージェントが、HTTP 200 で応答する場合は、ロード バランサーはそのインスタンスへのトラフィックの送信を再開します。Web ロールを使用する場合、Web サイト コードは通常、Azure ファブリックやゲスト エージェントでは監視されない w3wp.exe で実行されます。つまり、w3wp.exe が失敗 (HTTP 500 応答など) してもゲスト エージェントにレポートされず、ロード バランサーはそのインスタンスがローテーションから除外されたことを認識しません。
- **HTTP カスタム プローブ:** このプローブは、既定の (ゲスト エージェント) プローブを上書きします。ユーザーはこれを使用して独自のカスタム ロジックを作成し、ロール インスタンスの正常性を判断できます。ロード バランサーは、エンドポイントを定期的に調査します (既定では 15 秒ごと)。タイムアウト期間内 (既定値は 31 秒) にインスタンスが TCP ACK または HTTP 200 で応答した場合は、ローテーション内にあると見なされます。これは、ロード バランサーのローテーションからインスタンスを削除する、ユーザー独自のロジックを実装する場合に役立ちます。たとえば、インスタンスが CPU の 90% を超えた場合に 200 以外の状態を返すように、インスタンスを構成できます。w3wp.exe を使用する Web ロールの場合も、Web サイト コードが失敗するとプローブに 200 以外の状態が返されるため、Web サイトの自動監視が行われます。
- **TCP カスタム プローブ:** このプローブは、定義済みプローブ ポートへの正常な TCP セッションの確立に依存します。

詳細については、「[LoadBalancerProbe schema (LoadBalancerProbe スキーマ)](https://msdn.microsoft.com/library/azure/jj151530.aspx)」を参照してください。

### Source NAT


サービスからインターネットへのすべての送信トラフィックは、受信トラフィックと同じ VIP アドレスを使用してソース NAT (SNAT) 変換されます。SNAT には重要な利点があります。

- VIP を別のサービス インスタンスに動的にマップできるため、サービスのアップグレードや障害復旧が簡単にできます。
- ACL (アクセス制御リスト) は VIP を使用して表現できるため、ACL の管理が簡単になります。サービスのスケールアップやスケールダウン、再デプロイによって変更されません。

ロード バランサーの構成では、UDP の Full cone NAT がサポートされます。Full cone NAT は、ポートが (送信要求に応答して) 任意の外部ホストからの着信接続を許可する NAT の一種です。


>[AZURE.NOTE] VM によって開始された新しい送信接続ごとに、送信ポートもロード バランサーによって割り当てられます。外部ホストは、仮想 IP (VIP) の割り当てポートでトラフィックを認識します。大量の送信接続が必要なシナリオの場合は、VM が SNAT 用の専用送信 IP アドレスを持てるように、[インスタンスレベル パブリック IP アドレス](../virtual-network/virtual-networks-instance-level-public-ip.md)を使用することをお勧めします。これにより、ポートの枯渇のリスクが減少します。
>
>VIP またはインスタンスレベル パブリック IP (PIP) で使用できるポートの最大数は、64,000 です。これは TCP の標準的な限度です。


####仮想マシンの複数の負荷分散された IP アドレスのサポート

仮想マシンのセットに割り当てられている、負荷分散された複数のパブリック IP アドレスを取得することができます。この機能を使用して、複数の SSL Web サイトや複数の SQL Server AlwaysOn 可用性グループ リスナーを同じ仮想マシン セット上にホストすることができます。詳細については、「[クラウド サービスごとの複数の VIP](load-balancer-multivip.md)」を参照してください。

####Azure リソース マネージャーによるテンプレートベースのデプロイ####

リソース マネージャー ベースの API とツールを使用して、ロード バランサーを管理することができます。リソース マネージャーの詳細については、[Resource Manager の概要](../resource-group-overview.md)に関するページをご覧ください。

[AZURE.INCLUDE [load-balancer-compare-tm-ag-lb-include.md](../../includes/load-balancer-compare-tm-ag-lb-include.md)]

## 次のステップ

[インターネットに接続するロード バランサーの概要](load-balancer-internet-overview.md)

[内部ロード バランサーの概要](load-balancer-internal-overview.md)

[インターネットに接続するロード バランサーの作成の開始](load-balancer-get-started-internet-arm-ps.md)

<!---HONumber=AcomDC_0824_2016-->