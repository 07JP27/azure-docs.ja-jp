<properties 
	pageTitle="Stream Analytics の主要概念の説明 |Microsoft Azure" 
	description="Azure Stream Analytics の主要な概念に関する詳細情報: サポートされる入出力、ジョブ構成の詳細、メトリックなど、Stream Analytics ジョブのコンポーネント。" 
	keywords="event processing,data stream,key concepts,serialization"	
	services="stream-analytics" 
	documentationCenter="" 
	authors="jeffstokes72" 
	manager="paulettm" 
	editor="cgronlun" />

<tags 
	ms.service="stream-analytics" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.tgt_pltfrm="na" 
	ms.workload="data-services" 
	ms.date="06/16/2015" 
	ms.author="jeffstok" />


# Stream Analytics の主要な概念: Stream Analytics ジョブの基本に関するガイド 

Azure Stream Analytics は、待機時間の短縮、高可用性、クラウド内のデータ ストリームに対する拡張性の高い複雑なイベント処理を実現する、十分に管理されたサービスです。Stream Analytics により、ユーザーはデータ ストリームを分析するためにストリーミングのジョブをセットアップでき、ほぼリアルタイムで分析を実行できます。この記事では、Stream Analytics ジョブの主要概念について説明します。

## Stream Analytics の機能
Stream Analytics では、次のことが可能です。

- 大量の高速データ ストリームに対する複雑なイベント処理の実行   
- 接続された車や電力系統など、世界各地に分散した資産や設備のイベント データの収集 
- ほぼリアルタイムの監視と診断を行うための製品利用統計情報の処理 
- 後で処理するリアルタイムのイベントのキャプチャおよびアーカイブ

詳細については、「[Azure Stream Analytics の概要](stream-analytics-introduction.md)」を参照してください。

Stream Analytics ジョブには、次のすべてが含まれています。* 1 つまたは複数の入力ソース * 着信データ ストリームに対するクエリ * 出力ターゲット。


## 入力

### データ ストリーム

Stream Analytics の各ジョブの定義には、ジョブで使用および変換される少なくとも 1 つのデータ ストリームの入力ソースを含める必要があります。[Azure BLOB ストレージ](http://azure.microsoft.com/documentation/services/storage/) と [Azure Event Hubs](http://azure.microsoft.com/services/event-hubs/) は、データ ストリームの入力ソースとしてサポートされています。Event Hubs の入力ソースは、複数のさまざまなデバイスやサービスからイベント ストリームを収集するために使用されます。一方、BLOB ストレージは大量のデータのインジェストのために入力ソースとして使用できます。BLOB はデータをストリーミングしないため、BLOB 内のレコードにタイムスタンプが含まれていなければ、BLOB に対する Stream Analytics ジョブは実際には時間で分析されません。

### 参照データ
Stream Analytics は、参照データという 2 次タイプの入力ソースもサポートします。これは相関関係と参照を実行するために使用される補足データであり、通常は静的データまたは変更頻度の低いデータです。[Azure BLOB ストレージ](http://azure.microsoft.com/documentation/services/storage/)は、参照データをサポートする唯一の入力ソースです。参照データ ソースの BLOB のサイズは、最大で 50 MB に制限されています。

参照データの更新のサポートを有効にするには、ユーザーは、パスのパターン内で {date} および {time} トークンを使用して、入力構成で BLOB のリストを指定する必要があります。ジョブは、UTC タイム ゾーンを使用して BLOB 名にエンコードされた日時に基づいて、対応する BLOB を読み込みます。

たとえば、ジョブに /sample/{date}/{time}/products.csv というパスのパターンの、ポータルで構成された参照入力があるとします。ここで日付形式は "YYYY-MM-DD" であり、時刻形式は "HH:mm" です。この場合、ジョブは UTC タイム ゾーンで 2015 年 4 月 16 日 5:30 PM (太平洋標準時タイム ゾーンでは 2015 年 4 月 16 日 10:30 PM) に、/sample/2015-04-16/17:30/products.csv というファイルを取得します。


### シリアル化
クエリの正しい動作を確保するには、Stream Analytics で、受信データ ストリームに使用されているシリアル化形式に注意する必要があります。現在サポートされているシリアル化形式は、データ ストリームでは JSON、CSV、Avro、参照データでは CSV と JSON です。

### 生成されたプロパティ
ジョブで使用される入力型に応じて、イベント メタデータといくつかの追加フィールドが生成されます。これらのフィールドには他の入力列と同じようにクエリを実行できます。既存のイベントに次のいずれかのプロパティと同じ名前を持つフィールドがある場合、入力メタデータで上書きされます。

<table border="1">
	<tr>
		<th></th>
		<th>プロパティ</th>
		<th>説明</th>
	</tr>
	<tr>
		<td rowspan="4" valign="top"><strong>BLOB</strong></td>
		<td>BlobName</td>
		<td>イベントに起因する入力 BLOB の名前。</td>
	</tr>
	<tr>
		<td>EventProcessedUtcTime</td>
		<td>BLOB レコードが処理された日時。</td>
	</tr>
	<tr>
		<td>BlobLastModifiedUtcTime</td>
		<td>BLOB が最後に変更された日時。</td>
	</tr>
	<tr>
		<td>PartitionId</td>
		<td>入力アダプターの 0 から始まるパーティション ID。</td>
	</tr>
	<tr>
		<td rowspan="3" valign="top"><b>Event Hubs</b></td>
		<td>EventProcessedUtcTime</td>
		<td>イベントが処理された日時。</td>
	</tr>
	<tr>
		<td>EventEnqueuedUtcTime</td>
		<td>Event Hubs でイベントを受信した日時。</td>
	</tr>
	<tr>
		<td>PartitionId</td>
		<td>入力アダプターの 0 から始まるパーティション ID。</td>
	</tr>
</table>

###低速な入力データがある、または入力データなしのパーティション
複数のパーティションがある入力ソース、および 1 つ以上の遅延またはデータなしパーティションがある入力ソースからの読み取り時には、システム内でイベントの流れが中断しないように、ストリーミング ジョブでこの状況を扱う方法を決定する必要があります。[許容される最大着信遅延] 入力設定がこの動作を制御し、既定ではデータを無限に待機するように設定されます。これはつまり、イベントのタイムスタンプは変更されず、イベントの流れは最も遅い入力パーティションに応じたものとなり、1 つ以上の入力パーティションにデータがない場合は流れを停止するということを意味します。これは、複数の入力パーティション間でデータが均等に分散されており、複数のイベント間で時間の一貫性が重要な場合に便利です。

限られた時間だけ待機するよう指定することもできます。その場合、[許容される最大着信遅延] によって、ジョブを先に進めるまでに待機する遅延時間が決まります。その時間が経過すると、遅延入力パーティションを待たずに、[遅延イベントに対するアクション] 設定に従ってイベントを処理し、イベントを削除するか、後でデータが到着した場合はイベントのタイムスタンプを調整します。これは、待機時間が重要であり、タイムスタンプのシフトが許容され、入力が均等に分散されていない可能性がある場合に便利です。

###順不同のイベントがあるパーティション
ストリーミング ジョブ クエリで TIMESTAMP BY キーワードを使用する場合、イベントが入力に着信する順序は保証されません。そのため同じ入力パーティション内の一部のイベントは遅延する可能性があります。[入力内の最大許容不規則順序] パラメーターにより、ストリーミング ジョブは順序の許容範囲外にあるイベントを [遅延イベントに対するアクション] に従って処理し、イベントを削除するかまたはイベントのタイムスタンプを調整します。

### その他のリソース
入力ソースの作成方法の詳細については、「[Azure Event Hubs 開発者ガイド](http://msdn.microsoft.com/library/azure/dn789972.aspx)」および「[Azure BLOB ストレージの使用](../storage/storage-dotnet-how-to-use-blobs.md)」を参照してください。



## クエリ
受信データのフィルター処理、操作、処理のロジックは、Stream Analytics ジョブのクエリで定義されます。クエリは、Stream Analytics クエリ言語で作成されます。この言語は、SQL に似た言語で、大部分が標準的な Transact-SQL 構文のサブセットであり、一時クエリに関して特定の拡張機能を備えています。

### ウィンドウ化
ウィンドウ化の拡張機能により、複数の期間内に発生したイベントのサブセットに対して集計と計算を実行できます。ウィンドウ化関数は、**GROUP BY** ステートメントを通して呼び出されます。たとえば、次のクエリは 1 秒あたりの受信イベント数をカウントします。

	SELECT Count(*) 
	FROM Input1 
	GROUP BY TumblingWindow(second, 1) 

### 実行ステップ
さらに複雑なクエリの場合は、標準的な SQL 句 **WITH** を使用して、一時的な名前付き結果セットを指定できます。たとえば、このクエリは次の 2 つの実行ステップで構成される変換を実行するために **WITH** を使用します。
 
	WITH step1 AS ( 
		SELECT Avg(Reading) as avr 
		FROM temperatureInput1 
		GROUP BY Building, TumblingWindow(hour, 1) 
	) 

	SELECT Avg(avr) AS campus_Avg 
	FROM step1 
	GROUP BY TumblingWindow (day, 1) 

クエリ言語の詳細については、「[Azure Stream Analytics Query Language Reference (Azure Stream Analytics クエリ言語リファレンス)](http://go.microsoft.com/fwlink/?LinkID=513299)」を参照してください。

## 出力
出力ターゲットには、Stream Analytics のジョブの結果が書き込まれます。結果は、ジョブが入力イベントを処理すると、出力ターゲットに継続的に書き込まれます。次の出力ターゲットがサポートされています。

- Azure Event Hubs - デバイスへのコマンドの発行など、複数のストリーミング パイプラインを一緒に構成する必要がある場合は、Event Hubs をシナリオの出力ターゲットとして選択します。
- Azure BLOB ストレージ - 長期的な出力のアーカイブや、後で処理するためのデータの格納には、BLOB ストレージを使用します。
- Azure テーブル ストレージ - Azure テーブル ストレージは、スキーマに対する制約が少ない構造化データ ストアです。スキーマと型が異なるエンティティも、同じ Azure テーブルに格納できます。Azure テーブル ストレージを使用すると、永続化と効率的な取得のためにデータを保持できます。詳細については、「[Microsft Azure Storage の概要](../storage/storage-introduction.md)」と「[Azure テーブル ストレージのスケーラブルなパーティション分割方法の設計](https://msdn.microsoft.com/library/azure/hh508997.aspx)」を参照してください。
- Azure SQL データベース - この出力ターゲットは、実質的にリレーショナルであるデータや、データベースでホストされているコンテンツに依存するアプリケーションに適しています。


## ジョブの規模の設定

Stream Analytics ジョブは、ジョブが受信するデータの処理能力の大きさを定義するストリーミング ユニットを構成することで拡張できます。各ストリーミング ユニットは、約 1 MB/秒のスループットに対応します。各サブスクリプションには、そのリージョン内のジョブ間で割り当てられた、リージョンあたり 12 のストリーミング ユニットのクォータがあります。

詳細については、「[Azure Stream Analytics ジョブのスケーリング](stream-analytics-scale-jobs.md)」を参照してください。


## ジョブの監視およびトラブルシューティング

### 地域モニタリング ストレージ アカウント

ジョブの監視を有効にするには、Stream Analytics で、Stream Analytics のジョブが含まれている各リージョン内のデータを監視する Azure のストレージ アカウントを指定する必要があります。これは、ジョブの作成時に構成します。

### メトリック
次のメトリックは、Stream Analytics の使用状況とジョブのパフォーマンスの監視に利用できます。

- エラー - Stream Analytics のジョブから発生したエラー メッセージの数。
- 入力イベント - Stream Analytics のジョブが受信したデータの 
- イベント数単位の量。
- 出力イベント - Stream Analytics のジョブから出力ターゲットに送信されたデータのイベント数単位の量。
- 順不同イベント - 順不同ポリシーに基づいて、削除された、または調整されたタイムスタンプが付与された、順不同で受信したイベントの数。
- データ変換エラー - Stream Analytics のジョブによって発生した、データ変換エラーの数。

### 操作ログ
Stream Analytics のジョブのデバッグやトラブルシューティングに最適な手段が Azure の操作ログです。操作ログは、ポータルの**管理サービス**セクションからアクセスできます。ジョブのログを調べるには、**[サービスの種類]** を「**Stream Analytics**」に、**[サービス名]** をジョブの名前に設定します。


## ジョブの管理 

### ジョブの開始と停止
ジョブを開始すると、**[出力の開始]** 値の指定が求められます。この値により、そのジョブが結果の出力をいつ生成するかが決定されます。関連付けられたクエリに期間が使用されている場合は、指定したときに最初の出力イベントが生成されるように、所定の期間の開始時に入力ソースから入力を取得するジョブが開始されます。**[ジョブの開始時刻]**、**[ユーザー設定]**、および **[最後に停止した時刻]** の 3 つのオプションがあります。既定の設定は **[ジョブの開始時刻]** です。ジョブが一時的に停止した場合のベスト プラクティスは、最後の出力時刻からジョブを再開してデータ損失を回避するために、**[出力の開始]** 値に **[最後に停止した時刻]** を選択することです。**[ユーザー設定]** のオプションでは、日付と時刻を指定する必要があります。この設定は、入力ソースの履歴データの量の指定や、特定の時刻からのデータのインジェストの取り込みに便利です。

### ジョブの構成
Stream Analytics では、次ジョブの最上位レベルの設定を調整することができます。

- **[出力の開始]** - この設定は、ジョブが結果の出力の生成し始めるタイミングを指定するために使用します。関連付けられたクエリに期間が使用されている場合は、指定したときに最初の出力イベントが生成されるように、所定の期間の開始時に入力ソースから入力を取得するジョブが開始されます。**[ジョブの開始時刻]** と **[ユーザー設定]** の、2 つのオプションがあります。既定の設定は **[ジョブの開始時刻]** です。**[ユーザー設定]** のオプションでは、日付と時刻を指定する必要があります。この設定は、使用する入力ソースの履歴データの量の指定や、ジョブが最後に停止されたときなど、特定の時点からのデータのインジェストの取り込みに便利です。 
- **順不同の場合のポリシー** - Stream Analytics のジョブに順番に着信しないイベントを処理するための設定です。許容範囲を指定してイベントの順序を変更するための時間のしきい値を指定でき、この範囲外のイベントに実行するアクションとして、**削除**または**調整**を決定することもできます。**[削除]** を使用すると、順不同で受信したすべてのイベントが削除されます。**[調整]**を使用すると、システムが変更されます。順不同のイベントのタイムスタンプが、最近受信した順序付けられたイベントのタイムスタンプに変更されます。 
- **遅延着信の場合のポリシー** - 複数のパーティションがある入力ソース、および 1 つ以上の遅延またはデータなしパーティションがある入力ソースからの読み取り時には、システム内でイベントの流れが中断しないように、ストリーミング ジョブでこの状況を扱う方法を決定する必要があります。[許容される最大着信遅延] 入力設定がこの動作を制御し、既定ではデータを無限に待機するように設定されます。これはつまり、イベントのタイムスタンプは変更されず、イベントの流れは最も遅い入力パーティションに応じたものとなり、1 つ以上の入力パーティションにデータがない場合は流れを停止するということを意味します。これは、複数の入力パーティション間でデータが均等に分散されており、複数のイベント間で時間の一貫性が重要な場合に便利です。ユーザーは限定した時間だけ待機するように決定することもできます。その場合 [許容される最大着信遅延] は、ジョブを先に進めるまでに待機する遅延期間を決定します。その期間が経過すると、遅延入力パーティションを待たずに、[遅延イベントに対するアクション] 設定に従ってイベントを処理し、イベントを削除するかデータが後から着信した場合はイベントのタイムスタンプを調整します。これは、待機時間が重要であり、タイムスタンプのシフトが許容され、入力が均等に分散されていない可能性がある場合に便利です。
- **ロケール** - Stream Analytics のジョブの国際化の基本設定を指定するには、この設定を使用します。データのタイムスタンプはロケールに依存しませんが、この設定は、ジョブの解析、比較、およびデータの並べ替えの方法に影響を与えます。プレビュー リリースでは、**en-US** のみがサポートされています。

### 状態

Stream Analytics のジョブの状態は、Azure ポータルで検査することができます。ジョブの実行の状態は、"**実行中**" または "**低下**" のどちらかになります。これらの状態のそれぞれの定義を次に示します。

- **実行中** - ジョブは、割り当て済み、入力の処理中、または入力処理の待機中です。ジョブが出力を生成せずに実行中の状態のままになっている場合、データ処理期間が長期であるか、クエリのロジックが複雑である可能性があります。または、現在ジョブにデータが送信されていない可能性があります。
- **低下** - この状態は、Stream Analytics のジョブに、入出力の通信エラー、クエリのエラー、または再試行可能な実行時エラーのいずれかが発生していることを示しています。ジョブに発生したエラーの種類を見分けるには、操作ログを表示します。


## サポートを受ける
さらにサポートが必要な場合は、[Azure Stream Analytics フォーラム](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics)を参照してください。


## 次のステップ

Stream Analytics の主要概念を理解できたら、以下を試してみてください。

- [Azure Stream Analytics の概要](stream-analytics-introduction.md)
- [Azure Stream Analytics の使用](stream-analytics-get-started.md)
- [Azure Stream Analytics ジョブのスケーリング](stream-analytics-scale-jobs.md)
- [Stream Analytics Query Language Reference (Stream Analytics クエリ言語リファレンス)](https://msdn.microsoft.com/library/azure/dn834998.aspx)
- [Azure Stream Analytics management REST API reference (Azure ストリーム分析の管理 REST API リファレンス)](https://msdn.microsoft.com/library/azure/dn835031.aspx)
 

<!---HONumber=58_postMigration-->