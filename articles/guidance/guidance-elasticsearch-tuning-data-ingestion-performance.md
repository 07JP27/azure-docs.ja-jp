<properties
   pageTitle="Azure での Elasticsearch のデータ インジェスト パフォーマンスのチューニング | Microsoft Azure"
   description="Azure の Elasticsearch でデータ インジェストのパフォーマンスを最大にする方法です。"
   services=""
   documentationCenter="na"
   authors="mabsimms"
   manager="marksou"
   editor=""
   tags=""/>

<tags
   ms.service="guidance"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="02/18/2016"
   ms.author="masimms"/>

# Azure での Elasticsearch のデータ インジェスト パフォーマンスのチューニング

この記事は[シリーズの一部](guidance-elasticsearch.md)です。

## 概要

検索データベースを作成するときに重要なのは、迅速かつ効率的に検索可能なデータをインジェストするようにシステムを構築する最善の方法を決定することです。この要件について考慮するときは、システムを実装するインフラストラクチャの選択だけでなく、想定したデータ流入レベルをシステムが維持するのに役立つさまざまな最適化も関係してきます。

このドキュメントでは、高速のデータ インジェストが期待される Elasticsearch クラスターを実装するときに考慮する必要のあるデプロイメントと構成のオプションについて説明します。確かなデータを示して説明するため、このドキュメントでは、簡単な大容量データ インジェスト ワークロードを使用したさまざまな構成のベンチマークの結果を示します。ワークロードの詳細については、このドキュメントの最後にある「[付録](#appendix-the-bulk-load-data-ingestion-performance-test)」を参照してください。

ベンチマークの目的は、Elasticsearch の実行に関する詳細なパフォーマンス データを取得したり、特定のトポロジを推奨したりすることではなく、パフォーマンスの評価、データ ノードのサイズの決定、実際のパフォーマンス要件を満たすクラスターの実装などに使用できる方法を説明することです。

システムのサイズを決定するときは、実際のワークロードに基づいて詳細にパフォーマンスをテストする必要があります。使用する最適なハードウェア構成や、考慮すべき水平方向のスケーリング因子に関する情報を取得できるように、テレメトリ情報を収集します。具体的には、次のようなことを行う必要があります。

- 各一括挿入要求の項目数だけでなく、送信されるペイロード全体のサイズを検討します。各要求の処理に使用可能なリソースによっては、少数の大きい一括項目による要求の方が多数の項目よりよい結果になることがあります。

Marvel、JMeter の *readbytes*/*writebytes* I/O カウンター、Ubuntu の *iostat* や *vmstat* などのオペレーティング システム ツールを使って、さまざまな一括挿入要求の影響を監視できます。

- パフォーマンス テストを行ってテレメトリ情報を収集し、CPU の処理と I/O 待ち時間、ディスク待機時間、スループット、応答時間を測定します。この情報は、潜在的なボトルネックを特定し、Premium ストレージを使用するコストとメリットを評価するのに役立ちます。クラスターへのシャードとレプリカの分散方法によっては (一部のノードが他よりシャードが多い)、CPU とディスクの使用率がすべてのノードで均等にならない可能性があることに注意してください。

- ワークロードに対する多数の同時要求がクラスター全体にどのように分散されるかを検討し、このワークロードを処理するノードの数を変えたときの影響を評価します。

- ビジネスの拡大と共にワークロードがどのように増える可能性があるかを検討します。ノードで使用される VM とストレージのコストに対するこの増加の影響を評価します。

- 必要な要求の数が多く、ディスク インフラストラクチャが SLAS を満たすスループットを維持する場合、通常のディスクを使用する多数のノードでクラスターを構成した方が経済的である場合があることを認識してください。ただし、ノードの数を増やすと、ノード間の通信と同期が増えることでオーバーヘッドが発生する可能性があります。

- ノードあたりのコアの数が多いほど、より多くのドキュメントを処理できるため、ディスク トラフィックが増加する場合があります。この場合は、ディスクの使用率を測定して、I/O サブシステムがボトルネックになっていないかどうか評価し、Premium ストレージを使用するメリットを判断します。

- コア数が少ない多数のノードを使用した場合と、コア数が多い少数のノードを使用した場合の、トレードオフをテストして分析します。レプリカの数を増やすとクラスターに対する要求が増大し、ノードの追加が必要になる可能性があることに留意してください。

- インデックスをさらに頻繁に回復するために一時的なディスクの使用が必要かどうかを検討します。

- ストレージ ボリュームの使用率を測定し、ストレージの容量と低使用率を評価します。たとえば、このシナリオでは、350 GB のストレージを使用して 15 億個のドキュメントを保存しました。

- ワークロードの転送速度を測定し、仮想ディスクを作成した特定のストレージ アカウントの総 I/O 速度転送限界にどの程度近づいているかを検討します。

## ノードとインデックスの設計

大量データ インジェストをサポートする必要があるシステムでは、次のことを確認します。

- **データの移動は頻繁に行われますか、それともあまり行われませんか? ** データが動的なほど、Elasticsearch のメンテナンス オーバーヘッドも大きくなります。データがレプリケートされる場合、各レプリカは同期的に保持されます。有効期間が限られている、または簡単に再構築できる、移動の激しいデータは、レプリケーションを完全に無効にすることでメリットがある可能性があります。このオプションについては、「[大規模なデータ インジェストのチューニング](#tuning-large-scale-data-ingestion)」セクションでさらに詳しく説明します。

- **検索によってどの程度新しいデータが検出される必要がありますか? ** パフォーマンスを維持するため、Elasticsearch は可能な限り多くのデータをメモリのバッファーに格納します。つまり、検索要求に対してすべての変更をすぐに利用できるわけではありません。Elasticsearch で変更を保持し、その変更を表示するプロセスについては、「[Making Changes Persistent (変更を永続化する)](https://www.elastic.co/guide/en/elasticsearch/guide/current/translog.html#translog)」というオンライン ドキュメントを参照してください。

    データが表示されるようになるまでの時間は、関連するインデックスの *refresh\_interval* の設定で制御します。既定では、この間隔は 1 秒に設定されます。ただし、これほど速く更新を行う必要がない状況もあります。たとえば、ログ データを記録するインデックスは、高速で立て続けに流入する情報に対応して迅速にインジェストする必要がありますが、情報をすぐにクエリで使用できるようにする必要はありません。このような場合は、更新頻度を減らすことを検討します。この機能については、「[大規模なデータ インジェストのチューニング](#tuning-large-scale-data-ingestion)」セクションも参照してください。

- **データはどれくらいの速さで増加しますか?** インデックスの容量は、インデックス作成時に指定されるシャードの数によって決まります。成長に対応できるようにするには、適切な数のシャードを指定します (既定値は 5)。インデックスが最初に 1 つのノードに作成される場合、5 つのシャードはすべてそのノードに配置されますが、データ量の増加に合わせてノードを追加でき、Elasticsearch はノード間にシャードを動的に分配します。ただし、シャードごとにオーバーヘッドが発生します。あるインデックスでのすべての検索ではすべてのシャードがクエリされるので、少量のデータに対して多数のシャードを作成すると、データ取得速度が低下することがあります ([Kagillion シャード](https://www.elastic.co/guide/en/elasticsearch/guide/current/kagillion-shards.html)のようなシナリオの回避)。

    ワークロードによっては (ログなど)、新しいインデックスが毎日作成されることがあります。データ量に対してシャードの数が不十分であることがわかった場合は、次のインデックスを作成する前に変更する必要があります (既存のインデックスは影響を受けません)。既存データを配布するシャードを増やす必要がある場合の 1 つの方法は、情報のインデックスを作成し直すことです。適切な構成で新しいインデックスを作成し、それにデータをコピーします。[インデックス エイリアス](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html)を使用すると、このプロセスをアプリケーションに対して透過的にできます。

- **マルチ テナントのシナリオでデータをユーザー間に分割する必要がありますか?** ユーザーごとに個別のインデックスを作成できますが、各ユーザーのデータ量がそれほど多くない場合、コスト効率が悪くなる可能性があります。このような場合は、代わりに[共有インデックス](https://www.elastic.co/guide/en/elasticsearch/guide/current/shared-index.html)を作成し、[フィルター ベースのエイリアス](https://www.elastic.co/guide/en/elasticsearch/guide/current/faking-it.html)を使用して要求をユーザーごとのデータに送ることを検討します。1 人のユーザーのデータを同じシャードにまとめるには、インデックスの既定のルーティング構成をオーバーライドし、いくつかのユーザー識別属性に基づいてデータをルーティングします。

- **データの有効期間はどれくらいですか?** 一連の Azure VM を使用して Elasticsearch クラスターを実装している場合、一時的なデータは、接続されているドライブではなく、ローカル リソースのシステム ディスクに格納できます。SSD を搭載した VM SKU をリソース ディスクに使用すると、I/O パフォーマンスを向上させることができます。ただし、リソース ディスクに保持される情報は一時的であり、VM を再起動すると失われる可能性があります (詳しくは、「[Understanding the temporary drive on Microsoft Azure Virtual Machines (Microsoft Azure Virtual Machines での一時ドライブの概要)](http://blogs.msdn.com/b/mast/archive/2013/12/07/understanding-the-temporary-drive-on-windows-azure-virtual-machines.aspx)」の「When Will the Data on a Temporary Drive Be Lost (一時ドライブのデータが失われる場合)」を参照してください)。再起動してもデータが保持されるようにするには、この情報を保持するためのデータ ディスクを作成し、そのデータ ディスクを VM に接続します。

- **データはどの程度アクティブですか?** 読み取り/書き込みアクティビティの量が指定されているパラメーター (現在は、Standard レベルの VM に接続されたディスクで 500 IOPS、Premium ストレージ ディスクで 5000 IOPS) を超えた場合、Azure VHD には制限が適用されます。

    スロットルの可能性を減らして I/O パフォーマンスを向上させるには、VM ごとに複数のデータ ディスクを作成し、これらのディスクにデータをストライピングするように Elasticsearch を構成します。詳しくは、「[Disk and File System Requirements (ディスクとファイル システムの要件)](guidance-elasticsearch-running-on-azure.md#disk-and-file-system-requirements)」を参照してください。

    ディスク I/O 読み取り操作数が最小限になるように、頻繁にアクセスされるデータのキャッシュに十分なメモリを利用できるハードウェア構成を選択する必要があります。これについては、「Running Elasticsearch on Azure (Azure で Elasticsearch を実行する)」の「[Memory Requirements (メモリ要件)](guidance-elasticsearch-running-on-azure.md#memory-requirements)」セクションを参照してください。

- **どのような種類のワークロードを各ノードでサポートする必要がありますか? ** Elasticsearch では、ファイル システム キャッシュの形式でのデータのキャッシュおよび JVM ヒープにメモリを利用するとメリットがあります。「Running Elasticsearch on Azure (Azure で Elasticsearch を実行する)」の「[Memory Requirements (メモリ要件)](guidance-elasticsearch-running-on-azure.md#memory-requirements)」を参照してください。

    メモリの量、CPU コアの数、使用可能なディスクの数は、仮想マシンの SKU によって設定されます。詳細については、Azure Web サイトの「[Virtual Machines の価格](http://azure.microsoft.com/pricing/details/virtual-machines/)」ページを参照してください。

### 仮想マシンのオプション

Azure では、複数の異なる SKU を使用して VM をプロビジョニングできます。Azure VM で利用できるリソースは、選択した SKU によって異なります。各 SKU では、コア、メモリ、ストレージの異なる組み合わせが提供されます。予測されるワークロードを処理できて、しかもコスト効果のよい、適切なサイズの VM を選択する必要があります。現在の要件を満たす構成から始めます (このドキュメントで後述するように、ベンチマークを実行してテストします)。Elasticsearch ノードを実行する VM を追加することによって、後でクラスターを拡張できます。

Azure Web サイトの「[仮想マシンのサイズ](virtual-machines-size-specs/)」では、VM で使用できるさまざまなオプションと SKU が説明されています。

VM のサイズとリソースを、VM 上のノードが実行するロールと一致させる必要があります。

データ ノードの場合:

- 最大 30 GB または使用可能な RAM メモリの 50% のうちどちらか少ない方を、Java ヒープに割り当てます。それ以外は、オペレーティング システムによるファイルのキャッシュ用に残しておきます。Linux を使用している場合は、Elasticsearch を実行する前に、ES\_HEAP\_SIZE 環境変数を設定することによって、Java ヒープに割り当てるメモリの量を指定できます。または、Windows または Linux を使用している場合は、Elasticsearch の起動時に、*Xmx* および *Xms* パラメーターでメモリ サイズを指定できます。

    ワークロードによっては、少数の大きな VM が中程度のサイズの VM を多数使用するよりパフォーマンス的に効率的ではないことがあります。テストを実施して、ネットワーク トラフィックとメンテナンスが増加することと、使用可能なコア数を増やして各ノードでのディスク競合を減らすコストの間のトレードオフを、測定する必要があります。

- Premium Storage を使用して Elasticsearch のデータを格納します。詳細については、「[ストレージ オプション](#storage-options)」で説明します。

- 同じサイズの複数のディスクを使用し、これらのディスクにデータをストライピングします。VM の SKU で、接続できるデータ ディスクの最大数が示されています。詳細については、「[Disk and File System Requirements (ディスクとファイル システムの要件)](guidance-elasticsearch-running-on-azure.md#disk-and-file-system-requirements)」を参照してください。

- マルチコアの CPU SKU を使用します (少なくとも 2 コア、できれば 4 コア以上)。

クライアント ノードの場合:

- Elasticsearch データ用にディスク ストレージを割り当てないようにします。専用のクライアントはデータをディスクに保存しません。

- ワークロードの処理用に十分なメモリを用意します。一括挿入要求は、データがさまざまなデータ ノードに送信される前にメモリに読み取られます。また、集計とクエリの結果は、クライアント アプリケーションに返される前にメモリに蓄積されます。実際のワークロードをベンチマークし、Marvel や、*node/stats* API (`GET _nodes/stats`) を使用すると返される [JVM 情報](https://www.elastic.co/guide/en/elasticsearch/guide/current/_monitoring_individual_nodes.html#_jvm_section)を使用してメモリの使用状況を監視し、最適な要件を評価します。具体的には、各ノードの *heap\_used\_percent* メトリックを監視し、ヒープ サイズが使用可能な領域の 75% を常に下回るようにします。

- 予想される量の要求を受信して処理するのに十分な CPU コアが使用できることを確認します。受信された要求は処理の前にキューに格納され、キューに格納できる項目の量は各ノードの CPU コアの数の関数です。node/stats API で返される [Threadpool 情報](https://www.elastic.co/guide/en/elasticsearch/guide/current/_monitoring_individual_nodes.html#_threadpool_section)のデータを使用して、キューの長さを監視できます。

    キューの*拒否*数で、要求が拒否されていることが示されている場合は、クラスターがボトルネックになり始めています。これは CPU の帯域幅のためである可能性がありますが、メモリの不足や低い I/O パフォーマンスなどの他の要因が原因である場合もあるので、他の統計情報と共にこの情報を使用すると、根本原因の特定に役立ちます。

    ワークロードに応じて、クライアント ノードが必要である場合と、必要ない場合があります。データ インジェスト ワークロードでは専用のクライアントを使用してもメリットがない傾向がありますが、一部の検索や集計は時間を短縮できる場合があります。実際のシナリオでベンチマークすることを心がけてください。

    クライアント ノードは、トランスポート クライアント API を使用してクラスターに接続するアプリケーションに特に有効です。また、アプリケーション ホスト環境のリソースを使用して、アプリケーションの専用クライアントを動的に作成するノード クライアント API を使用することもできます。アプリケーションがノード クライアント API を使用している場合は、クラスターに事前構成済みの専用クライアント ノードを含める必要がない場合があります。
    
    ただし、ノード クライアント API を使用して作成されたノードはクラスターのファースト クラス メンバーであり、したがって他のノードとのネットワーク通信に参加することに注意してください。クライアント ノードを頻繁に開始および停止すると、クラスター全体に不要なノイズが発生することがあります。

マスター ノードの場合:

- Elasticsearch データ用にディスク ストレージを割り当てないようにします。専用のマスター ノードはデータをディスクに保存しません。

- CPU 要件を最小限にする必要があります。

- メモリ要件はクラスターのサイズによって異なります。クラスターの状態に関する情報はメモリに保持されます。小規模なクラスターの場合は必要なメモリの量は最小限ですが、頻繁にインデックスが作成されてシャードが移動する大規模で高アクティブのクラスターでは、状態情報の量が目に見えて増大することがあります。JVM ヒープのサイズを監視して、メモリの追加が必要かどうかを判断します。

> [AZURE.NOTE]  クラスターの信頼性のため、常に複数のマスター ノードを作成し、残りのノードを構成して、スプリット ブレインが発生しないようにします。できれば、マスター ノードの数を奇数にします。このトピックの詳細については、「[Configuring Resilience and Recovery on Elasticsearch on Azure (Azure での Elasticsearch の復元と回復の設定)][]」を参照してください。

### ストレージ オプション

多くのストレージ オプションを使用でき、コスト、パフォーマンス、可用性、回復に関して、慎重に検討する必要があるさまざまなトレードオフがあります。

Elasticsearch のデータは専用のデータ ディスクに格納する必要があることに注意してください。これにより、オペレーティング システムとの競合が減り、大量の Elasticsearch I/O が I/O リソースに関するオペレーティング システムの機能と競合しなくなります。

Azure ディスクはパフォーマンスの制約によって影響を受けます。クラスターのアクティビティが定期的に急増する場合、I/O 要求が調整される可能性があります。これを防ぐには、Elasticsearch でのドキュメントのサイズと、各ディスクが受信する可能性のある要求の量のバランスを考えて、設計を調整します。

Standard Storage に基づくディスクがサポートする最大要求速度は 500 IOPS です。それに対して、Premium Storage に基づくディスクは最大 5,000 IOPS で動作できます。Premium ストレージディスクは、DS および GS シリーズの VM にのみ利用できます。Azure VM の最大ディスク IOPS 速度については、[こちらのオンライン ドキュメント](virtual-machines-size-specs/)を参照してください。

**永続データ ディスク**

永続データ ディスクは、Azure Storage に基づく VHD です。大規模な障害の後で VM を再作成する必要がある場合、既存の VHD を新しい VM に簡単に接続できます。VHD は、Standard ストレージ(回転メディア) または Premium ストレージ(SSD) を基にして作成できます。SSD を使用する場合は、DS シリーズ以上を使用して VM を作成する必要があります。DS マシンのコストは同等の D シリーズ VM と同じですが、Premium ストレージを使用するための追加料金がかかります。

ディスクあたりの最大転送速度が予想されるワークロードをサポートするのに十分ではない場合は、複数のデータ ディスクを作成して Elasticsearch が[これらのディスクにデータをストライピング](guidance-elasticsearch-running-on-azure.md#disk-and-file-system-requirements)できるようにするか、またはシステム レベルの [RAID 0 ストライピングを仮想ディスクを使用して](virtual-machines-linux-configure-raid/)実装することを検討します。

> [AZURE.NOTE] Microsoft 社内での経験として、RAID 0 を使用すると、頻繁なアクティビティ バーストを生成するワークロードの*急増*による I/O への影響を平滑化するのに特に有効です。

ディスクを保持するストレージ アカウントには、ローカルに冗長な Premium ストレージを使用します (ローエンド ワークロードまたは QA ワークロードについてはローカルに冗長なストレージ)。地理的範囲およびゾーンをまたぐレプリケートは、Elasticsearch HA には必要ありません。

**一時ディスク**

SSD に基づく永続ディスクを使用するには、Premium ストレージをサポートする VM を作成する必要があります。その場合、価格に影響があります。ローカル一時ディスクを使用して Elasticsearch のデータを保持するのは、最大で約 800 GB のストレージを必要とする中規模のノードに対するコスト効率に優れたソリューションです。Standard-D シリーズの VM では、一時ディスクは、通常のディスクよりはるかに優れたパフォーマンスと短い遅延を実現する SSD を使用して実装されます。

Elasticsearch を使用すると、追加のコストをかけずに、Premium Storage を使用する場合と同等のパフォーマンスを実現できます。詳細については、「[ディスク遅延時間の問題への対処](#addressing-disk-latency-issues)」を参照してください。

「[D-Series Performance Expectations (D シリーズの予想パフォーマンス)](https://azure.microsoft.com/blog/d-series-performance-expectations/)」で説明されているように、VM のサイズにより、短期ストレージで使用できる領域の量が制限されます。

たとえば、提供される一時ストレージの量は、Standard\_D1 VM では 50 GB、Standard\_D2 VM では 100 GB、Standard\_D14 VM では 800 GB です。ノードに必要なのがこの量の領域だけであるクラスターでは、D シリーズの VM と短期ストレージを使用すると、コスト効率がよくなります。

短期ストレージによって増加する使用可能なスループットと、コンピューターの再起動後にこのデータを回付するときの時間とコストのバランスを取る必要があります。VM が別のホスト サーバーに移動した場合、ホストが更新された場合、またはホストでハードウェア障害が発生した場合は、一時ディスクの内容が失われます。データ自体の有効期間が限定的である場合、このデータ損失は許容できる可能性があります。長期間有効なデータの場合は、インデックスを再構築したり、足りない情報をバックアップから回復したりできる場合があります。他の VM にレプリカを保持することで、損失の可能性を最小限にすることができます。

> [AZURE.NOTE] 重要な本番データは**単一**の VM で保持しないでください。ノードで障害が発生した場合、すべてのデータを使用できなくなります。重要な情報は、少なくとも 1 つの他のノードにレプリケートします。

**Azure Files**

[Azure File Service](http://blogs.msdn.com/b/windowsazurestorage/archive/2014/05/12/introducing-microsoft-azure-file-service.aspx) は、Azure Storage による共有ファイル アクセスを提供します。ファイル共有を作成して、Azure VM にマウントできます。複数の VM で同じファイル共有をマウントし、同じデータにアクセスすることができます。

パフォーマンスのため、ノード間で共有する必要のない Elasticsearch データを保持するためにファイル共有を使用することはお勧めしません。この目的には、通常のデータ ディスクの方が適しています。ファイル共有は、Elasticsearch の[シャドウ レプリカ インデックス](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-shadow-replicas.html)の作成に使用できます。ただし、この機能は現在試験中であり、現時点では運用環境に実装しないでください。このため、このガイダンスではシャドウ インデックスについてはこれ以上考慮しません。

**ネットワーク オプション**

Azure は共有ネットワークのしくみを実装しています。同じハードウェア ラックを利用している複数の VM の間では、ネットワーク リソースの競合が発生します。したがって、同じ物理ネットワーク インフラストラクチャを共有する VM で実行される処理の時間単位はたは日単位のサイクルにより、ネットワーク帯域幅が変化する可能性があります。このような要因を制御することはほとんどできません。ネットワークのパフォーマンスは時間の経過と共に変動するので、ユーザーの期待をそれに従って設定することを理解しておくことが重要です。

## 大規模なデータ インジェストをサポートするためのノードのスケールアップ

中程度のハードウェアを使用して Elasticsearch クラスターを構築した後、データ量および要求数の増加に合わせてスケールアップまたはスケールアウトできます。Azure では、スケールアップとはより大型で高価な VM を使用することで、スケールアウトとは小型で安価な VM を追加することです。

両方の戦略を組み合わせて実行することもできます。すべてのシナリオのすべてのソリューションに 1 つのサイズで対応することはできないので、特定の状況に最適な方法を評価するには、一連のパフォーマンス テストを実行する必要があります。

このセクションでは、スケールアップの方法について説明します。スケールアウトについては、「[スケールアウト: 結論](#scaling-out-conclusions)」セクションで説明します。このセクションでは、異なるサイズの複数の VM で構成される Elasticsearch クラスターのセットに対して実行された一連のベンチマークの結果について説明します。クラスターは、Small、Medium、Large の 3 種類でした。次の表は、各クラスターの VM に割り当てられていたリソースをまとめたものです。

| クラスター | VM の SKU | コアの数 | データ ディスクの数 | RAM |
|---------|-------------|-----------------|----------------------|------|
| Small | Standard D2 | 2 | 4 | 7 GB |
| Medium | Standard D3 | 4 | 8 | 14 GB |
| Large | Standard D4 | 8 | 16 | 28 GB |

各 Elasticsearch クラスターには、3 つのデータ ノードが含まれます。これらのデータ ノードでは、クライアント要求の処理だけでなく、データの処理も行われました。クライアント ノードの分離は、テストで使用されるデータ インジェスト シナリオにはメリットがほとんどないので使用されませんでした。また、クラスターには 3 つのマスター ノードが含まれ、そのうちの 1 つが Elasticsearch によってクラスター調整用に選択されました。

テストは、Elasticsearch 1.7.3 を使用して行われました。テストは、最初に Ubuntu Linux 14.0.4 を実行するクラスターで行われた後、Windows Server 2012 を使用して繰り返されました。テストで実行されたワークロードの詳細については、「[付録](#appendix-the-bulk-load-data-ingestion-performance-test)」を参照してください。

### データ インジェストのパフォーマンス – Ubuntu Linux 14.0.4

次の表は、各構成で 2 時間テストを実行した全体的な結果をまとめたものです。

| 構成 | サンプル数 | 平均応答時間 (ミリ秒) | スループット (操作/秒) |
|---------------|-----------|----------------------------|---------------------------|
| Small | 67057 | 636 | 9\.3 |
| Medium | 123482 | 692 | 17\.2 |
| Large | 197085 | 839 | 27\.4 |

3 種類の構成で処理されたスループットとサンプル数は、だいたい 1:2:3 の比率です。ただし、メモリ、CPU コア、ディスクに関して利用可能なリソースの比率は 1:2:4 です。クラスター内のノードの下位レベルのパフォーマンスの詳細を調べて、このような結果になる理由を評価してみるのは価値があるものと考えられました。この情報は、スケールアップに制限があるかどうか、およびスケールアウトを検討する方がよい場合を判断するのに役立ちます。

### 制限要因の特定: ネットワーク使用率

Elasticsearch では、クライアント要求の流入およびクラスター内のノード間を流れる同期情報をサポートするのに十分なネットワーク帯域幅が必要です。前に指摘したように、帯域幅の可用性は、使用しているデータセンターや、同じネットワーク インフラストラクチャを共有する他の仮想マシンの現在のネットワーク負荷などの多数の変数に依存するため、制御できる範囲は限られます。ただし、トラフィックの量が過剰ではないことを確認するだけであっても、各クラスターのネットワーク アクティビティを調べる価値があります。次のグラフでは、各クラスターのノード 2 で受信されたネットワーク トラフィックの比較を示します (各クラスターの他のノードの量はほぼ同じでした)。

![](media/guidance-elasticsearch/data-ingestion-image1.png)

2 時間にわたって各クラスター構成のノード 2 が 1 秒間に受信した平均バイト数は次のとおりです。

| 構成 | 平均受信バイト数/秒 |
|---------------|--------------------------------------|
| Small | 3993640\.3 |
| Medium | 7311689\.9 |
| Large | 11893874\.2 |

テストはシステムが**安定した動作状態**のときに実施されました。インデックスの再バランス調整またはノードの回復が行われている場合は、プライマリ シャードおよびレプリカ シャードを保持しているノード間のデータ転送により、かなりのネットワーク トラフィックが発生する可能性があります。このプロセスによる影響の詳細については、「[Configuring Resilience and Recovery on Elasticsearch on Azure (Azure での Elasticsearch の復元と回復の設定)][]」を参照してください。

### 制限要因の特定: CPU 使用率

要求の処理速度は、少なくとも部分的には使用可能な処理能力によって決まります。Elasticsearch は、一括挿入キューで一括挿入要求を受け入れます。各ノードには、使用可能なプロセッサの数によって決まる一括挿入キューのセットがあります。既定では、プロセッサごとに 1 つのキューが存在し、各キューには最大で 50 個の未処理要求が保持されます。これを超えると、要求は拒否されるようになります。

アプリケーションは、キューからあふれないような速度で要求を送信する必要があります。ある時点における各キュー内の項目の数は、クライアント アプリケーションによる要求の送信速度と、同じ要求を Elasticsearch が取得して処理する速度の関数になります。このため、取得される重要な統計の 1 つは、次の表にまとめるエラー率に関するものです。

| 構成 | 合計サンプル数 | エラー数 | エラー率 |
|---------------|---------------|-----------|------------|
| Small | 67057 | 0 | 0\.00% |
| Medium | 123483 | 1 | 0\.0008% |
| Large | 200702 | 3617 | 1\.8 % |

これらの各エラーは、次のような Java 例外によるものです。

```
org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase$1@75a30c1b]; ]
[219]: index [systembase], type [logs], id [AVEAioKb2TRSNcPa_8YG], message [RemoteTransportException[[esdatavm2][inet[/10.0.1.5:9300]][indices:data/write/bulk[s]]]; nested: EsRejectedExecutionException[rejected execution (queue capacity 50)
```

キューの数や各キューの長さを増やすと、エラーの数が減る可能性がありますが、このアプローチで対応できるのは短時間のバーストのみです。継続的な一連のデータ インジェスト タスクの実行中にこれを行うと、エラーの発生開始が遅くなるだけです。さらに、この変更ではスループットは向上せず、要求は処理前に長時間キューに格納されるので、クライアント アプリケーションの応答時間を損なう可能性があります。

5 個のシャードと 1 個のレプリカ (全部で 10 シャード) という既定のインデックス構造により、クラスター内のノード間に中程度の負荷の不均衡が発生します。2 つのノードに 3 個のシャードが含まれ、もう 1 つのノードに 4 個のシャードが含まれます。通常、最もビジーなノードによってスループットが最も制限されるので、各ケースではこのノードが選択されています。

次の一連のグラフでは、各クラスターで最もビジーなノードの CPU 使用率を示します。

![](media/guidance-elasticsearch/data-ingestion-image2.png)

![](media/guidance-elasticsearch/data-ingestion-image3.png)

![](media/guidance-elasticsearch/data-ingestion-image4.png)

Small、Medium、Large クラスターの平均 CPU 使用率は、それぞれ 75.01%、64.93%、64.64% でした。使用率が実際に 100% に達することはほとんどなく、ノードのサイズと使用可能な CPU パワーが増えると使用率は低下します。したがって、CPU パワーが大規模なクラスターのパフォーマンスを制限する要因である可能性は低いと見られます。

### 制限要因の特定: メモリ

メモリ使用量は、パフォーマンスに影響を与える可能性のあるもう 1 つの重要な要素です。テストでは、Elasticsearch に使用可能なメモリの 50% を割り当てました。これは、[推奨事項](https://www.elastic.co/guide/en/elasticsearch/guide/current/heap-sizing.html#_give_half_your_memory_to_lucene)に即したものです。テストの実行中、JVM では過剰なガベージ コレクション アクティビティ (ヒープ メモリ不足の兆候) が監視されました。すべてのケースにおいて、ヒープ サイズは安定しており、JVM のガベージ コレクション アクティビティは低いものでした。次のスクリーンショットは Marvel のスナップショットであり、Large クラスターでのテスト実行中の短時間の主要な JVM 統計情報を示しています。

![](media/guidance-elasticsearch/data-ingestion-image5.png)

***Large クラスターでの JVM メモリとガベージ コレクション アクティビティ。***

### 制限要因の特定: ディスク I/O 速度

パフォーマンスを制限する可能性があるサーバー側の物理的特性で残っているのは、ディスク I/O サブシステムのパフォーマンスです。次のグラフは、各クラスターの最もビジーなノードでの書き込みバイト数に関してディスク利用状況を比較したものです。

![](media/guidance-elasticsearch/data-ingestion-image6.png)

次の表では、2 時間にわたって各クラスター構成のノード 2 が 1 秒間に書き込んだ平均バイト数を示します。

| 構成 | 書き込まれた平均バイト数/秒 |
|---------------|-------------------------------------|
| Small | 25502361\.94 |
| Medium | 48856124\.5 |
| Large | 88137675\.46 |

書き込まれたデータの量はクラスターにより処理される要求の数と共に増加しますが、I/O 速度は Azure Storage の制限内です (Azure Storage を使用して作成されたディスクは、Standard ストレージか Premium ストレージかにより、数十～数百 MB/秒の速度を維持できます)。ディスク I/O 待機時間を調べると、ディスクのスループットが理論上の最大値より十分に低い理由を説明できます。以下のグラフと表では、同じ 3 つのノードについてのこれらの統計を示します。

> [AZURE.NOTE] ディスク待機時間は、プロセッサが I/O 操作の完了を待機してブロックされている CPU 時間の割合を監視することによって測定されます。

![](media/guidance-elasticsearch/data-ingestion-image7.png)

![](media/guidance-elasticsearch/data-ingestion-image8.png)

![](media/guidance-elasticsearch/data-ingestion-image9.png)

| 構成 | 平均ディスク待機 CPU 時間 (%) |
|---------------|--------------------------------|
| Small | 21\.04 |
| Medium | 14\.48 |
| Large | 15\.84 |

このデータからは、CPU 時間のかなりの割合 (約 16% ～ 21%) が、ディスク I/O 完了の待機に費やされていることがわかります。これは、Elasticsearch が要求を処理してデータを格納する能力を制限します。

テストの実行中に、Large クラスターは **5 億個を超えるドキュメント**を挿入しました。テストを続けると、データベースに含まれるドキュメントが 6 億個を超えた時点で、待機時間が大幅に増加しました。この動作の原因は完全には調査されていませんが、ディスクの断片化によるディスク待機時間の増加である可能性があります。

ノードを追加してクラスターのサイズを増やすと、この動作の影響を軽減するのに役立ちます。極端なケースでは、I/O 時間が過剰に長いディスクの最適化が必要になる場合があります。ただし、大きなディスクの最適化にはかなりの時間がかかり (おそらく、2 TB の VHD ドライブで 48 時間以上)、単にドライブを再フォーマットして Elasticsearch でレプリカ シャードから欠落しているデータを回復する方が、コスト効果が高い可能性があります。

### ディスク遅延時間の問題への対処

テストは最初に、Standard ディスクで構成された VM を使用して実行されました。Standard ディスクは回転メディアを利用しており、結果として、I/O 速度を制限する回転待ち時間やその他のボトルネックが発生します。Azure では、ディスクが SSD デバイスで作成されている Premium ストレージも提供されています。SSD デバイスには回転待ち時間がないので、I/O 速度が向上します。

次の表では、Large クラスターの Standard ディスクを Premium ディスクに置き換えた場合の結果を示します。Large クラスターの Standard D4 VM を Standard DS4 VM に置き換えました。コア数、メモリ、ディスク数はどちらも同じであり、唯一の違いは DS4 VM が SSD を使用していることです。

| 構成 | サンプル数 | 平均応答時間 (ミリ秒) | スループット (操作/秒) |
|------------------|-----------|----------------------------|---------------------------|
| Large - Standard | 197085 | 839 | 27\.4 |
| Large - Premium | 255985 | 581 | 35\.6 |

応答時間は著しく向上し、その結果、平均スループットは Small クラスターのほぼ 4 倍になりました。これは、Standard DS4 VM で利用可能なリソースにより近いものです。I/O 完了待機時間が短くなったため、クラスターで最もビジーなノード (この場合はノード 1) の平均 CPU 使用率は上昇しました。

![](media/guidance-elasticsearch/data-ingestion-image10.png)

次のグラフを見ると、ディスク待機時間の減少が明らかです。グラフでは、最もビジーなノードでこの統計値が平均約 1% 低下したことが示されています。

![](media/guidance-elasticsearch/data-ingestion-image11.png)

ただし、この向上には代償があります。インジェスト エラーの数が約 10 倍の 35797 件 (12.3%) に増加しました。やはり、ほとんどのエラーは一括挿入キューのオーバーフローによるものでした。ハードウェアは能力の限界近くで動作しているので、エラーの数を減らすには、ノードを追加するか、一括挿入の速度を抑えることが必要な可能性があります。これらの問題については後で説明します。

### 短期ストレージでのテスト

同じテストを、短期ストレージを使用する D4 VM クラスターで繰り返しました。D4 VM では、短期ストレージは単一の 400 GB SSD として実装されています。処理サンプル数、応答時間、スループットの値はいずれも、Premium ストレージを使用する DS14 VM に基づくクラスターで報告された値とよく似ていました。

| 構成 | サンプル数 | 平均応答時間 (ミリ秒) | スループット (操作/秒) |
|-----------------------------------|-----------|----------------------------|---------------------------|
| Large - Premium | 255985 | 581 | 35\.6 |
| Large – Standard (一時ディスク) | 255626 | 585 | 35\.5 |

エラー率も近い値でした (全 289488 件の要求に対して 33862 件のエラー – 11.7%)。

次のグラフでは、クラスターの最もビジーなノード (今度はノード 2) での CPU 使用率とディスク待機の統計情報を示します。

![](media/guidance-elasticsearch/data-ingestion-image12.png)

![](media/guidance-elasticsearch/data-ingestion-image13.png)

この場合、パフォーマンスだけ考えれば、一時ストレージを使用する方が、Premium ストレージを使用するよりコスト効率のよいソリューションです。

### データ インジェストのパフォーマンス – Windows Server 2012

Windows Server 2012 を実行するノードで構成された Elasticsearch クラスターのセットを使用して、同じテストを繰り返しました。これらのテストの目的は、オペレーティング システムの選択によってクラスターのパフォーマンスにどのような影響があるか (ある場合) を確認することでした。

Windows での Elasticsearch のスケーラビリティを示すため、次の表では Small、Medium、Large のクラスター構成でのスループットと応答時間を示します。これらのテストは、SSD短期ストレージを使用するように構成された Elasticsearch ですべて実行されたことに注意してください。Ubuntu でのテストで示したように、最大のパフォーマンスを実現するには、ディスクの待機時間が重要な要素でした。

| 構成 | サンプル数 | 平均応答時間 (ミリ秒) | スループット (操作/秒) |
|---------------|-----------|----------------------------|---------------------------|
| Small | 90295 | 476 | 12\.5 |
| Medium | 169243 | 508 | 23\.5 |
| Large | 257115 | 613 | 35\.6 |

これらの結果では、VM のサイズおよび Windows で使用可能なリソースによる Elasticsearch のパフォーマンスの変化が示されています。

次の表は、Ubuntu と Windows での Large クラスターの結果を比較したものです。

| オペレーティング システム | サンプル数 | 平均応答時間 (ミリ秒) | スループット (操作/秒) | エラー率 (%) |
|------------------|-----------|----------------------------|---------------------------|----------------|
| Ubuntu | 255626 | 585 | 35\.5 | 11\.7 |
| Windows | 257115 | 613 | 35\.6 | 7\.2 |

スループットは Ubuntu の Large クラスターと一致しましたが、応答時間はわずかに長く、これは低いエラー率によるものである可能性があります (エラーは正常な操作より速く報告されるため、応答時間が低下します)。

Windows 監視ツールによって報告された CPU 使用率は、Ubuntu の場合よりわずかに高い値でした。ただし、異なるオペレーティング システムでのこれらの統計情報の報告方法のため、オペレーティング システム間で測定値を直接比較する場合はよく注意する必要があります。さらに、I/O の待機に費やされた CPU 時間によるディスク待機時間に関する情報は、Ubuntu の場合と同じ方法では使用できません。重要な点は、高い CPU 使用率は、I/O を待つために費やされた時間が少ないことを示しているということです。

![](media/guidance-elasticsearch/data-ingestion-image14.png)

### スケールアップ: 結論

適切に調整されたクラスターでの Elasticsearch のパフォーマンスは Windows でも Ubuntu でも同じであると思われ、同様のパターンでスケールアップします。最適なパフォーマンスを実現するには、**Premium Storage を使用して Elasticsearch のデータを保持します**。

## 大規模なデータ インジェストをサポートするためのクラスターのスケールアウト

スケールアウトは、前のセクションで調べたスケールアップに対する補完的なアプローチです。Elasticsearch の重要な機能は、ソフトウェアに組み込まれている本質的な水平方向のスケーラビリティです。クラスターのサイズを拡大するには、ノードを追加するだけで済みます。インデックスやシャードの再配布は自動的に行われるので手動操作を実行する必要はありませんが、このプロセスを制御できる構成オプションがいくつかあります。

ノードを追加すると、負荷がより多くのハードウェアに分散されるので、パフォーマンスが向上します。ノードを追加するときは、データのインデックスを作り直して使用可能なシャードの数を増やすことも検討する必要があります。最初に使用できるノードより多くのシャードでインデックスを作成することにより、このプロセスをある程度事前に済ましておくことができます。ノードを追加すると、シャードを配布できます。

Elasticsearch の水平拡張性を活用するだけでなく、ノードより多くのシャードでインデックスを実装するには他にも理由があります。各シャードは個別のデータ構造 ([Lucene](https://lucene.apache.org/) インデックス) として実装され、一貫性を維持して同時実行を処理するための独自の内部メカニズムを保持しています。複数のシャードを作成すると、ノード内の並列性が高くなり、パフォーマンスを向上させることができます。

ただし、スケーリングしながらパフォーマンスを維持することは、バランスを要する作業です。クラスターに含まれるノードとシャードが増えると、クラスターによって実行される処理を同期するために必要な作業が増え、スループットが低下する可能性があります。どのようなワークロードにも、メンテナンスのオーバーヘッドを最小限に抑えながらインジェストのパフォーマンスを最大にするスイート スポットがあります。このスイート スポットは、ワークロードとクラスターの特性に大きく依存します。具体的には、ボリューム、サイズ、ドキュメントの内容、 インジェストの発生頻度、システムが実行されているハードウェアなどです。

このセクションでは、前に説明したパフォーマンス テストで使用したワークロードをサポートするためのクラスターのサイズ決定での調査結果をまとめます。Ubuntu Linux 14.0.4 を実行する大規模な VM サイズ (8 CPU コアの Standard D4、16 個のデータ ディスク、28 GB の RAM) のクラスターで、ノードとシャードの数を変えて、同じテストを実行しました。結果は 1 つの特定のシナリオにのみ適用されるので確定的なものではありませんが、クラスターの水平的スケーラビリティを分析する際に役立つ起点となり、独自の要件を見たシャードとノードの最適な比率に関する値が得られます。

### ベースラインとなる結果 – 3 つのノード

ベースラインとなる値を得るため、5 つのシャードと 1 つのレプリカを含む 3 ノードのクラスターに対してデータ インジェスト パフォーマンスのテストを実行しました。これは、Elasticsearch インデックスの既定の構成です。この構成では、Elasticsearch は 2 つのプライマリ シャードを 2 つのノードに配布し、残りのプライマリ シャードは 3 つ目のノードに格納します。次の表は、1 秒あたりの一括インジェスト操作数でのスループット、およびテストによって正常に保存されたドキュメントの数をまとめたものです。

> [AZURE.NOTE] このセクションの以降の表では、プライマリ シャードの配布を、ハイフンで区切られた各ノードの数として表します。たとえば、5 シャードで 3 ノードのレイアウトは、2-2-1 と記述します。レプリカ シャードのレイアウトは含まれません。レプリカ シャードは、プライマリ シャードと同様の方法で配布されます。

| 構成 | ドキュメント数 | スループット (操作数/秒) | シャードのレイアウト |
|---------------|--------------|-----------------------------|--------------|
| 5 シャード | 200560412 | 27\.86 | 2-2-1 |

### 6 ノードの結果

6 ノードのクラスターでテストを繰り返しました。これらのテストの目的は、1 つのノードに複数のシャードを格納してみて、その効果を正確に確認することでした。

| 構成 | ドキュメント数 | スループット (操作数/秒) | シャードのレイアウト |
|---------------|--------------|-----------------------------|--------------|
| 4 シャード | 227360412 | 31\.58 | 1-1-0-1-1-0 |
| 7 シャード | 268013252 | 37\.22 | 2-1-1-1-1-1 |
| 10 シャード | 258065854 | 35\.84 | 1-2-2-2-1-2 |
| 11 シャード | 279788157 | 38\.86 | 2-2-2-1-2-2 |
| 12 シャード | 257628504 | 35\.78 | 2-2-2-2-2-2 |
| 13 シャード | 300126822 | 41\.68 | 2-2-2-2-2-3 |

これらの結果から、次のような傾向を読み取ることができます。

* ノードあたりのシャードの数が多いほど、スループットが向上します。これらのテストで作成したようにノードごとのシャードの数が少ない場合は、前に説明した理由から、この現象は予想されたことです。

* シャードの数が奇数の場合の方が、偶数の場合よりパフォーマンスが向上します。このようになる理由ははっきりしませんが、*可能性*として考えられるのは、Elasticsearch が使用するルーティング アルゴリズムでは奇数の場合の方がシャード間にデータをよりうまく配布でき、ノードごとの負荷がいっそう均等化されることです。

これらの仮説をテストするため、シャードの数を増やしてさらに何回かテストを実行しました。Elasticsearch からのアドバイスに従い、対象範囲内で妥当な奇数の配布になることから、各テストではシャードの数を素数にしました。

| 構成 | ドキュメント数 | スループット (操作数/秒) | シャードのレイアウト |
|---------------|--------------|-----------------------------|-------------------|
| 23 シャード | 312844185 | 43\.45 | 4-4-4-3-4-4 |
| 31 シャード | 309930777 | 43\.05 | 5-5-5-5-6-5 |
| 43 シャード | 316357076 | 43\.94 | 8-7-7-7-7-7 |
| 61 シャード | 305072556 | 42\.37 | 10-11-10-10-10-10 |
| 91 シャード | 291073519 | 40\.43 | 15-15-16-15-15-15 |
| 119 シャード | 273596325 | 38\.00 | 20-20-20-20-20-19 |

これらの結果では、約 23 シャードで転換点に達したことが示されています。これ以降、シャードの数を増やすと、パフォーマンスがわずかに低下します (43 シャードのスループットはおそらく例外的なものです)。

### 9 ノードの結果

9 ノードのクラスターを使用し、やはり素数個のシャードでテストを繰り返しました。

| 構成 | ドキュメント数 | スループット (操作数/秒) | シャードのレイアウト |
|---------------|--------------|-----------------------------|----------------------------|
| 17 シャード | 325165364 | 45\.16 | 2-2-2-2-2-2-2-2-1 |
| 19 シャード | 331272619 | 46\.01 | 2-2-2-2-2-2-2-2-3 |
| 29 シャード | 349682551 | 48\.57 | 3-3-3-4-3-3-3-4-3 |
| 37 シャード | 352764546 | 49\.00 | 4-4-4-4-4-4-4-4-5 |
| 47 シャード | 343684074 | 47\.73 | 5-5-5-6-5-5-5-6-5 |
| 89 シャード | 336248667 | 46\.70 | 10-10-10-10-10-10-10-10-9 |
| 181 シャード | 297919131 | 41\.38 | 20-20-20-20-20-20-20-20-21 |

これらの結果では同じようなパターンが示され、転換点は約 37 シャードでした。

### スケールアウト: 結論

大まかな推定として、6 ノードと 9 ノードのテストの結果では、この特定のシナリオの場合、n 個のノードでパフォーマンスが最適になるシャードの理想的な数は 4n ± 1 でした。これは、使用可能な一括挿入スレッド数の関数である*可能性があり*、さらに CPU コアの数に依存します。根拠は次のとおりです (詳しくは「[Multidocument Patterns (複数ドキュメントのパターン)](https://www.elastic.co/guide/en/elasticsearch/guide/current/distrib-multi-doc.html#distrib-multi-doc)」を参照)。

- クライアント アプリケーションによって送信される各一括挿入要求は、1 つのデータ ノードによって受信されます。

- データ ノードは、元の要求の影響を受けるプライマリ シャードごとに新しい一括挿入要求を作成し、並列で他のノードに転送します。

- 各プライマリ シャードが書き込まれると、別の要求がそのシャードの各レプリカに送信されます。プライマリ シャードは、レプリカに送信された要求が完了するのを待ってから、終了します。

既定では、Elasticsearch は VM 内の使用可能な CPU コアごとに 1 つの一括挿入スレッドを作成します。このテストで使用した D4 VM の場合、各 CPU は 8 コアなので、8 つの一括挿入スレッドが作成されました。使用したインデックスは各ノードに 4 つ (1 つのケースでは 5 つ) のプライマリ シャードを配置しましたが、レプリカも各ノードに 4 つ (5 つ) ありました。これらのシャードとレプリカにデータを挿入すると、要求ごとに各ノードで最大 8 つのスレッドが消費されますが、これは利用可能な数と一致します。シャードの数を増やしたり減らしたりすると、使用されないスレッドが発生したり、要求がキューに格納されたりするため、スレッドが非効率的になる可能性があります。ただし、これはあくまでも理論上の考えであり、さらに実験を行わないと、確実なことはいえません。

テストでは、もう 1 つの重要なことが示されました。このシナリオでは、ノードの数を増やすとデータ インジェストのスループットは向上しますが、必ずしも直線的ではありません。12 ノードや 15 ノードのクラスターでさらにテストを実施すれば、スケールアウトによるメリットがほとんどなくなるポイントがわかるはずです。その数のノードによって十分なストレージスペースが提供されない場合、スケールアップ戦略に戻り、Premium ストレージでディスクの数やサイズを増やすことが必要になる可能性があります。

> [AZURE.IMPORTANT] 4n ± 1 を、すべてのクラスターで常にうまくいく魔法の公式とは考えないでください。使用可能な CPU コアの数が異なる場合は、最善のシャード構成が異なる可能性があります。これまでに説明した結果は、データ インジェストのみを実行する特定のワークロードに基づくものです。クエリや集計の混合も含まれるワークロードでは、非常に異なる結果になるかもしれません。

> さらに、このデータ インジェスト ワークロードで利用したインデックスは 1 つだけです。多くの状況では、データは複数のインデックスに分散し、パターンやリソースの使用状況も異なります。

> この演習の重要な点は、得られた結果ではなく、使用した方法を理解することです。実際のシナリオに基づく独自のスケーラビリティ評価を実行し、実際のシナリオに最も適した情報を取得する必要があります。

## 大規模なデータ インジェストのチューニング

Elasticsearch はさまざまな構成が可能で、多くのスイッチと特定を使用して特定のユース ケースやシナリオのパフォーマンスを最適化できます。このセクションでは、いくつかの一般的な例について説明します。このような Elasticsearch の柔軟性には注意する必要があります。Elasticsearch のチューニングに失敗してパフォーマンスが悪化することがよくあります。チューニングするときは、一度に 1 つの変更だけを行い、常に変更の影響を測定してシステムに悪影響がないことを確認してください。

### インデックス作成操作用のリソースの最適化

以下では、大規模なデータ インジェストをサポートするために Elasticsearch クラスターをチューニングするときに考慮する必要のあるいくつかの点について説明します。最初の 2 つの項目はパフォーマンスに対してすぐにはっきりとした効果がありますが、他の項目はそれほど明白ではなく、ワークロードに依存します。

*  インデックスに追加された新しいドキュメントは、インデックスが更新されたときにのみ、検索に表示されるようになります。インデックスの更新は負荷の高い操作であり、ドキュメントが作成される都度ではなく、定期的にのみ実行されます。既定の更新間隔は 1 秒です。一括操作を実行する場合は、インデックスの更新を一時的に無効にすることを検討する必要があります。そのためには、インデックスの *refresh\_interval* を -1 に設定します。

	```http
	PUT /my_busy_index
	{
		"settings" : {
			"refresh_interval": -1
		}
	}
	```

	操作の最後に [*\_refresh*](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-refresh.html) API を使用して手動で更新をトリガーし、データが表示されるようにします。詳細については、「[Bulk Indexing Usage (一括インデックス作成の使用法)](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-update-settings.html#bulk)」を参照してください。[更新間隔変更によるデータ インジェストへの影響](#the-impact-of-changing-the-index-refresh-interval-on-data-ingestion-performance)については、後でさらに詳しく説明します。

* インデックスがレプリケートされる場合、各インデックス作成操作 (ドキュメントの作成、更新、削除) は、プライマリ シャードで発生するとレプリカ シャードで繰り返されます。一括インポート操作中はレプリケーションを無効化し、インポート完了後に再度有効にします。

    ```http
	PUT /my_busy_index
	{
		"settings" : {
			"number_of_replicas": 0
		}
	}
	```

	レプリケーションを再度有効にすると、Elasticsearch はインデックスから各レプリカにデータをバイト単位でネットワーク転送します。これは、各ノード上でドキュメントごとにインデックス作成操作を繰り返すよりも効率的です。一括インポートの実行中にプライマリ ノードで障害が発生するとデータが失われるリスクがありますが、インポートを再度開始するだけで回復できます。[レプリケーションによるデータ インジェストのパフォーマンスへの影響](#the-impact-of-replicas-on-data-ingestion-performance)については、後でさらに詳しく説明します。

* Elasticsearch は、クエリの実行に必要なリソースとデータのインジェストに必要なリソースのバランスを取ろうとします。その結果、データ インジェストのパフォーマンスが抑えられることがあります (スロットル イベントは Elasticsearch ログに記録されます)。この制限は、マージおよびディスクへの保存を必要とするインデックス セグメントが同時に多数作成されるのを防ぐためです。この処理は、リソースを独占する可能性があります。システムが現在クエリを実行していない場合は、データ インジェストのスロットルを無効にできます。これにより、インデックス作成のパフォーマンスを最大にできます。クラスター全体のスロットルは次のようにして無効にできます。

	```http
	PUT /_cluster/settings
	{
		"transient" : {
			"indices.store.throttle.type": "none"
		}
	}
	```

    インジェストが完了したら、クラスターのスロットルの種類を *"merge"* に戻します。スロットルを無効にするとクラスターが不安定になる場合があることにも注意してください。必要な場合にクラスターを回復できる手順を設けておいてください。

* Elasticsearch は、ヒープ メモリの一定の割合をインデックス作成操作用に確保します。残りの部分は、主にクエリと検索で使用されます。このようなバッファーの目的は、多数の小さい書き込みを実行するより、少数の大きい書き込みを実行することで、ディスク I/O 操作の数を減らすことです。割り当てられるヒープ メモリの既定の割合は、10% です。大量のデータのインデックスを作成する場合、この値では十分ではない可能性があります。大量のデータ インジェストをサポートするシステムでは、ノード内のアクティブな各シャードに対して最大 512 MB のメモリを許可する必要があります。たとえば、D4 VM (28 GB RAM) で Elasticsearch を実行していて、使用可能なメモリの 50% を JVM (14 GB) に割り当てた場合、インデックス作成操作では 1.4 GB を使用できます。ノードに含まれるアクティブなシャードが 3 つの場合は、この構成でおそらく十分でしょう。しかし、ノードに含まれるシャードがそれより多い場合は、elasticsearch.yml 構成ファイルで *indices.memory.index\_buffer\_size* パラメーターの値を大きくすることを検討します。詳細については、「[Performance Considerations for Elasticsearch Indexing (Elasticsearch のインデックス作成でのパフォーマンスに関する考慮事項)](https://www.elastic.co/blog/performance-considerations-elasticsearch-indexing)」を参照してください。

    アクティブなシャードへの割り当てを 512 MB より多くしても、インデックス作成のパフォーマンスが向上することはほとんどなく、実際には他のタスクの実行に使用できるメモリが減ることによる弊害があります。また、インデックス バッファーに割り当てるヒープ領域を増やすと、データの検索や集計などの他の操作用のメモリが減り、クエリ操作のパフォーマンスが低下する可能性があることにも留意してください。

* Elasticsearch は、シャードでインデックス作成操作を同時に実行できるスレッドの数を制限しています (既定値は 8)。ノードに少数のシャードしか含まれていない場合は、大量のインデックス作成操作の対象になるインデックスまたは一括挿入の対象であるインデックスの *index\_concurrency* の設定を、次のように大きくすることを検討します。

	```http
	PUT /my_busy_index
	{
		"settings" : {
			"index_concurrency": 20
		}
	}
	```

* 多数のインデックス作成および一括操作を短時間で実行する場合は、スレッド プールで使用可能な*インデックス* スレッドと*一括*スレッドの数を増やし、各データ ノードの*一括挿入*キューのサイズを大きくすることができます。このようにすれば、破棄されずにキューに登録される要求を増やすことができます。詳細については、「[Thread Pool (スレッド プール)](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-threadpool.html)」を参照してください。持続的に高レベルのデータ インジェストを実行している場合は、一括スレッドの数を増やすことはお勧めできません。代わりに、ノードを追加作成し、シャーディングを使用してこれらのノードにインデックス作成の負荷を分散します。または、一括挿入のバッチをパラレルではなくシリアルに送信することを検討してください。これは自然なスロットル メカニズムとして機能し、一括挿入キューのオーバーフローによるエラーの可能性を減らすことができます。

### インデックス更新間隔変更のデータ インジェスト パフォーマンスに対する影響

更新間隔はインジェストされたデータがクエリおよび集計で使用されるようになるまでの時間を左右しますが、頻繁に更新するとデータ インジェスト操作のパフォーマンスに影響を与える可能性があります。既定の更新間隔は 1 秒です。更新を完全に無効にできますが、ワークロードに対して適切ではない場合があります。さまざまな間隔を試し、インジェストのパフォーマンスと最新の情報が提供される必要性のバランスが取れたスイート スポットを見つけてください。

影響の例として、7 つのシャードが 3 つのデータ ノードに分散された Elasticsearch クラスターでデータ インジェスト パフォーマンスのテストを繰り返しました。インデックスにはレプリカが 1 つありました。各データ ノードは D4 VM (28 GB RAM、8 プロセッサ コア) で、SSD の短期ストレージを使用してデータを保持しました。各テストを 1 時間実行しました。

このテストでは、更新間隔を既定値の 1 秒に設定しました。次の表では、このテストと、更新間隔を 30 秒に 1 回に減らした場合の、スループットと応答時間を比較して示します。

| 更新間隔 | サンプル数 | 平均応答時間 – 正常動作 (ミリ秒) | スループット – 正常動作 (操作/秒) |
|--------------|------------|----------------------------------------------------|---------------------------------------------------|
| 1 秒 | 93755 | 460 | 26\.0 |
| 30 秒 | 117758 | 365 | 32\.7 |

このテストでは、更新間隔を長くすると、スループットが 18% 向上し、平均応答時間が 21% 短縮されました。Marvel で生成された次のグラフでは、この違いの主な理由が示されています。次の図には、更新間隔を 1 秒に設定した場合と 30 秒に設定した場合に生じたインデックス マージ アクティビティが示されています。

インデックスのマージは、メモリ内のインデックス セグメントの数が多くなりすぎないようにするために実行されます。更新間隔が 1 秒では頻繁にマージする必要のある小さいセグメントが多数生成されるのに対し、更新間隔が 30 秒のときは少数の大きいセグメントが生成されて、マージがいっそう最適化されます。

![](media/guidance-elasticsearch/data-ingestion-image15.png)

***インデックス更新間隔が 1 秒の場合のインデックス マージ アクティビティ***

![](media/guidance-elasticsearch/data-ingestion-image16.png)

***インデックス更新間隔が 30 秒の場合のインデックス マージ アクティビティ***

### データ インジェスト パフォーマンスに対するレプリカの影響

レプリカは回復力のあるクラスターに不可欠な機能であり、レプリカを使わないとノードの障害時に情報が失われる可能性があります。ただし、レプリカを使用すると実行されるディスクおよびネットワーク I/O の量が増え、データ インジェスト速度が低下する場合があります。前に説明した理由から、大規模なデータ アップロード操作の間はレプリカを一時的に無効にするとメリットがある場合があります。

3 つの構成を使用してデータ インジェスト パフォーマンスのテストを繰り返しました。

* レプリカなしのクラスターを使用

* レプリカが 1 つのクラスターを使用

* レプリカが 2 つのクラスターを使用

いずれの場合も、クラスターは 3 つのノードに分散した 7 つのシャードで構成され、前のテストで説明した VM 構成で実行しました。テスト インデックスでは 30 秒の更新間隔を使用しました。

次の表では、比較のため各テストの応答時間とスループットをまとめて示します。

| 構成 | サンプル数 | 平均応答時間 – 正常動作 (ミリ秒) | スループット – 正常動作 (操作/秒) | データ インジェスト エラー数 |
|---------------|------------|----------------------------------------------------|---------------------------------------------------|--------------------------|
| レプリカなし | 215451 | 200 | 59\.8 | 0 |
| 1 つのレプリカ | 117758 | 365 | 32\.7 | 0 |
| 2 つのレプリカ | 94218 | 453 | 26\.1 | 194262 |


レプリカの数が増えたときのパフォーマンスの低下は明らかですが、3 番目のテストで大量のデータ インジェスト エラーが発生していることにも注目する必要があります。これらのエラーによって生成されたメッセージでは、一括挿入キューのオーバーフローによる要求の拒否が原因であることが示されていました。このような拒否は、非常に頻繁に発生したため、数が増えました。

> [AZURE.NOTE] 3 番目のテストの結果では、このような一時的エラーが発生したときのインテリジェントな再試行戦略の重要性が強調されています。つまり、しばらく速度を落として一括挿入キューを空けてから、一括挿入操作を繰り返します。

次の一連のグラフでは、テスト中に応答時間の比較を示します。いずれの場合も、最初のグラフでは全体的な応答時間を示し、2 番目のグラフでは最も速い操作の応答時間を拡大して示してあります (最初のグラフのスケールが 2 番目のグラフの 10 倍であることに注意してください)。3 つのテストで応答時間の概略がどのように異なるかがわかります。

レプリカがない場合、ほとんどの操作は 75 ～ 750 ミリ秒の間で発生し、最も速い応答時間は約 25 ミリ秒でした。

![](media/guidance-elasticsearch/data-ingestion-image17.png)

レプリカが 1 つの場合は、応答時間が最も多かったのは 125 ～ 1250 ミリ秒の範囲でした。最速の応答は約 75 ミリ秒でしたが、その件数はレプリカがない場合より減りました。最も一般的な場合より大幅に長い時間 (1250 ミリ秒超) を要した応答も増えました。

![](media/guidance-elasticsearch/data-ingestion-image18.png)

レプリカが 2 つの場合は、最も多かった応答時間の範囲は 200 ～ 1500 ミリ秒でしたが、最少範囲以下の結果の数は 1 レプリカのテストよりはるかに少なくなりました。ただし、上限を超える結果のパターンは、1 レプリカのテストとよく似ていました。これはおそらく、一括挿入キューのオーバーフロー (50 要求のキュー長を超えた場合) の影響です。2 つのレプリカを維持するために必要な追加処理により、キュー オーバーフローの発生頻度が上昇し、インジェスト操作の応答時間が長くなるのを妨げています。操作は長引くことなく短時間で拒否され、タイムアウト例外やクライアント アプリケーションの応答性への影響の原因になっている可能性があります (これは、一括挿入キュー メカニズムの目的です)。

![](media/guidance-elasticsearch/data-ingestion-image19.png)

<span id="_The_Impact_of_1" class="anchor"><span id="_Impact_of_Increasing" class="anchor"></span></span>Marvel を使用して、一括インデックス キューに対するレプリカの数の影響を確認できます。次の図に示す Marvel のデータでは、テストの間に一括挿入キューが埋まる様子が示されています。キューの平均長は約 40 要求ですが、定期的な急増のためにオーバーフローし、その結果として要求が拒否されました。

![](media/guidance-elasticsearch/data-ingestion-image20.png)

***レプリカが 2 つの場合の、一括インデックス キューのサイズと拒否された要求の数。***

これを、次の図に示すレプリカが 1 つの場合の結果と比較してください。Elasticsearch エンジンは十分に速く要求を処理できており、キューの平均長は約 25 に保たれ、キューの長さが 50 要求を超えたことはないため、拒否された要求はありません。

![](media/guidance-elasticsearch/data-ingestion-image21.png)

***レプリカが 1 つの場合の、一括インデックス キューのサイズと拒否された要求の数。***

## Elasticsearch にデータを送信するクライアントのベスト プラクティス

パフォーマンスの多くの側面は、システム内部だけでなく、クライアント アプリケーションによるシステムの使用方法にも関係しています。Elasticsearch には、データ インジェスト プロセスで利用できる多くの機能が用意されています。ドキュメントに対する一意の識別子の生成、ドキュメントの分析の実行、データ格納時のスクリプトによるデータの変換などです。ただし、これらの機能はすべて Elasticsearch エンジンに負荷をかけることになり、多くの場合、送信前にクライアント アプリケーションによっていっそう効率よく実行できます。

> [AZURE.NOTE] このベスト プラクティスの一覧は、主として、インデックスに既に格納されている既存データの変更ではなく、新しいデータのインジェストに関するものです。インジェスト ワークロードが Elasticsearch により追加操作として実行されるのに対し、データの変更は削除/追加操作として実行されます。これは、インデックス内のドキュメントは変更できないので、ドキュメントを変更する場合はドキュメント全体を新しいバージョンに置き換えるためです。HTTP PUT 要求を実行して既存のドキュメントを上書きできます。また、Elasticsearch の *update* API を使用できます。この API により、既存のドキュメントをフェッチするクエリを抽象化し、変更をマージした後、PUT を実行して新しいドキュメントを格納します。

さらに、必要に応じて以下の手段を実装することを検討してください。

* 分析する必要のないインデックス フィールドのテキスト分析を無効にします。分析には、特定の用語を検索できるクエリを有効にするためのテキストのトークン化が含まれます。ただし、CPU 負荷の高い作業であるため、選択できるようになっています。Elasticsearch を使用してログ データを格納している場合、詳細なログ メッセージをトークン化して複雑な検索を実行できるようにすると役に立つことがあります。エラー コードや識別子などを含む他のフィールドは、通常はトークン化する必要はありません (たとえば、エラー コードに "3" が含まれるすべてのメッセージの詳細を要求することがどれくらいありますか)。 次のコードは、*systembase* インデックスの *logs* 型の *name* フィールドと *hostip* フィールドの分析を無効にしています。

	```http
	PUT /systembase
	{
		"settings" : {
			...
		},
		"logs" : {
			...
			"name": {
				"type": "string",
				"index" : "not_analyzed"
			},
			"hostip": {
				"type": "string",
				"index" : "not_analyzed"
			},
			...
		}
	}
	```

* 必要ない場合は、インデックスの *\_all* フィールドを無効にします。*\_all* フィールドは、分析とインデックス作成のためにドキュメントの他のフィールドの値を連結しています。ドキュメントの任意のフィールドと一致するクエリを実行する場合は便利です。クライアントが名前付きフィールドとの照合を望む場合、*\_all* を有効にすると CPU とストレージのオーバーヘッドが増えるだけです。次の例では、*systembase* インデックスの *logs* 型の *\_all* フィールドを無効にする方法を示します。

	```http
	PUT /systembase
	{
		"settings" : {
			...
		},
		"logs" : {
			"_all": {
				"enabled" : false
			},
			...,
		...
		}
	}
	```

    特定のフィールドの情報だけを含む *\_all* の選択バージョンを作成できることに注意してください。詳細については、「[Disabling the \_all Field (\_all フィールドの無効化)](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-all-field.html#disabling-all-field)」を参照してください。

* インデックスの動的マッピングを行わないようにします。動的マッピングは強力な機能ですが、既存のインデックスに新しいフィールドを追加するには、ノード間でインデックス構造の変更を調整する必要があり、一時的にインデックスがロックされる場合があります。また、慎重に使用しないと、動的マッピングによってフィールドの数が急増し、結果としてインデックス メタデータの量が増える可能性があります。また、これにより、データのインジェストとクエリ実行の両方の場合の、ストレージ要件と I/O が増加します。これらの問題はどちらもパフォーマンスに影響します。動的マッピングを無効にし、インデックス構造を明示的に定義することを検討します。詳細については、「[Dynamic Field Mapping (動的フィールド マッピング)](https://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-field-mapping.html#dynamic-field-mapping)」を参照してください。

* 競合する要件を満たすようにワークロードのバランスを調整する方法を理解します。データのインジェストは同時に行われているクエリなどの他の操作のパフォーマンスに大きな影響を与える可能性があることを常に考慮する必要があります。データ インジェストは急増することがあり、システムが到着したすべてのデータをすぐに使用しようとすると、流入によってクエリ速度が低下する場合があります。Elasticsearch は、一括挿入キューを使用してインジェスト要求の処理速度を調整することにより、このような状況の発生を防ごうとします (詳しくは「[制限要因の特定: CPU 使用率](#determining-limiting-factors-cpu-utilization)」を参照)。ただし、このメカニズムは最後の手段と考える必要があります。アプリケーション コードが拒否された要求の処理に対応していないと、データが失われるおそれがあります。代わりに、[キュー ベースの負荷の平均化](https://msdn.microsoft.com/library/dn589783.aspx)などのパターンを使用して、データが Elasticsearch に渡される速度を制御することを検討します。

* ワークロードの処理に十分なリソースがクラスターにあることを確認します (特に、インデックスが複数のレプリカで構成される場合)。

* ドキュメントの大きなバッチをアップロードするには、一括挿入 API を使用します。一括要求のサイズを適切に設定します。場合によっては、大きいバッチはパフォーマンスに悪影響を及ぼし、Elasticsearch のスレッドや他のリソースが過負荷になって、他の同時操作を遅らせる可能性があります。一括挿入バッチのドキュメントは、操作が実行されている間、調整ノードのメモリに保持されます。重要なのは、ドキュメントの数より各バッチの物理サイズです。理想的なバッチ サイズの構成要素に関する厳格なルールはありませんが、Elasticsearch のドキュメントでは、調査の手始めとして 5 ～ 15 MB を使用することが推奨されています。パフォーマンス テストを実施し、実際のシナリオとワークロードの組み合わせに最適なバッチ サイズを確認してください。

* 一括挿入要求が単一のノードに送られるのではなく複数のノードに分散されていることを確認します。処理される各一括挿入要求はノードのメモリに格納されるので、すべての要求を 1 つのノードに送ると、メモリが不足する可能性があります。また、要求は他のノードにリダイレクトされるので、ネットワーク遅延も増加します。

* Elasticsearch は、データを書き込むときに、プライマリとレプリカのノードの大多数で構成されるクォーラムを使用します。クォーラムが成功を報告するまで、書き込み操作は完了しません。この方法は、ネットワーク パーティション (失敗) イベントのためにノードの大部分が使用できない場合に、データが書き込まれないようにするのに役立ちます。クォーラムを使用すると、書き込み操作のパフォーマンスが低下することがあります。データを書き込むときに *consistency* パラメーターを *one* に設定することで、クォーラム ベースの書き込みを無効にできます。次の例は、新しいドキュメントを追加しますが、プライマリ シャードへの書き込みが完了するとすぐに完了します。

	```http
	PUT /my_index/my_data/104?consistency=one
	{
		"name": "Bert",
		"age": 23
	}
	```

	非同期レプリケーションと同様に、クォーラム ベースの書き込みを無効にすると、プライマリ シャードと各レプリカの整合性が失われる可能性があることに注意してください。

* クォーラムを使用すると、Elasticsearch は、クォーラムに達しないために書き込み操作の中止を決定する前に、十分なノードを使用できない場合は待機します。この待機時間は、タイムアウト クエリ パラメーターによって決まります (既定値は 1 分)。タイムアウト クエリ パラメーターを使用してこの設定を変更できます。次の例では、新しいドキュメントを作成し、クォーラムが応答するのを最大 5 秒待ってから中止します。

	```http
	PUT /my_index/my_data/104?timeout=5s
	{
		"name": "Sid",
		"age": 27
	}
	```

	Elasticsearch では、ユーザーは、[外部で生成した](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.html#_version_types)独自のバージョン番号を使用することもできます。

* インデックスの *\_source* フィールドの無効化を検討します。このフィールドには、ドキュメントの格納時に使用された元の JSON ドキュメントのコピーが含まれます。このフィールドを保存すると、ストレージ コストとディスク I/O が増えます。ただし、これらのコストはドキュメントの構造によってはほとんどないこともあり、また、*\_source* フィールドを無効にするとクライアントで次の操作を実行できなくなることに留意する必要もあります。

	* Update API を使用したドキュメントの変更。
	* クエリ実行時の即時強調表示の実行。
	* データのインデックス再作成。
	* 元のドキュメントを表示することによるクエリおよび集計のデバッグ。

	次の例では、*systembase* インデックスの *logs* 型の *\_source* フィールドを無効にしています。

  ```http
  PUT /systembase
  {
		"settings" : {
			...
		},
		"logs" : {
			"_source": {
				"enabled": false
			},
			...,
		...
		}
  }
  ```

## Elasticsearch でデータ インジェストのパフォーマンス テストを実施するときの一般的なガイドライン

以下では、Elasticsearch でパフォーマンス テストを実行して結果を分析するときに考慮する必要がある事項について説明します。

* パフォーマンス テストはどうしても時間とコストがかかります。少なくとも、ディスクとネットワークの転送速度、CPU 使用率、CPU 待機時間、およびディスクの待ち時間 (可能な場合) を測定する統計情報を収集します。これにより、テスト作業へのすばやいフィードバックが得られて、投資を回収できます。

* ロード テスト ツールが提供するスクリプト機能を利用して、他の方法では入手できないメトリックを収集します。たとえば、Linux には、*vmstat* や *iostat* などのユーティリティを使用して収集できる、信頼性が高く優れたパフォーマンス統計情報が数多くあります。JMeter でスクリプトを使用して、テスト計画の一環としてこのデータをキャプチャできます。

* パフォーマンス エンジニアリングの中心となるのは、信頼できて反復可能なデータに基づく統計情報の分析です。必要な洞察を得られない上位レベルのメトリックで終わらせないでください。データについて学習し、パフォーマンス エンジニアリングを迅速なフィードバック ループを備えた開発操作プロセスにします。常に統計情報を調べて、傾向や過去の結果/構成と比較します。これを定期的に行うことで、理解できるデータをワークロードで繰り返し生成し、それを使用して構成およびデプロイメントでの変更の影響を評価できます。

* Marvel などのツールを使用して、テストで新しい洞察を獲得しながら、クラスターやノードのパフォーマンスを監視します。JMeter も後の分析に役立つ生データの取得に有効ですが、Marvel を使用すると、パフォーマンスおよび異常や速度低下の原因に関する情報をリアルタイムで得られます。さらに、多くのロード テスト ツールでは、Elasticsearch の内部メトリックを確認できません。インデックスの統計情報で得られるインデックス作成のスループット速度、マージ セグメント カウント、GC 統計、スロットル時間を使用して比較します。定期的にこの分析を繰り返します。

* ロード テスト ツールの統計情報と Marvel のノード統計 (ディスクおよびネットワークのトラフィック、CPU 使用率、メモリ、スレッド プール使用率) を比較し、インフラストラクチャと特定の Elasticsearch 統計で報告される値の間の相関パターンを理解します。

* 一般的な規則として、*1 ノード/1 シャード*をパフォーマンス テストの基準と考え、ノードを追加してアプリケーションのコストを評価します。ただし、少数のノードとシャードを基にしたパフォーマンスの推定に完全に依存しないでください。ノードおよびシャードの数が多くなるほど、クラスターでの同期と通信のコストに予期しない影響があります。

* ノード間のシャードの割り当てを調べて、統計情報を比較します。一部のノードのレプリカとシャードの数が少ないと、リソースの使用率が不均衡になります。

* 負荷テストを実行する場合は、テスト ツールが使用するスレッドの数を増やしながら、エラーが発生するまでクラスターに作業を送信します。維持可能なスループットのテストでは、テスト レベルを合意された*目に見えない障壁*より低く保ちます。エラー率が見えない障壁を超えた場合、回復性のためのエラーによってバックエンド リソースに費用が発生します。このような場合、スループットは必然的に低下します。

* 予期しない大きさのアクティビティ急増に対するシステムの反応をシミュレートするには、エラー率の見えない障壁までエラー率を生成するテストを実行します。これにより、容量だけでなく回復性のコストに関するスループット値も得られます。

* ドキュメント数を使用してパフォーマンス プロファイルを評価し、ワークロード パターンに従ってドキュメントをリサイクルします。ドキュメントが増えるとパフォーマンス プロファイルが変化する可能性があることを考慮します。

* 使用しているストレージの IOPS に対する SLA と転送速度の制限について注意してください。ストレージの種類 (SSD、スピン メディア) が異なると、転送速度も異なります。

* CPU のパフォーマンスは、ディスクとネットワークのアクティビティだけでなく、バックエンド アプリケーションによるプロセッサの過小使用をもたらす分散処理でのロックと通信メカニズムの使用によっても低下する可能性があることに注意してください。

* 数分ではなく、少なくとも 2 時間はパフォーマンス テストを実行します。インデックス作成によるパフォーマンスへの影響は、すぐにはわからない場合があります。たとえば、JVM ガベージ コレクションの統計とインデックス作成のマージは、時間の経過と共にパフォーマンス プロファイルを変化させることがあります。

* クラスターでのデータ インジェストのスループットとスロットルに対するインデックス更新の大きな影響を考慮してください。

## 概要

データ量と要求数が増加したときのソリューションの拡張方法を理解しておくことが重要です。Azure で Elasticsearch を実行すると、垂直方向と水平方向のスケーリングが可能です。多くのリソースを備えた大きな VM で実行したり、Elasticsearch クラスターを VM のネットワークに分散させたりできます。非常に広範なオプションがあります。コスト効果が高いのは、多数の小さい VM、少数の大きい VM、その中間のどれにクラスターを実装した場合でしょうか。 また、各インデックスはいくつのシャードを含む必要があり、データ インジェストとクエリ パフォーマンスの間にはどのようなトレードオフがあるでしょうか。 ノードにシャードを分散させる方法は、データ インジェストのスループットに大きな影響を与える可能性があります。シャードを増やすとシャード内で発生する内部競合は減りますが、このメリットと、多数のシャードを使用するとクラスターにかかるオーバーヘッドのバランスを考慮する必要があります。これらの質問に効果的に答えるには、システムのテストを行って最も適切な戦略を決定する必要があります。

データ インジェストのワークロードの場合、ディスク I/O サブシステムのパフォーマンスが重要な要因です。SSD を使用すると、書き込み操作のディスク待ち時間が減って、スループットが向上します。ノードで大量のディスク領域が必要ない場合は、Premium ストレージをサポートする高価な VM の代わりに、短期ストレージを備えた Standard VM の使用を検討してください。

## 付録: 一括ロード データ インジェストのパフォーマンス テスト

この付録では、Elasticsearch クラスターに対して実行されたパフォーマンス テストについて説明します。このテストは、独立した一連の VM で実行する JMeter を使用して実行されました。テスト環境の構成の詳細については、「[Creating a Performance Testing Environment for Elasticsearch on Azure (Azure での Elasticsearch 用のパフォーマンス テスト環境の作成)][]」を参照してください。独自のテストを実行するには、JMeter テスト計画を手動で作成するか、または別に使用可能な自動テスト スクリプトを使用できます。詳細については、「[Running the Automated Elasticsearch Performance Tests (自動化された Elasticsearch パフォーマンス テストの実行)][]」を参照してください。

データ インジェストのワークロードでは、一括挿入 API を使用してドキュメントの大規模なアップロードを実行しました。このインデックスの目的は、以降の検索と分析のためにシステム イベントを表すログ データを受信するリポジトリをシミュレートすることでした。各ドキュメントは、*logs* 型の *systembase* という名前の単一のインデックスに格納されました。すべてのドキュメントでは、次の表で説明する同じ固定スキーマを使用しました。

| フィールド | データ型 | 例 |
|---------------|---------------------|-----------------------------------|
| @timestamp | datetime | 2013-12-11T08:01:45.000Z |
| name | string | checkout.payment |
| message | string | 着信要求メッセージ |
| severityCode | integer | 1 |
| severity | string | info |
| hostname | string | sixshot |
| hostip | string (IP アドレス) | 10\.0.0.4 |
| pid | int | 123 |
| tid | int | 4325 |
| appId | string (UUID) | {00000000-0000-0000-000000000000} |
| appName | string | mytestapp |
| appVersion | string | 0\.1.0.1234 |
| type | int | 5 |
| subtype | int | 1 |
| correlationId | guid | {00000000-0000-0000-000000000000} |
| OS | string | Linux |
| osVersion | string | 4\.1.1 |
| parameters | [ ] | {key:value,key:value} |

次の要求を使用してインデックスを作成できます。*number\_of\_replicas*、*refresh\_interval*、*number\_of\_shards* の設定は、多くのテストで次に示す値とは異なりました。

> [AZURE.IMPORTANT] 各テストを実行する前に、インデックスを削除して再作成しました。

```http
PUT /systembase
{
	"settings" : {
		"number_of_replicas": 1,
		"refresh_interval": "30s",
		"number_of_shards": "5"
	},
	"logs" : {
		"properties" : {
			"@timestamp": {
			"type": "date",
			"index" : "not_analyzed"
			},
			"name": {
				"type": "string",
				"index" : "not_analyzed"
			},
			"message": {
				"type": "string",
				"index" : "not_analyzed"
			},
			"severityCode": {
				"type": "integer",
				"index" : "not_analyzed"
			},
			"severity": {
				"type": "string",
				"index" : "not_analyzed"
			},
			"hostname": {
				"type": "string",
				"index" : "not_analyzed"
			},
			"hostip": {
				"type": "string",
				"index" : "not_analyzed"
			},
			"pid": {
				"type": "integer",
				"index" : "not_analyzed"
			},
			"tid": {
				"type": "integer",
				"index" : "not_analyzed"
			},
			"appId": {
				"type": "string",
				"index" : "not_analyzed"
			},
			"appName": {
				"type": "string",
				"index" : "not_analyzed"
			},
			"appVersion": {
				"type": "integer",
				"index" : "not_analyzed"
			},
			"type": {
				"type": "integer",
				"index" : "not_analyzed"
			},
			"subtype": {
				"type": "integer",
				"index" : "not_analyzed"
			},
			"correlationId": {
				"type": "string",
				"index" : "not_analyzed"
			},
			"os": {
				"type": "string",
				"index" : "not_analyzed"
			},
			"osVersion": {
				"type": "string",
				"index" : "not_analyzed"
			},
			"parameters": {
				"type": "string",     
				"index" : "not_analyzed"
			}
		}
	}
}
```

各一括挿入バッチには、1000 個のドキュメントが含まれました。各ドキュメントは、*severityCode*、*hostname*、*hostip*、*pid*、*tid*、*appName*、*appVersion*、*type*、*subtype*、*correlationId* フィールドのランダムな値と、*name*、*message*、*severity*、*os*、*osVersion*、*parameters*、*data1*、*data2* フィールドの固定用語セットからのランダムなテキスト選択の組み合わせに基づいて生成されました。データのアップロードに使用されたクライアント アプリケーション インスタンスの数は、正常な入力ボリュームが最大になるように慎重に選択されました。クラスターが安定し、全体的な結果における一時的な異常の影響が減るように、テストは 2 時間実行されました。この時点で、いくつかのテストは、ほぼ 15 億個のドキュメントをアップロードしました。

データは、JMeter テスト計画のスレッド グループに追加されたカスタム JUnit Request サンプラーを使用して動的に生成されました。JUnit コードは、Eclipse IDE で JUnit Test Case テンプレートを使用して作成されました。

> [AZURE.NOTE] JMeter 用の JUnit テストの作成方法については、「[Deploying a JMeter JUnit Sampler for Testing Elasticsearch Performance (Elasticsearch のパフォーマンスをテストするための JMeter JUnit サンプラーをデプロイする)][]」を参照してください。

次のスニペットでは、Elasticsearch 1.7.3 をテストするための Java コードを示します。この例の JUnit テスト クラスの名前が *ElasticsearchLoadTest2* であることに注意してください。

```java
/* Java */
package elasticsearchtest2;

	import static org.junit.Assert.*;

	import org.junit.*;

	import java.util.*;

	import java.io.*;

	import org.elasticsearch.action.bulk.*;
	import org.elasticsearch.common.transport.*;
	import org.elasticsearch.client.transport.*;
	import org.elasticsearch.common.settings.*;
	import org.elasticsearch.common.xcontent.*;

	public class ElasticsearchLoadTest2 {

		private String [] names={"checkout","order","search","payment"};
		private String [] messages={"Incoming request from code","incoming operation succeeded with code","Operation completed time","transaction performed"};
		private String [] severity={"info","warning","transaction","verbose"};
		private String [] apps={"4D24BD62-20BF-4D74-B6DC-31313ABADB82","5D24BD62-20BF-4D74-B6DC-31313ABADB82","6D24BD62-20BF-4D74-B6DC-31313ABADB82","7D24BD62-20BF-4D74-B6DC-31313ABADB82"};

		private String hostname = "";
		private String indexstr = "";
		private String typestr = "";
		private int port = 0;
		private int itemsPerInsert = 0;
		private String clustername = "";
		private static Random rand=new Random();

		@Before
		public void setUp() throws Exception {
		}

		public ElasticsearchLoadTest2(String paras) {
		* Paras is a string containing a set of comma separated values for:
			hostname
			indexstr
			typestr
			port
			clustername
			node
			itemsPerInsert
		*/

			// Note: No checking/validation is performed

			String delims = "[ ]*,[ ]*"; // comma surrounded by zero or more spaces
			String[] items = paras.split(delims);

			hostname = items[0];
			indexstr = items[1];
			typestr = items[2];
			port = Integer.parseInt(items[3]);
			clustername = items[4];
			itemsPerInsert = Integer.parseInt(items[5]);

			if (itemsPerInsert == 0)
				itemsPerInsert = 1000;
			}

		@After
		public void tearDown() throws Exception {
		}

		@Test
		public void BulkBigInsertTest() throws IOException {

			Settings settings = ImmutableSettings.settingsBuilder().put("cluster.name", clustername).build();

			TransportClient client;
			client = new TransportClient(settings);

			try {
				client.addTransportAddress(new InetSocketTransportAddress(hostname, port));
				BulkRequestBuilder bulkRequest = client.prepareBulk();
				Random random = new Random();
				char[] exmarks = new char[12000];
				Arrays.fill(exmarks, 'x');
				String dataString = new String(exmarks);

				for(int i=1; i &lt; itemsPerInsert; i++){
					random.nextInt(10);
					int host=random.nextInt(20);

					bulkRequest.add(client.prepareIndex(indexstr, typestr).setSource(XContentFactory.jsonBuilder().startObject()
						.field("@timestamp", new Date())
						.field("name", names[random.nextInt(names.length)])
						.field("message", messages[random.nextInt(messages.length)])
						.field("severityCode", random.nextInt(10))
						.field("severity", severity[random.nextInt(severity.length)])
						.field("hostname", "Hostname"+host)
						.field("hostip", "10.1.0."+host)
						.field("pid",random.nextInt(10))
						.field("tid",random.nextInt(10))
						.field("appId", apps[random.nextInt(apps.length)])
						.field("appName", "application" + host)
						.field("appVersion", random.nextInt(5))
						.field("type", random.nextInt(6))
						.field("subtype", random.nextInt(6))
						.field("correlationId", UUID.randomUUID().toString())
						.field("os", "linux")
						.field("osVersion", "14.1.5")
						.field("parameters", "{key:value,key:value}")
						.field("data1",dataString)
						.field("data2",dataString)
					.endObject()));
				}

				BulkResponse bulkResponse = bulkRequest.execute().actionGet();
				assertFalse(bulkResponse.hasFailures());
			}
			finally {
				client.close();
			}
		}

		@Test
		public void BulkDataInsertTest() throws IOException {
			Settings settings = ImmutableSettings.settingsBuilder().put("cluster.name", clustername).build();

			TransportClient client;
			client = new TransportClient(settings);

			try {
				client.addTransportAddress(new InetSocketTransportAddress(hostname, port));
				BulkRequestBuilder bulkRequest = client.prepareBulk();

				for(int i=1; i&lt; itemsPerInsert; i++){
					rand.nextInt(10);
					int host=rand.nextInt(20);

					bulkRequest.add(client.prepareIndex(indexstr, typestr).setSource(XContentFactory.jsonBuilder().startObject()
						.field("@timestamp", new Date())
						.field("name", names[rand.nextInt(names.length)])
						.field("message", messages[rand.nextInt(messages.length)])
						.field("severityCode", rand.nextInt(10))
						.field("severity", severity[rand.nextInt(severity.length)])
						.field("hostname", "Hostname" + host)
						.field("hostip", "10.1.0."+host)
						.field("pid",rand.nextInt(10))
						.field("tid",rand.nextInt(10))
						.field("appId", apps[rand.nextInt(apps.length)])
						.field("appName", "application"+host)
						.field("appVersion", rand.nextInt(5))
						.field("type", rand.nextInt(6))
						.field("subtype", rand.nextInt(6))
						.field("correlationId", UUID.randomUUID().toString())
						.field("os", "linux")
						.field("osVersion", "14.1.5")
						.field("parameters", "{key:value,key:value}")
					.endObject()));
				}

				BulkResponse bulkResponse = bulkRequest.execute().actionGet();
				assertFalse(bulkResponse.hasFailures());
			}
			finally {
				client.close();
			}
		}
	}
```

private *String* の配列 *names*、*messages*、*severity*、*apps* には、そこから項目がランダムに選択される少数の値が含まれます。各ドキュメントの残りのデータ項目は、実行時に生成されます。

*String* パラメーターを受け取るコンストラクターは JMeter から呼び出され、文字列で渡される値は JUnit Request サンプラー構成の一部として指定されます。この JUnit テストでは、*String* パラメーターには次の情報が含まれることが想定されます。

* **Hostname**。これは、Azure Load Balancer の名前または IP アドレスです。Load Balancer は、クラスター内のデータ ノードに要求を分配します。Load Balancer を使用しない場合は、クラスターでノードのアドレスを指定できますが、すべての要求がそのノードに送信されて、ボトルネックになる可能性があります。

* **Indexstr**。JUnit テストによって生成されたデータが追加されるインデックスの名前です。前述のようにインデックスを作成した場合、この値は *systembase* になります。

* **Typestr**。データが格納されるインデックスの型です。前述のようにインデックスを作成した場合、この値は *logs* になります。

* **Port**。ホスト上で接続するポートです。通常、これは 9300 に設定する必要があります (Elasticsearch がクライアント API 要求をリッスンするために使用するポート、ポート 9200 は HTTP 要求のみに使用されます)。

* **Clustername**。インデックスを含む Elasticsearch クラスターの名前です。

* **ItemsPerInsert**。各一括挿入バッチで追加するドキュメントの数を示す数値パラメーターです。既定のバッチ サイズは 1000 です。

コンストラクターの文字列の値は、JMeter で JUnit サンプラーの構成に使用される [JUnit Request] ページで指定します。次に例を示します。

![](media/guidance-elasticsearch/data-ingestion-image22.png)

*BulkInsertTest* メソッドと *BigBulkInsertTest* メソッドは、データの生成とアップロードの実際の作業を行います。この 2 つのメソッドはよく似ています。Elasticsearch クラスターに接続した後、ドキュメントのバッチを作成します (*ItemsPerInsert* コンストラクター文字列パラメーターによる決定に従います)。ドキュメントは、Elasticsearch の一括 API を使用してインデックスに追加されます。2 つのメソッドの違いは、*BulkInsertTest* メソッドのアップロードでは各ドキュメントの *data1* および *data2* 文字列フィールドが省略されていますが、*BigBulkInsertTest* メソッドでは 12000 文字の文字列が設定されています。JMeter の [JUnit Request] (JUnit リクエスト) ページの *[Test Method]* (テスト メソッド) ボックスを使用して、実行するメソッドを選択します (前の図で強調表示されている箇所)。

> [AZURE.NOTE] ここで示したサンプル コードでは、Elasticsearch 1.7.3 Transport Client ライブラリを使用します。Elasticsearch 2.0.0 以降を使用している場合は、選択したバージョンの適切なライブラリを使用する必要があります。Elasticsearch 2.0.0 Transport Client ライブラリの詳細については、Elasticsearch の Web サイトの「[Transport Client](https://www.elastic.co/guide/en/elasticsearch/client/java-api/2.0/transport-client.html)」ページを参照してください。

[Configuring Resilience and Recovery on Elasticsearch on Azure (Azure での Elasticsearch の復元と回復の設定)]: guidance-elasticsearch-configuring-resilience-and-recovery.md
[Creating a Performance Testing Environment for Elasticsearch on Azure (Azure での Elasticsearch 用のパフォーマンス テスト環境の作成)]: guidance-elasticsearch-creating-performance-testing-environment.md
[Running the Automated Elasticsearch Performance Tests (自動化された Elasticsearch パフォーマンス テストの実行)]: guidance-elasticsearch-running-automated-performance-tests.md
[Deploying a JMeter JUnit Sampler for Testing Elasticsearch Performance (Elasticsearch のパフォーマンスをテストするための JMeter JUnit サンプラーをデプロイする)]: guidance-elasticsearch-deploying-jmeter-junit-sampler.md

<!---HONumber=AcomDC_0224_2016-->