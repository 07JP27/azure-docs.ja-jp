<properties
   pageTitle="Azure 上の Elasticsearch での復元と回復の設定"
   description="Elasticsearch の復元と回復に関連する考慮事項。"
   services=""
   documentationCenter="na"
   authors="mabsimms"
   manager="marksou"
   editor=""
   tags=""/>

<tags
   ms.service="guidance"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="02/18/2016"
   ms.author="masimms"/>
   
# Azure 上の Elasticsearch での復元と回復の設定

これは[一連の記事の一部](guidance-elasticsearch.md)です。

Elasticsearch の重要な機能は、ノードの障害またはネットワーク パーティション イベントが発生した場合の復元のために、それが提供するサポートです。レプリケーションは、すべてのクラスターの復元性を向上し、1 つのノードがアクセス不能になった場合に、Elasticsearch がすべてのデータ項目の複数のコピーを別のノードで使用できるようにする最も明確な方法です。ノードが一時的に使用不能になった場合、失われたノードのデータのレプリカを格納する他のノードが、問題が解決されるまで失われたデータを提供できます。長期的な問題が発生した場合は、失われたノードを新しいノードと交換でき、Elasticsearch がレプリカから、新しいノードにデータを復元することができます。

ここでは Azure でホストされている場合の Elasticsearch で使用できる復元と回復のオプションをまとめ、データの損失やデータの回復に長い時間がかかる可能性を最小にするために考慮すべき Elasticsearch クラスターのいくつかの重要な側面について説明します。

この記事では、Elasticsearch クラスターに対するさまざまな種類の障害の影響と、回復時のシステムの応答を示すために実行されたいくつかのサンプル テストについても説明します。

Elasticsearch クラスターは、可用性を維持し、読み取りパフォーマンスを向上するためにレプリカを使用します。レプリカは、レプリケートするプライマリのシャードと別の VM に保存される必要があります。この目的は、データ ノードをホストしている VM で障害が発生するか、使用できなくなった場合に、システムが、レプリカを保持している VM を使用して機能し続けられることです。

## 専用のマスター ノードの使用

Elasticsearch クラスター内の 1 つのノードがマスター ノードとして選択されます。このノードの目的は次のようなクラスター管理操作を実行することです。

- 障害が発生したノードの検出とレプリカへの切り替え、

- ノードのワークロードを分散するためのシャードの再配置、

- ノードがオンラインに戻ったときのシャードの回復。

重要なクラスターでは、専用のマスター ノードを使用することを検討し、マスターとしてのロールだけを持つ 3 つの専用ノードを設置するようにします。この構成により、これらのノードが実行する必要があるリソースを大量に使用する作業の量を減らし (それらはデータを格納したり、クエリを処理したりしません)、クラスターの安定性を向上するために役立ちます。これらのノードのうち 1 つだけを選択しますが、他のノードはシステム状態のコピーを格納し、選択されたマスターで障害が発生した場合に引き継ぐことができます。

## Azure による高可用性の制御 - 更新ドメインと障害ドメイン 

異なる VM で、同じ物理ハードウェアを共有できます。Azure データ センターでは、単一のラックで多数の VM をホストでき、これらのすべての VM で共通の電源とネットワーク スイッチを共有します。そのため、単一ラック レベルの障害が、多数の VM に影響する可能性があります。Azure は、障害ドメイン (FD) の概念を使用して、このリスクを分散しようとします。FD は、大まかに言って、同じラックを共有する VM のグループに相当します。ラック レベルの障害によって、そのすべてのレプリカを保持する 1 つまたは複数のノードが同時にクラッシュしないようにするため、VM が FD 全体に分散されるようにする必要があります。

同様に、[Azure ファブリック コントローラー](https://azure.microsoft.com/documentation/videos/fabric-controller-internals-building-and-updating-high-availability-apps/)によって、VM を停止し、計画済みメンテナンスとオペレーティング システムのアップグレードを実行できます。Azure は、VM を更新ドメイン (UD) に割り当てます。計画済みメンテナンス イベントが発生すると、いつでも単一の UD 内の 1 つの VM だけが影響を受けます。他の UD 内の VM は、更新される UD 内の VM がオンラインに戻るまで、実行したままになります。そのため、可能な限り、ノードをホストする VM とそれらのレプリカが別の UD に属するようにする必要があります。

> [AZURE.NOTE] FD と UD の詳細については、「[仮想マシンの可用性管理][]」を参照してください。

特定の UD や FD に VM を明示的に割り当てることはできません。この割り当ては VM の作成時に、Azure によって制御されます。詳細については、ドキュメント「[仮想マシンの可用性管理][]」を参照してください。ただし、VM を可用性セット (AS) の一部として作成するように指定することができます。同じ AS 内の VM は UD と FD に分散されます。VM を手動で作成した場合、Azure によって、各 AS に 2 つの FD と 5 つの UD が関連付けられ、コンピューターにこれらの FD と UD が割り当てられて、追加の VM がプロビジョニングされると次のように循環します。

- AS に最初にプロビジョニングされる VM は、最初の FD (FD 0) および最初の UD (UD 0) に配置されます。
- AS に 2 番目にプロビジョニングされる VM は、FD 1 と UD 1 に配置されます。
- AS に 3 番目にプロビジョニングされる VM は、FD 0 と UD 2 に配置されます。AS に 4 番目にプロビジョニングされる VM は、FD 1 と UD 3 に配置されます。
- AS に 5 番目にプロビジョニングされる VM は、FD 0 と UD 4 に配置されます。
- AS に 6 番目にプロビジョニングされる VM は、FD 1 と UD 0 に配置されます。
- AS に 7 番目にプロビジョニングされる VM は、FD 0 と UD 1 に配置されます。

> [AZURE.IMPORTANT] Azure リソース マネージャー (ARM) を使用して VM を作成する場合、各可用性セットに最大 3 つの FD と 20 個の UD を割り当てることができます。これは、ARM を使うべき強力な理由です。

一般に、同じ目的で使用するすべての VM を同じ可用性セットに配置しますが、異なる機能を実行する VM に対して、異なる可用性セットを作成します。Elasticsearch では、これは、次の VM に対して、少なくとも個別の可用性セットを作成することを検討する必要があることを意味します。

- データ ノードをホストしている VM
- クライアント ノード (それらを使用している場合) をホストしている VM
- マスター ノードをホストしている VM

さらに、クラスター内の各ノードが、それぞれ属する更新ドメインと障害ドメインを認識していることを確認する必要があります。この情報は、Elasticsearch が同じ障害ドメインと更新ドメイン内にシャードとそれらのレプリカを作成しないようにし、シャードとそのレプリカが同時に停止する範囲を最小に留めるために役立つ可能性があります。クラスターのハードウェア分散をミラーリングするように、Elasticsearch ノードを構成できます。それには [Shard Allocation Awareness (シャード割り当て認識)](https://www.elastic.co/guide/en/elasticsearch/reference/current/allocation-awareness.html#allocation-awareness) を構成します。たとえば、次のように、elasticsearch.yml ファイルに *faultDomain* と *updateDomain* と呼ばれるカスタム ノード属性のペアを定義できます。

```yaml
node.faultDomain: \${FAULTDOMAIN}
node.updateDomain: \${UPDATEDOMAIN}
```

この場合、属性は、Elasticsearch の起動時に、*\\${FAULTDOMAIN}* および *\\${UPDATEDOMAIN}* 環境変数に保持されている値を使用して、設定されます。Elasticsearch.yml ファイルに次のエントリを追加して、*faultDomain* と *updateDomain* が割り当て認識属性であることを示し、これらの属性に使用できる値のセットを指定する必要もあります。

```yaml
cluster.routing.allocation.awareness.force.updateDomain.values: 0,1,2,3,4
cluster.routing.allocation.awareness.force.faultDomain.values: 0,1
cluster.routing.allocation.awareness.attributes: updateDomain, faultDomain
```

シャード割り当て認識を [Shard Allocation Filtering (シャード割り当てフィルタリング)](https://www.elastic.co/guide/en/elasticsearch/reference/2.0/shard-allocation-filtering.html#shard-allocation-filtering) と組み合わせて使用して、特定のインデックスのシャードをホストできるノードを明示的に指定できます。

AS 内の FD と UD の数を超えて拡張する必要がある場合は、追加の AS に VM を作成できます。ただし、メンテナンスのために同時に停止できるノードは別の AS 内のノードであることを理解する必要があります。各シャードとその少なくとも 1 つのレプリカが、同じ AS 内に格納されるようにします。

> [AZURE.NOTE] 現在、AS あたりの VM は 100 に制限されています。詳細については、「[Azure サブスクリプションとサービスの制限、クォータ、制約](../azure-subscription-service-limits.md)」を参照してください。

### バックアップと復元

レプリカを使用することは、致命的なエラー (クラスター全体を誤って削除するなど) からの完全な保護にはなりません。クラスター内のデータを定期的にバックアップし、これらのバックアップからシステムを復元するための試行済みおよびテスト済みの戦略があることを確認する必要があります。

Elasticsearch の[スナップショットと復元の API](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html) を使用して、インデックスをバックアップし、復元します。スナップショットは、共有ファイル システムに保存できます。または、スナップショットを HDFS ([HDFS プラグイン](https://github.com/elasticsearch/elasticsearch-hadoop/tree/master/repository-hdfs)) または Azure Storage ([Azure クラウド プラグイン](https://github.com/elasticsearch/elasticsearch-cloud-azure#azure-repository)) に書き込むことができるプラグインを使用できます。

スナップショット ストレージ メカニズムを選択する場合は、次の点を検討してください。

- [Azure File Storage](https://azure.microsoft.com/services/storage/files/) を使用して、すべてのノードからアクセス可能な共有ファイル システムを実装できます。

- HDFS プラグインは、Hadoop と組み合わせて Elasticsearch を実行している場合にのみ使用します。

- HDFS プラグインでは、JVM の Elasticsearch インスタンス内で実行される Java セキュリティ マネージャーを無効にする必要があります。

- HDFS プラグインは、Elasticsearch で正しい Hadoop 構成が使用されていれば、HDFS と互換性のあるファイル システムをサポートします。

  
## ノード間の断続的な接続の処理

断続的なネットワークの切断、データ センターでの定期的なメンテナンス後の VM の再起動、およびその他の類似イベントによって、ノードが一時的にアクセスできなくなる可能性があります。これらの状況では、イベントが一時的である可能性があり、 シャードの再バランス調整が立て続けに 2 回発生する (障害の検出時に 1 回と、ノードがマスターに対して可視になったときにもう 1 回) のオーバーヘッドは、パフォーマンスに影響する大きなオーバーヘッドになる可能性があります。一時的なノードのアクセス不能によって、マスターのクラスターの再バランス調整が発生することを防ぐには、特定のインデックスのまたはすべてのインデックスに *delayed\_timeout* プロパティを設定します。次の例では、遅延を 5 分に設定しています。

```http
PUT /_all/settings
{
	"settings": {
    "index.unassigned.node_left.delayed_timeout": "5m"
	}
}
```

詳細については、「[Delaying allocation when a node leaves (ノードが離脱したときの割り当ての遅延)](https://www.elastic.co/guide/en/elasticsearch/reference/current/delayed-allocation.html)」を参照してください。

中断しがちなネットワークでは、マスターで、別のノードがアクセスできなくなったときに検出するように構成するパラメーターを変更することもできます。これらのパラメーターは、Elasticsearch で提供されている [Zen Discovery](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-zen.html#modules-discovery-zen) モジュールに含まれ、Elasticsearch.yml ファイルに設定することができます。たとえば *discovery.zen.fd.ping.retries* パラメーターは、マスター ノードが、クラスター内の別のノードに障害が発生したと判断するまでに、そのノードの ping を試みる回数を指定します。このパラメーターの既定値は 3 ですが、次のように変更できます。

```yaml
discovery.zen.fd.ping_retries: 6
```

## 回復の制御

障害発生後にノードへの接続が復元されるときに、そのノード上のすべてのシャードが回復され、それらが最新の状態になる必要があります。既定で、Elasticsearch は次の順序でシャードを回復します。

- インデックス作成日の逆順。古いインデックスの前に新しいインデックスが回復されます。

- インデックス名の逆順。アルファベット順で他より後の名前を持つインデックスが最初に復元されます。

一部のインデックスが他のインデックスより重要であるが、これらの条件を満たさない場合は、*index.priority* プロパティを設定して、インデックスの優先順位を上書きできます。このプロパティに大きい値を持つインデックスは、小さい値を持つインデックスより前に回復されます。

```http
PUT low_priority_index
{
	"settings": {
		"index.priority": 1
	}
}

PUT high_priority_index
{
	"settings": {
		"index.priority": 10
	}
}
```

詳細については、「[Index Recovery Prioritization (インデックスの回復の優先順位付け)](https://www.elastic.co/guide/en/elasticsearch/reference/2.0/recovery-prioritization.html#recovery-prioritization)」を参照してください。

*\_recovery* API を使用して、1 つまたは複数のインデックスの回復プロセスを監視できます。

```http
GET /high_priority_index/_recovery?pretty=true
```

詳細については、「[Indices Recovery (インデックスの回復)](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-recovery.html#indices-recovery)」を参照してください。

> [AZURE.NOTE] 回復が必要なシャードがあるクラスターの状態は*黄色*であり、現在使用できないシャードがあることを示します。すべてのシャードが使用できるようになると、クラスターの状態が*緑色*に戻るはずです。*赤色*の状態のクラスターは、1 つまたは複数のシャードが物理的に失われていることを示し、バックアップからデータを復元する必要がある可能性があります。

## スプリット ブレインの防止 

スプリット ブレインは、ノード間の接続に失敗した場合に発生する可能性があります。マスター ノードがクラスターの一部に到達できなくなった場合、接続可能なままであるネットワーク セグメントで選択が行われ、別のノードがマスターになります。不適切に構成されたクラスターでは、クラスターの部分ごとに異なるマスターが存在し、データの不整合や破損につながる可能性があります。この現象は*スプリット ブレイン*と呼ばれています。

スプリット ブレインの可能性を低減するには、elasticsearch.yml ファイルに、検出モジュールの *minimum\_master\_nodes* プロパティを設定します。このプロパティは、マスターの選択を可能にするために使用できる必要があるノードの数を指定します。次の例では、このプロパティの値を 2 に設定しています。

```yaml
discovery.zen.minimum_master_nodes: 2
```

この値は、マスター ロールを満たすことができる、ノード数の過半数の最小に設定する必要があります。たとえば、クラスターに 3 つのマスター ノードがある場合、*minimum\_master\_nodes* を 2 に設定する必要があり、5 つのマスター ノードがある場合は、*minimum\_master\_nodes* を 3 に設定する必要があります。できれば、マスター ノードの数を奇数にします。

**注:** 同じクラスター内の複数のマスター ノードが同時に起動した場合に、スプリット ブレインが発生する可能性があります。この発生はまれですが、各ノード間を短い遅延 (5 秒) で順番に起動することで回避できます。

## ローリング更新の処理

自分でノードのソフトウェア アップグレードを実行する (新しいリリースに移行するか、修正プログラムを実行するなど) 場合は、クラスターの残りの部分を使用可能な状態にしたまま、オフラインにする必要がある個々のノードを操作する必要がある場合があります。この状況では、次のプロセスを実装することを検討してください。

選択されたマスターが、失われているノードのシャードをクラスターの残りのノードに再バランス調整しないように、シャードの再割り当てが十分に遅延されることを確認します。既定で、シャードの再割り当ては 1 分間遅延されますが、ノードが長時間使用できない可能性がある場合は、この期間を増やすことができます。次の例では、遅延を 5 分に増やしています。

```http
PUT /_all/_settings
{
	"settings": {
		"index.unassigned.node_left.delayed_timeout": "5m"
	}
}
```

> [AZURE.IMPORTANT] クラスターの *cluster.routing.allocation.enable* を *none* に設定して、シャードの再割り当てを完全に無効にすることもできます。ただし、ノードがオフラインの間に新しいインデックスが作成される可能性が高い場合は、インデックスの割り当てが失敗し、クラスターが赤の状態になる可能性があるため、このアプローチの使用を避ける必要があります。

メンテナンスを行うノードで Elasticsearch を停止します。Elasticsearch がサービスとして実行されている場合は、オペレーティング システム コマンドを使用して、制御された方法でプロセスを停止できることがあります。次の例は、Ubuntu で実行している単一のノードで Elasticsearch サービスを停止する方法を示しています。

```bash
service elasticsearch stop
```

または、ノードで直接シャット ダウン API を使用できます。

```http
POST /_cluster/nodes/_local/_shutdown
```

ノードで必要なメンテナンスを実行してから、ノードを再起動し、それがクラスターに参加するまで待ちます。

シャードの割り当てを再度有効にします。

```http
PUT /_cluster/settings
{
	"transient": {
		"cluster.routing.allocation.enable": "all"
	}
}
```

> [AZURE.NOTE] 複数のノードのメンテナンスを行う必要がある場合は、シャードの割り当てを再度有効にする前に、各ノードで手順 2、3、および 4 を繰り返します。

可能であれば、この処理中に新しいデータのインデックス作成を停止します。これにより、ノードがオンラインに復帰し、クラスターに再参加するまでの回復時間を最短にすることができます。

特に Windows で Elasticsearch を実行する場合に、JVM などの項目の自動更新に注意してください (理想的には、これらの項目の自動更新を無効にする)。Java 更新エージェントは、Java の最新バージョンを自動的にダウンロードできますが、更新を有効にするために、Elasticsearch の再起動が必要になる場合があります。これにより、Java 更新エージェントの構成方法によっては、ノードの一貫性のない一時的な損失が発生する可能性があります。さらに、同じクラスター内の異なる Elasticsearch のインスタンスが、JVM の異なるバージョンを実行し、互換性の問題を引き起こす可能性もあります。

## Elasticsearch の復元と回復のテストと分析

このセクションでは、3 つのデータ ノードと 3 つのマスター ノードで構成される Elasticsearch クラスターの復元と回復を評価するために実行された一連のテストについて説明します。

4 つのシナリオがテストされました。

1.  ノードの障害が発生し、データの損失なく再起動する。データ ノードが停止し、5 分後に再起動します。Elasticsearch は、この期間で失われたシャードを再割り当てしないように構成されているため、シャードの移動で追加の I/O が発生しません。ノードが再起動すると、回復プロセスによって、そのノードのシャードが最新の状態に戻されます。

2.  ノードの障害が発生し、致命的なデータの損失が発生する。データ ノードが停止し、それが保持するデータが消去され、致命的なディスク障害をシミュレートします。ノードは再起動されますが (5 分後)、事実上、元のノードの交換として動作します。回復プロセスでは、このノードの失われたデータの再構築が必要であり、他のノードで保持されているシャードの再配置が必要になることがあります。

3.  ノードの障害が発生し、データの損失はないが、シャードが再割り当てされて再起動する。データ ノードが停止し、それが保持するシャードが他のノードに再割り当てされます。その後ノードが再起動され、クラスターを再バランス調整するために追加の再割り当てが発生します。

4.  ローリング更新。クラスター内の各ノードが停止し、短い間隔の後に再起動して、ソフトウェアの更新後に再起動されるマシンをシミュレートします。一度に 1 つだけのノードが停止します。ノードの停止中に、シャードは再割り当てされません。

各シナリオでは、ノードがオフラインになり、回復される間に、データ取り込みタスク、集計、およびフィルター クエリの組み合わせで構成される同じワークロードが課せられました。ワークロードの一括挿入操作は、それぞれ 1000 ドキュメントを保存し、1 つのインデックスに対して実行されましたが、集計クエリとフィルター クエリは、数百万のドキュメントを含む個別のインデックスを使用しました。これはクエリのパフォーマンスを一括挿入と別に評価できるようにするためです。各インデックスは、5 つのシャードと 1 つのレプリカで構成されました。

次のセクションでは、これらのテストの結果をまとめ、ノードのオフライン中または回復中のパフォーマンスの低下、および報告されたエラーについて説明します。結果はグラフィカルに示し、1 つまたは複数のノードが失われた時点を強調表示し、システムが完全に回復し、ノードがオフラインになる前に発揮していた同様のパフォーマンスのレベルを達成するまでにかかる時間を推定しています。

> [AZURE.NOTE] これらのテストを実行するために使用されたテスト ハーネスは、オンラインで入手できます。これらのハーネスを適応し、使用して、独自のクラスター構成の復元性と回復性を確認できます。詳細については、「[Running the Automated Elasticsearch Resiliency Tests (Elasticsearch の自動復元テストの実行)][]」を参照してください。

## ノードの障害が発生し、データの損失なく再起動する: 結果

<!-- TODO; reformat this pdf for display inline -->

このテストの結果は、[ElasticsearchRecoveryScenario1.pdf](https://github.com/mspnp/azure-guidance/blob/master/figures/Elasticsearch/ElasticsearchRecoveryScenario1.pdf) ファイルに示しています。グラフは、クラスター内のノードごとのワークロードと物理リソースのパフォーマンス プロファイルを示しています。グラフの最初の部分は、システムが約 20 分間正常に実行していることを示しており、20 分の時点でノード 0 が 5 分間シャット ダウンしてから、再起動しています。さらにその後の 20 分間の統計情報を示しています。システムは回復し、安定するまで、約 10 分かかっています。これは、さまざまなワークロードのトランザクション レートと応答時間で示しています。

以下の点に注意してください。

- テスト中、エラーは報告されませんでした。失われたデータはなく、すべての操作が正常に完了しました。

- ノード 0 がオフラインの間に、3 種類のすべての操作 (一括挿入、集計クエリ、およびフィルター クエリ) のトランザクション レートが低下し、平均応答時間が増加しました。

- 回復期間中、集計クエリとフィルター クエリの処理のトランザクション レートと、応答時間は徐々に回復しました。一括挿入のパフォーマンスは短くなるまで、少し回復に時間がかかりました。ただし、これはおそらく一括挿入で使用されるインデックスを増加させるデータの量に原因があり、この操作のトランザクション レートは、ノード 0 がオフラインになる前でも低下が見られる可能性があります。

- ノード 0 の CPU 使用率グラフは、回復フェーズ中のアクティビティの減少を示しており、これは回復メカニズムによって引き起こされるディスクおよびネットワーク アクティビティの増加に原因があります。ノードはオフラインの間に失われたデータを取り戻し、格納するシャードを更新する必要があります。

- インデックスのシャードはすべてのノードに正確に均等に分散されるわけではありません。それぞれ 5 つのシャードと 1 つのレプリカから構成される 2 つのインデックスがあり、合計 20 個のシャードが作成されます。そのため、2 つのノードは 6 つのシャードを格納し、他の 2 つのノードは 7 つずつ保持することになります。これは、CPU 使用率グラフの最初の 20 分間で明らかであり、ノード 0 は、他の 2 つのノードよりもビジーではありません。回復の完了後、ノード 2 がやや負荷の軽いノードになったように見えるため、何らかの切り替えが発生したようです。

    
## ノードの障害が発生し、致命的なデータの損失が発生する: 結果

<!-- TODO; reformat this pdf for display inline -->

このテストの結果は、[ElasticsearchRecoveryScenario2.pdf](https://github.com/mspnp/azure-guidance/blob/master/figures/Elasticsearch/ElasticsearchRecoveryScenario2.pdf) ファイルに示しています。最初のテストと同様に、グラフの最初の部分は、システムが約 20 分間正常に実行していることを示しており、20 分の時点でノード 0 が 5 分間シャットダウンしています。この間に、このノードの Elasticsearch データが削除され、再起動される前に、致命的なデータ損失をシミュレートしています。完全な回復は、テスト前に発揮されたパフォーマンスのレベルが復元されるまで、12 ～ 15 分かかっているように見えます。

以下の点に注意してください。

- テスト中、エラーは報告されませんでした。失われたデータはなく、すべての操作が正常に完了しました。

- ノード 0 がオフラインの間に、3 種類のすべての操作 (一括挿入、集計クエリ、およびフィルター クエリ) のトランザクション レートが低下し、平均応答時間が増加しました。この時点で、テストのパフォーマンス プロファイルは最初のシナリオに似ていますが、これは、この時点までのシナリオが同じであるため、驚くべきことではありません。

- 回復期間中に、トランザクション レートと応答時間は復元されましたが、この期間、数字に大きな変動がありました。これは、おそらくクラスター内のノードが実行し、失われたシャードを復元するためにデータを提供する追加の作業に原因があります。この追加作業は、CPU 使用率、ディスク アクティビティ、およびネットワーク アクティビティ グラフに明らかです。

- ノード 0 および 1 の CPU 使用率グラフは、回復フェーズ中のアクティビティの減少を示しており、これは、回復プロセスによって引き起こされるディスクおよびネットワーク アクティビティの増加に原因があります。最初のシナリオでは、回復されるノードでのみこの動作が発生していましたが、このシナリオではノード 0 の失われたデータの大部分がノード 1 から復元されているように見えます。

- ノード 0 の I/O アクティビティは最初のシナリオと比較して、実際に減少します。これは、既存のシャードを最新状態にするために必要な一連の小さな I/O 要求よりも、シャード全体にデータを単純にコピーする場合の I/O の効率性に原因がある可能性があります。

- 3 つのすべてのノードのネットワーク アクティビティは、データがノード間で送受信されるため、アクティビティの急増を示しています。シナリオ 1 では、ノード 0 にのみその量のアクティビティが示されていましたが、このアクティビティは長い期間続いていたように見えました。ここでも、この違いは、シャードの回復時に、一連の小さな要求を受信するより、1 回の要求として、シャードにデータ全体を転送する方が効率的であることに原因があります。

## ノードの障害が発生し、シャードが再割り当てされる: 結果

<!-- TODO; reformat this pdf for display inline -->

[ElasticsearchRecoveryScenario3.pdf](https://github.com/mspnp/azure-guidance/blob/master/figures/Elasticsearch/ElasticsearchRecoveryScenario3.pdf) ファイルに、このテストの結果を示しています。最初のテストと同様に、グラフの最初の部分は、システムが約 20 分間正常に実行していることを示しており、20 分の時点でノード 0 が 5 分間シャットダウンしています。この時点で、Elasticsearch クラスターは、失われたシャードを再作成し、残りのノード全体へのシャードの再バランス調整を試みます。5 分後、ノード 0 がオンラインに復帰し、もう一度クラスターがシャードを再バランス調整する必要があります。パフォーマンスは 12 ～ 15 分後に復元されます。

以下の点に注意してください。

- テスト中、エラーは報告されませんでした。失われたデータはなく、すべての操作が正常に完了しました。

- 前の 2 つのテストと比較して、ノード 0 がオフラインの間に、3 種類のすべての操作 (一括挿入、集計クエリ、およびフィルター クエリ) のトランザクション レートが低下し、平均応答時間が大幅に増加しました。これは、失われたシャードを再作成し、クラスターを再バランス調整するクラスター アクティビティの増加に原因があり、この期間のノード 1 とノード 2 のディスクおよびネットワーク アクティビティの数字の上昇によって明らかです。

- この期間、ノード 0 がオンラインに戻っても、トランザクション レートと応答時間は不安定なままです。

- ノード 0 の CPU 使用率およびディスク アクティビティ グラフは、回復フェーズ中の初期アクションの著しい減少を示しています。これは、この時点で、ノード 0 がデータをまったく提供していないためです。約 5 分後、ネットワーク、ディスク、および CPU アクティビティの突然の増加によって示されているように、ノードのアクションが急増しています。これはおそらくクラスターがノード全体にシャードを再分散することに原因がありますその後、ノード 0 は通常のアクティビティを示します。
  
## ローリング更新: 結果

<!-- TODO; reformat this pdf for display inline -->

[ElasticsearchRecoveryScenario4.pdf](https://github.com/mspnp/azure-guidance/blob/master/figures/Elasticsearch/ElasticsearchRecoveryScenario4.pdf) ファイルのこのテストの結果は、各ノードがオフラインになり、連続して再稼働される状況を示しています。各ノードは 5 分間シャット ダウンしてから、再起動され、その時点で順番の次のノードが停止されます。

以下の点に注意してください。

- 各ノードが循環する間、スループットと応答時間の観点でのパフォーマンスはほとんど一定のままです。

- 各ノードのディスク アクティビティの増加は、それがオンラインに戻ったときの短時間の増加です。これは、おそらくノードの停止中に発生した変更の処理を続行する回復プロセスに原因があります。

- ノードがオフラインになると、残りのノードでネットワーク アクティビティが急増します。急増は、ノードが再起動されたときにも発生します。

- 最後のノードの再利用後に、システムは大きい変動期間に入ります。これは、おそらくすべてのノード全体に変更を同期して、すべてのレプリカとそれらの対応するシャードの整合性を確保する必要がある回復プロセスに原因があります。途中、この作業により、連続した一括挿入操作がタイムアウトして、失敗します。各ケースで報告されたエラーは次のとおりです。

```
Failure -- BulkDataInsertTest17(org.apache.jmeter.protocol.java.sampler.JUnitSampler$AnnotatedTestCase): java.lang.AssertionError: failure in bulk execution:
[1]: index [systwo], type [logs], id [AVEg0JwjRKxX_sVoNrte], message [UnavailableShardsException[[systwo][2] Primary shard is not active or isn't assigned to a known node. Timeout: [1m], request: org.elasticsearch.action.bulk.BulkShardRequest@787cc3cd]]

```

後の実験で、各ノードの循環の間に、数分の遅延を導入することで、このエラーがなくなったことが示されたため、このエラーの最も可能性の高い原因は、複数のノードを同時に復元しようとする回復プロセスと、何千もの新しいドキュメントを保存しようとする一括挿入操作の競合にあります。


## 概要

実行されたテストでは、次のことが示されました。

- Elasticsearch は、クラスターで発生する可能性のあるほとんどの一般的な障害のモードに対して、高い復元性がありました。

- Elasticsearch は、適切に設計されたクラスターのノードで致命的なデータ損失が発生した場合に、迅速に回復できます。これは、データを一時的ストレージに保存し、ノードが再起動後、続けて再プロビジョニングされるように Elasticsearch を構成した場合に行われる可能性があります。これらの結果は、このケースでも、一時的ストレージの使用のリスクは、このクラスのストレージで提供されるパフォーマンス上のメリットを上回る可能性が高いことを示しています。

- 最初の 3 つのシナリオでは、ノードがオフラインになり、回復する間の同時一括挿入、集計、およびフィルター クエリのワークロードで、エラーが発生しませんでした。

- シナリオ 4 のみ、データ損失の可能性を示しており、この損失は追加される新しいデータにのみ影響を与えました。データ取り込みを実行するアプリケーションでは、報告されたエラーの種類が一時的である可能性が高いため、失敗した挿入操作を再試行して、この可能性を軽減することをお勧めします。

- テスト 4 の結果は、クラスター内のノードの計画済みメンテナンスを行う場合に、1 つのノードから次のノードに循環する間に、数分を見込むとパフォーマンス上のメリットがあることも示しています。計画外の状況 (オペレーティング システムの更新を実行した後に、ノードを再利用するデータ センターなど) では、ノードが停止され、再起動される方法とタイミングについてあまり制御できません。Elasticsearch が連続したノードの停止後に、クラスターの状態を回復しようとしたときに発生する競合によって、タイムアウトとエラーが発生することがあります。

[仮想マシンの可用性管理]: ../articles/virtual-machines/virtual-machines-manage-availability.md
[Running the Automated Elasticsearch Resiliency Tests (Elasticsearch の自動復元テストの実行)]: guidance-elasticsearch-running-automated-resilience-tests.md

<!---HONumber=AcomDC_0224_2016-->