<properties
   pageTitle="Azure で Elasticsearch を実行する | Microsoft Azure"
   description="Azure に Elasticsearch をインストールし、構成し、実行する方法。"
   services=""
   documentationCenter="na"
   authors="mabsimms"
   manager="marksou"
   editor=""
   tags=""/>

<tags
   ms.service="guidance"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="02/18/2016"
   ms.author="masimms"/>

# Azure で Elasticsearch を実行する

これは[一連の記事の一部](guidance-elasticsearch.md)です。

## 概要

Elasticsearch は拡張性の高いオープン ソースの検索エンジンとデータベースです。大規模なデータセットに含まれる情報を高速で検索し、分析する場合に最適です。一般的なシナリオは、次のとおりです。

- **大規模な全文検索**。検索語句の組み合わせに一致する文書をすばやく検索できます。

- **イベントのログ記録**。さまざまなソースから情報が得られます。場合によっては、一連のイベントが特定の結論に導かれた経緯を解明するために、データを分析する必要があります。

- **リモート デバイスや他のソースから取得されたデータの格納**。データにはさまざまな情報が含まれますが、共通の要件は、オペレーターがシステム全体の状態を理解できるように、一連のダッシュボードにこの情報を表示することです。アプリケーションでも情報を利用し、データの流れと結果として実行しなければならない事業活動についてすばやく決定できます。

- **在庫管理**。商品が販売されると、在庫の変更が記録されます。ビジネス システムでこの情報を利用し、在庫状況を利用者に報告したり、製品の在庫が少なくなった場合に再発注したりできます。アナリストはデータを分析して傾向をとらえ、製品がよく売れる状況を見つけ出すことができます。

- **財務分析**。市場情報がほぼリアルタイムで届きます。さまざまな金融商品の最新状況を示すダッシュボードを生成し、それを利用して買い/売りを決定できます。

この記事では、Elasticsearch の一般的構造を簡単に説明し、Azure を使用して Elasticsearch クラスターを実装する方法について説明します。この記事では主に、Elasticsearch クラスターのデプロイのベスト プラクティスを紹介します。システムのさまざまな機能的パフォーマンス/管理要件を取り上げ、要件に基づき、構成とトポロジを選択する際の考慮事項について説明します。

> [AZURE.NOTE] このガイダンスは、[Elasticsearch][] の基礎知識があることを前提としています。

## Elasticsearch の構造

Elasticsearch は、検索エンジンとして機能するために高度に最適化されたドキュメント データベースです。ドキュメントは JSON 形式でシリアル化されます。データはインデックスに保持され、[Apache Lucene][] を使用して実装されます。ただし、詳細はビューから要約され、Elasticsearch を使用するために Lucene を完全に理解する必要はありません。

### クラスター、ノード、インデックス、シャード

Elasticsearch では、シャーディングを利用して複数のノードにデータを分散し、複製を利用して高可用性を実現する、クラスター化されたアーキテクチャを実装します。

ドキュメントはインデックスで保存されます。ドキュメント内のフィールドを指定し、インデックス内でそのドキュメントを一意に識別できます。あるいは、キー フィールドと値を自動生成できます。インデックスはドキュメントを物理的に整理するために使用され、また、ドキュメントの位置を見つけるための第一の手段として使用されます。さらに、Elasticsearch では、残りのフィールドで逆インデックスとして機能する一連の追加構造が自動的に作成されます。それにより、コレクション内で高速の検索と分析が可能になります。

インデックスは一連のシャードで構成されます。ドキュメントは、インデックス キーの値とインデックス内のシャード数に基づいてハッシュ メカニズムを利用し、シャード全体に均等に分散されます。ドキュメントがシャードに割り当てられると、そのインデックス キーが変更されるまで、そのシャードから移動しません。Elasticsearch では、クラスター内で利用できるすべてのデータ ノードにシャードが分散されます。1 つのノードは最初に、同じインデックスに属する 1 つまたは複数のシャードを保有できますが、新しいノードがクラスターに追加されると、Elasticsearch はシャードの位置を変更し、システム全体の負荷を分散します。ノードが移動されると、同じ再負荷分散が適用されます。

インデックスは複製できます。この場合、インデックスの各シャードがコピーされます。Elasticsearch では、インデックスの元のシャード (「プライマリ シャード」と呼ばれる) とそのレプリカが常に異なるノードに置かれます。

> [AZURE.NOTE] インデックスの作成後は、レプリカは追加できますが、インデックス内のシャードの数は簡単に変更できなくなります。

ドキュメントが追加または変更されると、すべての書き込み操作が最初にプライマリ シャードで実行され、次に各レプリカで実行されます。既定では、このプロセスは同期実行され、一貫性が維持されます。Elasticsearch では、データを書き込むときに、オプティミスティック同時実行制御とバージョン管理が利用されます。読み取り操作は、プライマリ シャードとそのレプリカのいずれかを利用して実行されます。

次の図は、3 つのノードで構成された Elasticsearch クラスターの重要な側面を示しています。2 つのプライマリ シャードと各シャードの 2 つのレプリカ (合計で 6 つのシャード) で構成されるインデックスが作成されています。

![](media/guidance-elasticsearch/general-cluster1.png)

*2 つのプライマリ ノードと 2 つのレプリカ セットで構成されている単純な Elasticsearch クラスター*

このクラスターでは、プライマリ シャード 1 とプライマリ シャード 2 が別々のノードに置かれ、付加が分散されています。レプリカも同様に分散されています。1 つのノードが故障しても、システムの機能を続行するために十分な情報が残りのノードにあります。必要に応じて、プライマリ シャードが利用不可能になった場合、Elasticsearch はレプリカ シャードをプライマリ シャードに昇進させます。ノードが実行を開始するとき、新しいクラスターを開始するか (それがクラスターの最初のノードの場合)、既存のクラスターに参加できます。ノードが属するクラスターは、elasticsearch.yml ファイルの `cluster.name` 設定によって決定されます。

### ノード ロール

Elasticsearch クラスターのノードは次のロールを実行できます。

- **データ ノード**: インデックス データが含まれる 1 つ以上のシャードを保持できます。

- **クライアント ノード**: インデックス データは保持しませんが、適切なデータ ノードに対するクライアント アプリケーションの受信要求を処理します。
 
- **マスター ノード**: インデックス データは保持しませんが、クラスターに関するルーティング情報 (ノードとそれに含まれるシャードのリスト) の管理と配布、利用可能なノードの特定、ノードが追加または削除されたときのシャードの再配置、ノードの障害後の復旧の調整など、クラスター管理操作を実行します。複数のノードをマスターとして構成できますが、実際には 1 つだけのノードが選ばれ、マスター機能を実行します。そのノードが故障した場合、もう一度選択が行われ、資格のある他のノードの 1 つが選ばれ、引き継ぎます。

既定では、Elasticsearch ノードは 3 つのロールをすべて実行しますが (これにより、開発と概念実証のために 1 台のコンピューターで完全に動作するクラスターを構築できます)、次のように、*elasticsearch.yml* ファイルの *node.data* 設定と *node.master* 設定を使用して操作を変更できます。

```yaml
# Configuration for a data node
node.data: true
node.master: false
```

```yaml
# Configuration for a client node
node.data: false
node.master: false
```

```yaml
# Configuration for a master node
node.data: false
node.master: true
```

> [AZURE.NOTE] 選ばれたマスター ノードは、クラスターの健全性のために重要です。他のノードは定期的に ping を実行し、引き続き利用できることを確認します。選ばれたマスター ノードがデータ ノードとしても機能している場合、ノードがビジー状態になり、ping に応答できないことがあります。そのような場合、マスターが故障していると見なされ、他のマスター ノードの 1 つが代わりに選ばれます。
> 
> 元のマスターが実際には利用できる場合、結果的にクラスターで 2 つのマスターが選ばれ、「スプリット ブレイン」問題が発生し、データの破損やその他の問題が発生することがあります。
> 
> この問題が発生する可能性を抑えるようにクラスターを構成する方法については、「[Configuring Resilience and Recovery on Elasticsearch on Azure][]」をご覧ください。ただし、最終的には、データ管理の役割を担わない専用のマスター ノードを使用することが中規模から大規模のクラスターでの最良の方法となります。

クラスターのノードは、クラスターの他のノードの情報 ([ゴシップ プロトコル][]を使用) と各ノードに含まれるシャードに関する情報を共有します。データを保存し、取得するクライアント アプリケーションはクラスター内のあらゆるノードに接続できます。要求は透過的に正しいノードに送信されます。クライアント アプリケーションがクラスターからデータを要求するとき、要求を最初に受信したノードが操作を指示し、関連ノードと通信してデータを取得し、結果を集計してクライアント アプリケーションに返します。

クライアント ノードを利用して要求を処理することで、データ ノードがスキャッター/ギャザー作業から解放され、データに対するサービス提供に集中できます。データ ノードの HTTP トランスポートを無効にすることで、クライアント アプリケーションがデータ ノードと思いがけず通信する事態 (データ ノードがクライアント ノードとして機能し始めます) を回避できます。

```yaml
http.enabled: false
```

データ ノードは引き続き、同じネットワークにある他のデータ ノード、クライアント ノード、専用マスター ノードと Elasticsearch モジュール (TCP ソケットを利用してノード間で直接接続します) で通信できますが、クライアント アプリケーションは HTTP でクライアント ノードにのみ接続できます。次の図は、Elasticsearch クラスターに専用マスター ノード、クライアント ノード、データ ノードが混在するトポロジを示しています。

![](media/guidance-elasticsearch/general-cluster2.png)

*さまざまな種類のノードを表示する Elasticsearch クラスター*

### クライアント ノードを使用する場合の費用と利点

アプリケーションがクエリを Elasticsearch クラスターに送信するとき、アプリケーションの接続先となるノードがクエリ プロセスを指示します。ノードは要求を各データ ノードに転送し、結果を収集し、累積された情報をアプリケーションに返します。クエリに集約やその他の計算が含まれる場合、アプリケーションの接続先のノードは他のノードからデータを取得し、必要な演算を実行します。このスキャッター/ギャザー プロセスでは、大量の処理/メモリ リソースが使用されます。

専用クライアント ノードでこれらのタスクを実行することで、データ ノードをデータの管理と保管に集中させることができます。そのため、複雑なクエリや集約が伴う多くのシナリオでは、専用クライアント ノードを利用すると効率的になります。ただし、専用クライアント ノードの利用の効果は、多くの場合、シナリオ、ワークロード、クラスター サイズに依存します。

たとえば、データ取り込みのワークロードはクライアント ノードを利用すると効率性が下がることがあります。データを格納するとき、付加的ネットワークの「ホップ」が必要になるためです。シャードが 6 つの 3 ノード クラスターでは、システムが専用クライアント ノードで構成されていない場合、すべての環境要因とノード読み込みが等しいとき、データを保存または変更するアプリケーションが 1/3 の確率で最も適切なシャードに直接接続します。1/3 のケースで、付加的なネットワーク ジャンプを実行する必要がなくなります。

一方で、複雑な集約を実行するワークロードの場合、専用クライアントを利用すると効率的になることがあります。複雑な集約で実行される一連のスキャッター/ギャザー操作を 1 つのノードが担当します。混合ワークロード環境では、特定のワークロードでクライアント ノードを使用した場合の効果を評価するためにパフォーマンス テストを実行する準備をします。

> [AZURE.NOTE] このチューニング プロセスの詳細については、「[Tuning data aggregation and Query performance with Elasticsearch on Azure][]」をご覧ください。

### クラスターに接続する

Elasticsearch は、クライアント アプリケーションを構築し、要求をクラスターに送信するための一連の REST API を公開します。.NET フレームワークを使用してアプリケーションを開発している場合は、2 つの高レベルの API である [Elasticsearch.Net と NEST][] を利用できます。

Java を使用してクライアント アプリケーションを構築している場合は、[ノード クライアント API][] を使用してクライアント ノードを動的に作成し、クラスターに追加できます。長時間接続の数が比較的少ない場合、クライアント ノードを動的に作成する方法が便利です。ノード API を利用して作成されたクライアント ノードには、マスター ノードによりクラスター ルーティング マップ (ノードとそれに含まれるシャードの詳細) が与えられます。この情報により、Java アプリケーションはデータにインデックスを作成したり、データを問い合わせたりするときに適切なノードに直接接続できます。他の API の利用時に比べ、ホップの数が少なくなります。

クライアント ノードをクラスターに登録するための諸経費がこの手法のコストとなります。大量のクライアント ノードが現れては消える場合、クラスター ルーティング マップを保守管理し、配信することの影響が大きくなります。

**接続の負荷分散**

Elasticsearch は、接続の負荷分散を実装するためのいくつかのメカニズムを可能にします。次は、いくつかの共通手法を一覧にしたものです。

**クライアント ベースの負荷分散**: Elasticsearch.Net API または NEST API を使用してクライアント アプリケーションを構築している場合は、接続プールを使用してノード全体で接続要求をラウンドロビンできるので、外部ロード バランサーがなくても要求の負荷を分散できます。次のコード スニペットは、3 つのノードのアドレスで構成された *ElasticsearchClient* オブジェクトを作成する方法を示しています。クライアント アプリケーションからの要求がこれらのノード全体に分配されます。

```csharp
// C#
var node1 = new Uri("http://node1.example.com:9200");
var node2 = new Uri("http://node2.example.com:9200");
var node3 = new Uri("http://node3.example.com:9200");

var connectionPool = new SniffingConnectionPool(new[] {node1, node2, node3});
var config = new ConnectionConfiguration(connectionPool);
var client = new ElasticsearchClient(config);
```

> [AZURE.NOTE] [トランスポート クライアント API][] により、同様の機能を Java アプリケーションで利用できます。

**サーバー ベースの負荷分散**: 個別のロード バランサーを使用して要求をノードに分配できます。この手法には、アドレスの透過性という長所があります。クライアント アプリケーションは各ノードの詳細で構成する必要がありません。クライアント コードを変更せずに、ノードを簡単に追加、削除、位置変更できます。次の図は、ロード バランサーを使用して一連のクライアント ノードに要求をルーティングする構成を示しています。ただし、クライアント ノードを使用しない場合は、同じ方法を使用してデータ ノードに直接接続できます。

![](media/guidance-elasticsearch/general-clientappinstances.png)

*Azure Load Balancer を使用して Elasticsearch クラスターに接続するクライアント アプリケーション インスタンス*

> [AZURE.NOTE] [Azure Load Balancer][] を使用して、クラスターをパブリック インターネットに公開できます。また、クライアント アプリケーションとクラスターがすべて同じプライベート仮想ネットワーク (VNET) に含まれている場合は、[内部ロード バランサー][]を使用できます。

**カスタムの負荷分散**: Azure Load Balancer の代わりに、[nginx][] をリバース プロキシ サーバーとして使用できます。Nginx には、ラウンド ロビン、Least-Connected (現在、接続が最も少ない宛先に要求が送信される)、クライアントの IP アドレスに基づくハッシュなど、さまざまな負荷分散方法があります。

> [AZURE.NOTE] Azure VM として nginx サーバーをデプロイできます。可用性を維持するために、同じ Azure 可用性セットに 2 つ以上の nginx サーバーを作成してください。

負荷分散の使用と使用する実装を決定する際には次の点を検討してください。

- 同じノードに接続し、あるアプリケーションのすべてのインスタンスのすべての要求を処理すると、そのノードがボトルネックになることがあります。ノードで利用できるスレッドの数が使い尽くされると、要求が待ち行列に入り、待ち行列があまりに長くなると拒否されます (多数のユーザーにデプロイされるアプリケーション コードには単一ノードの接続詳細をハード コード化しないでください)。

- Elasticsearch.Net、NEST、Transport Client API のラウンドロビン メカニズムは、接続プールで次に利用できるノードに接続を再試行することで、失敗した接続要求を処理します。プール内の応答しないノードへの接続は、一時的に*停止 (dead)* としてマークされる場合があります。このようなノードは後で復帰することがあります。プールはノードに対して ping を実行して、再度アクティブになっているかどうかを判断できます。

- Azure ロード バランサーは、要因 (クライアント IP アドレス、クライアント ポート、宛先 IP アドレス、宛先ポート、プロトコル タイプ) の数に基づき、透過的に要求をノードにリダイレクトできます。この方法に従い、特定のコンピューターで実行されているクライアント アプリケーションのインスタンスは、多くの場合、同じ Elasticsearch ノードにリダイレクトされます。ロード バランサーのプローブ構成にもよりますが、Elasticsearch サービスがこのノードで故障しても、VM 自体は動作を継続している場合、このノードに対するすべての接続がタイムアウトになるが、他のクライアント インスタンスの他のノードに対する接続は続行することがあります。

- ロード バランサーが実行するヘルス プローブ要求にノードが適切に応答しない場合、そのノードをローテーションが外すように Azure ロード バランサーを設定できます。

### ノード検出

Elasticsearch はピアツーピア通信を基盤としています。クラスターの他のノードを検出することがノードのライフサイクルにおいて重要な部分となります。ノードを検出することで、新しいデータ ノードをクラスターに動的に追加し、クラスターを透過的に拡張できます。また、あるデータ ノードが他のノードからの通信要求に応答できない場合、マスター ノードがそのデータ ノードの失敗を判断し、必要な手順を踏み、動作している他のデータ ノードにシャードを再割り当てすることができます。

Elasticsearch ノード検出は検出モジュールの使用により処理されます。検出モジュールは、別の検出メカニズムに切り替えられるプラグインです。既定の検出モジュール ([Zen][]) では、ノードは ping 要求を発行し、同じネットワークの他のノードを見つけます。他のノードが応答する場合、ゴシップ プロトコルで情報を交換します。その後、マスター ノードは新しいノードにシャードを配信し (データ ノードの場合)、クラスターの負荷を再び分散できます。

Zen 検出モジュールはマスターの選択プロセスとノード失敗を検出するプロトコルも処理します。

Elasticsearch バージョン 2.0 以前は、Zen 検出モジュールはノードが互いに通信するためにマルチキャスト通信を使用していました。その方法では、新しいノードを簡単にクラスターに導入できますが、同じネットワークの別の Elasticsearch インストールで同じクラスター名が使用されていた場合にセキュリティ上の問題を引き起こします。新しいインストールが同じクラスターに含まれると見なされ、シャードがこのインストールのノードに送信されることがあります。

また、Azure Virtual Machines (VM) として Elasticsearch ノードを実行している場合、マルチキャスト メッセージングはサポートされません。そのような理由から、ユニキャスト メッセージを使用するように Zen 検出を構成し、elasticsearch.yml 構成ファイルに有効な連絡先ノードの一覧を指定してください。

> [AZURE.NOTE] Elasticsearch 2.0 以降では、マルチキャストは既定の検出メカニズムではなくなりました。

Azure VNET 内で Elasticsearch クラスターをホストしている場合、DHCP が割り当て、クラスターの各 VM に与えられたプライベート IP アドレスが割り当てられている状態を維持するように指定できます (静的)。これらの静的 IP アドレスを利用し、Zen 検出ユニキャスト メッセージングを構成できます。動的 IP アドレスで VM を利用している場合、VM が停止し、再起動した場合、新しい IP アドレスが割り当てられ、検出が難しくなる可能性があることに注意してください。このシナリオに対処するために、Zen 検出モジュールを [Azure クラウド プラグイン][]と交換できます。このプラグインは Azure API を使用し、Azure サブスクリプション情報に基づく検出メカニズムを実装します。

> [AZURE.NOTE] Azure クラウド プラグインの現行バージョンを利用するには、Elasticsearch ノードに Java キーストアの Azure サブスクリプションの管理証明書をインストールし、elasticsearch.yml ファイルにキーストアにアクセスするための場所と資格情報を指定する必要があります。このファイルはクリア テキストで保存されます。そのため、このファイルへのアクセスを Elasticsearch サービスを実行しているアカウントに限定することが重要になります。
> 
> また、Azure リソース マネージャー (ARM) のデプロイではこの方法が利用できない場合があります。そのような理由から、マスター ノードに静的 IP アドレスを使用し、そのノードを利用してクラスター全体で Zen 検出ユニキャスト メッセージングを実装することが推奨されます。次の構成 (サンプル データ ノードの elasticsearch.yml ファイルからの抜粋) では、ホスト IP アドレスがクラスターのマスター ノードを参照しています。

```yaml
discovery.zen.ping.multicast.enabled: false  
discovery.zen.ping.unicast.hosts: ["10.0.0.10","10.0.0.11","10.0.0.12"]
```

## 一般的なシステム ガイドライン

Elasticsearch は、1 台のラップトップから高性能サーバーの集合まで、さまざまなコンピューター上で実行できます。ただし、メモリ、計算能力、高速ディスクなどのリソースが多ければ多いほど、性能はよくなります。次のセクションでは、Elasticsearch を実行するための基本的なハードウェアとソフトウェアの要件がまとめてあります。

### メモリの要件

Elasticsearch は高速化のためにメモリにデータを保存しようとします。一般的な企業向けまたは中規模の商用のノードを Azure にデプロイするには運用サーバーに 14GB ～ 28GB の RAM が必要になります (D3 または D4 VM)。**より多くのメモリを持つノードを作成するのではなく、ノードを増やして負荷を分散させます** (実験の結果、多くのメモリを持つ大規模ノードを使用すると、障害発生時の復旧に時間がかかる可能性があることがわかりました)。 ただし、たくさんの小規模ノードでクラスターを作ると、可用性とスループットが上がりますが、そのようなシステムを運用し、保守管理する労力もたくさん必要になります。

**サーバーで利用できるメモリの 50% を Elasticsearch のヒープに割り当てます**。Linux を使用している場合、Elasticsearch を実行する前に ES\_HEAP\_SIZE 環境変数を設定します。また、Windows または Linux を使用している場合は、Elasticsearch の起動時に `Xmx` パラメーターと `Xms` パラメーターでメモリ サイズを指定することもできます。Java 仮想マシン (JVM) が実行時にヒープのサイズを変更するのを回避するために、両方のパラメーターを同じ値に設定します。ただし、**30 GB 以上のメモリを割り当てないでください**。オペレーティング システム ファイル キャッシュに残りのメモリを使用します。

> [AZURE.NOTE] Elasticsearch は Lucene ライブラリを活用し、インデックスを作成して管理します。Lucene 構造はディスク基盤の形式を利用します。ファイル システム キャッシュにそのような構造をキャッシュすると、性能が大幅に上がります。

64 ビット コンピューターでの Java の最適な最大ヒープ サイズは、30 GB を少し超えるくらいです。このサイズを超えると、Java はヒープでオブジェクトを参照する拡張メカニズムの使用に切り替えます。このメカニズムが各オブジェクトのメモリ要件を増やし、性能を下げます。

ヒープ サイズが 30GB を超える場合、既定の Java ガベージ コレクション (同時実行のマークとスイープ) を次善の方法で実行することもできます。Elasticsearch と Lucene は既定以外に対してはテストされていないため、別のガベージ コレクションに切り替えることは現在のところ推奨されていません。

メイン メモリをディスクにスワップすると性能に深刻な影響を与えるため、メモリをオーバーコミットしないでください。可能であれば、スワップは完全に無効にしてください (詳細はオペレーティング システムによって異なります)。これができない場合は、次のように Elasticsearch 構成ファイル (elasticsearch.yml) で *mlockall* 設定を有効にします。

```yaml
bootstrap.mlockall: true
```

この構成設定により、JVM はそのメモリをロックし、オペレーティング システムによるスワップ アウトを回避します。

### ディスクとファイル システムの要件

シャードを格納するために Premium Storage のデータ ディスクを使用します。ディスクのサイズは、シャードで予想される最大量のデータを格納できるように決定してください。ただし、後でディスクを追加することもできます。ノードの複数のディスクにわたりシャードを拡張できます。

> [AZURE.NOTE] Elasticsearch は LZ4 アルゴリズムを利用して保存されるフィールドのためにデータを圧縮します。Elasticsearch 2.0 以降では、圧縮タイプを変更できます。*zip* ユーティリティと *gzip* ユーティリティで使用される DEFLATE に圧縮アルゴリズムを切り替えることができます。この圧縮方法ではリソース利用率が高くなることがありますが、アーカイブされているログ データなど、コールド インデックスには使用を検討してください。この方法では、インデックスのサイズを減らすことができます。

クラスターのすべてのノードのディスク レイアウトと容量を同じにすることは必須というわけではありません。ただし、あるノードのディスク容量が他のノードに比べて非常に大きければ、そのノードに多くのデータが集まり、それを処理するために大量の処理パワーが必要になります。結果的に、そのノードは他のノードに比べて「ホット」になり、性能に影響を与えます。

可能であれば、RAID 0 (ストライピング) を採用してください。Elasticsearch には、レプリカの形で独自の HA ソリューションが用意されているので、パリティとミラーリングを実装する他の形式の RAID は不要です。

> [AZURE.NOTE] Elasticsearch 2.0.0 より前では、*path.data* 構成設定に複数のディレクトリを指定することで、ソフトウェア レベルでストライピングを実装することもできました。Elasticsearch 2.0.0 では、この形式のストライピングは利用できません。代わりに、異なるシャードを異なるパスに割り当てることができます。ただし、1 つのシャードのすべてのファイルが同じパスに書き込まれます。**ストライピングが必要な場合は、オペレーティング システム レベルまたはハードウェア レベルでデータをストライピングしてください**。

ストレージのスループットを最大限に高めるには、各 **VM に専用の Premium Storage アカウントが必要**です。

Lucene ライブラリは大量のファイルを利用し、インデックス データを保存できます。Elasticsearch はかなりの数のソケットを開き、ノード間で通信したり、クライアントと通信したりできます。オペレーティング システムは適切な数のオープン ファイル記述子をサポートするように構成されていることを確認してください (十分なメモリが利用できる場合、最大 64000)。多くの Linux ディストリビューションの既定の構成では、オープン ファイル記述子の数が 1,024 に制限されており、これでは少なすぎることに注意してください。

Elasticsearch はメモリがマッピングされた (mmap) IO と Java New IO (NIO) I/O を組み合わせ、データ ファイルとインデックスに対する同時アクセスを最適化します。Linux を使用している場合、十分な仮想メモリと 256K のメモリ マップ領域が利用できるようにオペレーティング システムを構成してください。

> [AZURE.NOTE] 多くの Linux ディストリビューションは、ディスクにデータを書き込むように調整されているとき、Completely Fair Queuing (CFQ) スケジューラーを使用するように初期設定されています。このスケジューラーは SSD には向いていません。NOOP スケジューラーか Deadline スケジューラーを使用するようにオペレーティング システムを再設定することを検討してください。いずれも SSD で効果を発揮します。

### CPU の要件

Azure VM はさまざまな CPU 構成で利用できます。1 ～ 32 コアに対応しています。データ ノードの場合、標準の DS シリーズ VM から始め、DS3 (4 コア) または D4 (8 コア) SKU を選択することをお勧めします。DS3 は 14 GB の RAM を提供し、DS4 は 28 GB の RAM を提供します。

GS シリーズ (Premium Storage 用) と G シリーズ (Standard Storage 用) では、Xeon E5 V3 プロセッサが使用されており、大規模な集約など、大量の計算処理を必要とするワークロードで役立ちます。最新情報については、「[仮想マシンのサイズ][]」をご覧ください。

### ネットワークの要件

実装するクラスターのサイズとボラティリティに基づき、Elasticsearch は 1 ～ 10Gbps のネットワーク帯域幅を必要とします。ノードがクラスターに追加されると、Elasticsearch はノード間でシャードを移行させます。Elasticsearch では、すべてのノード間の通信時間がおおよそ等しいと想定され、ノードで保存されているシャードの相対的位置は考慮されません。また、複製がシャード間で大量のネットワーク I/O を発生させることがあります。このような理由から、**異なるリージョンにあるノードでクラスターを作成しないでください。**

### ソフトウェアの要件

Elasticsearch は Windows または Linux で実行できます。Elasticsearch サービスは Java jar ライブラリとしてデプロイされ、Elasticsearch パッケージに含まれる他の Java ライブラリに依存します。Elasticsearch を実行するには、Java 7 (更新 55 以降) または Java 8 (更新 20 以降) JVM をインストールする必要があります。

> [AZURE.NOTE] *Xmx* と *Xms* (Elasticsearch エンジンにコマンド ライン オプションとして指定 - 「[メモリの要件][]」を参照) 以外のメモリ パラメーターでは、既定の JVM 構成設定は変更されません。Elasticsearch は初期設定を利用して設計されています。変更すると、Elasticsearch の性能が下がります。

### Azure で Elasticsearch をデプロイする

1 つの Elasticsearch インスタンスをデプロイする作業は難しくありませんが、大量のノードを作成し、各ノードで Elasticsearch をインストールし、構成するのは時間がかかり、間違いが起こりやすくなります。Azure VM で Elasticsearch を実行することを検討している場合、エラーが発生する可能性の低減に役立つ 2 つの方法があります。

- [Azure Resource Manager (ARM) テンプレート](http://azure.microsoft.com/documentation/templates/elasticsearch/)を使用してクラスターを構築する: このテンプレートは完全にパラメーター化されており、ノードを実装する VM のサイズとパフォーマンス レベル、使用するディスクの数、その他の共通用意を指定できます。テンプレートでは、Windows Server 2012 または Ubuntu Linux 14.0.4 に基づくクラスターを作成できます。

- 自動実行可能なスクリプトを使用する: [Azure クイックスタート テンプレート][] サイトに、Elasticsearch クラスターを作成してデプロイできるスクリプトが用意されています。

## クラスターおよびノードの規模とスケーラビリティ 

Elasticsearch では、さまざまなデプロイメント トポロジが可能であり、さまざまな要件と規模に対応するように設計されています。このセクションでは、いくつかの共通トポロジとそのトポロジに基づいてクラスターを実装する際の考慮事項について説明します。

### Elasticsearch トポロジ

次の図は、Azure の Elasticsearch トポロジを設計するときの出発点を示しています。

![](media/guidance-elasticsearch/general-startingpoint.png)

*Azure で Elasticsearch クラスターを構築するとき推奨される出発点*

このトポロジは 6 つのデータ ノード、3 つのクライアント ノード、3 つのマスター ノードで構成されています (マスターに選ばれるノードは 1 つだけであり、その選ばれたマスターが故障した場合に、他の 2 つから選択されます)。 各ノードは別の VM として実装されます。Azure Web アプリケーションはロード バランサーを介してクライアント ノードに送られます。

この例では、すべてのノードは Web アプリケーションが同じ Azure VNET に置かれ、外の世界から効果的に隔離されます。クラスターを外部で利用する必要がある場合 (たとえば、オンプレミス クライアントを組み込むハイブリッド ソリューションの一環として)、Azure Load Balancer を利用し、パブリック IP アドレスを指定できますが、クラスターへの無許可のアクセスを防止するためにセキュリティ上の対策を増やす必要があります。

オプションの「ジャンプ ボックス」は管理者だけが利用できる VM です。この VM には Azure VNET へのネットワーク接続が与えられますが、外部に向けられたネットワーク接続も与えられ、それを利用して管理者は外部ネットワークからログインできます (このログインは強力なパスワードまたは証明書で保護する必要があります)。管理者はジャンプ ボックスにログオンし、そこからクラスターの任意のノードに直接接続できます。

代替方法として、組織と VNET の間でのサイト間 VPN の使用や、[ExpressRoute][] 回線を使用した VNET への接続などがあります。これらのメカニズムでは、クラスターを公共のインターネットに公開しなくても、クラスターに管理者アクセスできます。

VM の可用性を維持するために、データ ノードが同じ Azure 可用性セットにグループ化されます。同様に、クライアント ノードが別の可用性セットに保存され、マスター ノードが 3 番目の可用性セットに保存されます。

このトポロジは拡張が比較的簡単です。適切な種類のノードを追加し、elasticsearch.yml ファイルで同じクラスター名で構成するだけです。また、クライアント ノードは Azure ロード バランサーのバックエンド プールに追加する必要があります。

**クラスターの地理的位置検索**

**リージョンをまたいでクラスターのノードを分散させないでください。ノード間通信のパフォーマンスに影響を及ぼす可能性があります** (「[ネットワークの要件][]」を参照)。異なるリージョンのユーザーの地理的に近いデータの位置を検索するには、複数のクラスターを作成する必要があります。そのような状況では、クラスターの同期方法 (あるいは、クラスターを同期するかどうか) を考慮する必要があります。考えられる解決策:

[トライブ ノード][]は、複数の Elasticsearch クラスターに参加し、そのすべてを 1 つの大きなクラスターとして表示できる点を除き、クライアント ノードに似ています。データは各クラスターにローカル管理されますが (クラスター境界をまたいで更新が適用することはありません)、すべてのデータが表示されます。トライブ ノードはあらゆるクラスターでドキュメントを照会、作成、管理できます。

主な制約は、トライブ ノードを利用して新しいインデックスを作成できないということです。インデックスの名前はすべてのクラスターで一意にする必要があります。そのため、トライブ ノードからアクセスするクラスターを設計するときは、インデックスの命名方法を考慮することが重要になります。

このメカニズムを使用し、ローカル クライアント アプリケーションでアクセスされる可能性が最も高いデータを各クラスターに含めることができます。ただし、待ち時間が長くなるとしても、そのクライアントはリモート データにアクセスし、変更できます。次の図は、このトポロジの例を示しています。クラスター 1 のトライブ ノードが強調表示されています。その他のクラスターにもトライブ ノードを与えることができますが、図には示されていません。

![](media/guidance-elasticsearch/general-tribenode.png)

*トライブ ノードを介して複数のクラスターにアクセスするクライアント アプリケーション*

この例では、クライアント アプリケーションはクラスター 1 (同じリージョン内に併置) のトライブ ノードに接続しますが、このノードは、別のリージョンに配置されている可能性があるクラスター 2 とクラスター 3 にアクセスできるように構成されています。クライアント アプリケーションは、任意のクラスターのデータを取得または変更する要求を送信できます。

> [AZURE.NOTE] トライブ ノードは、クラスターに接続するためにマルチキャスト検出を必要とします。それはセキュリティ上の懸念事項となる可能性があります。詳細については、「[ノード検出][]」をご覧ください。

- クラスター間で geo レプリケーションを実装するこの方法では、各クラスターで行われた変更が他のデータ センターに配置されているクラスターにほぼリアルタイムで適用されます。Elasticsearch では、この機能をサポートするサード パーティのプラグイン ([PubNub Changes Plugin][] など) を使用できます。

- [Elasticsearch スナップショット/復元モジュール][]を使用する: データの動きが非常に遅く、1 つのクラスターでのみ変更される場合は、スナップショットを使用してデータの定期的なコピーを取得し、これらのスナップショットを他のクラスターで復元することを検討します ([Azure クラウド プラグイン][]がインストールされている場合は、Azure BLOB ストレージにスナップショットを保存できます)。ただし、データが急速に変化する場合やデータが複数のクラスターで変更される場合、この解決策はうまく機能しません。

**小規模トポロジ**

専用マスター、クライアント、データ ノードのクラスターで構成されている大規模トポロジは一部のシナリオには適していません。小規模の運用システムまたは開発システムを構築している場合、次の図に示す 3 ノード クラスターを検討してください。

クライアント アプリケーションは、クラスター内で利用できる任意のデータ ノードに直接接続します。クラスターには、P1 ～ P3 というラベルが付いた 3 つのシャード (増加を考慮) と R1 ～ R3 というラベルが付いたレプリカが含まれます。3 つのノードを使用することで、1 つのノードが故障してもデータが失われないように Elasticsearch はシャードとレプリカを配信できます。

![](media/guidance-elasticsearch/general-threenodecluster.png)

*3 つのシャードとレプリカが含まれる 3 ノード クラスター*

スタンドアロン コンピューターで開発環境を実行している場合、マスター、クライアント、データ ストレージとして機能する 1 つのノードでクラスターを構成できます。あるいは、同じコンピューターで複数のノードをクラスターとして実行できます。Elasticsearch の複数のインスタンスを起動します。次の図に例を示します。

![](media/guidance-elasticsearch/general-developmentconfiguration.png)

*複数の Elasticsearch ノードを同じコンピューターで実行する開発構成*

いずれのスタンドアロン構成も運用環境には推奨されません。開発マシンに大量のメモリと複数の高速ディスクが搭載されていない限り、競合を引き起こす可能性があるためです。また、高い可用性が保証されません。マシンが故障すると、すべてのノードが失われます。

### クラスター ノードとデータ ノードの拡張

Elasticsearch は垂直 (大きく高性能なマシンを利用) と水平 (マシン間で負荷を分散) の 2 つの次元で拡張できます。

**Elasticsearch データ ノードを垂直方向に拡張する**

Azure VM を使用して Elasticsearch クラスターをホストしている場合、各ノードが 1 つの VM に対応できます。ノードの垂直拡張性の上限は、大部分は、VM の SKU と、個々のストレージ アカウントと Azure サブスクリプションに適用される全体的制約によって決まります。

「[Azure サブスクリプションとサービスの制限、クォータ、制約](azure-subscription-service-limits/)」で、これらの上限について詳しく説明していますが、Elasticsearch クラスターの構築に関する限り、次に示す項目が最も関連します。

- 各ストレージ アカウントは 20,000 IOPS に制限されています。クラスターの各 VM で専用の (できれば Premium) ストレージ アカウントを利用します。

- VNET 内のデータ ノード数。Azure リソース マネージャー (ARM) を使用していない場合、VNET あたりの VM インスタンス上限は 2048 になります。多くの場合、これで十分ですが、数千のノードが含まれる非常に大きな構成では、これが制約になることがあります。

- リージョン別のサブスクリプションあたりのストレージ アカウント数。リージョン別の Azure サブスクリプションあたり、最大 100 のストレージ アカウントを作成できます。ストレージ アカウントを使用して仮想ディスクが保持されます。各ストレージ アカウントには、500 TB の容量制限があります。

- サブスクリプションあたりのコア数。既定の上限はサブスクリプションあたり 20 コアですが、サポート チケットを使用して上限の引き上げを要求することで最大 10,000 コアまで増やすことができます。

- VM サイズあたりのメモリ量。VM のサイズが小さければ、利用できるメモリ量が限られます (D1 マシンは 3.5GB で、D2 マシンは 7GB です)。このようなマシンは、良好なパフォーマンスを得るために Elasticsearch で大量のデータをキャッシュする必要があるシナリオ (データの集約や、データ取り込み中の大量のドキュメントの分析など) には適していません。

- VM サイズあたりの最大ディスク数。この制約によりクラスターのサイズとパフォーマンスを制限できます。ディスクが少なければ、保持できるデータも少なくなります。ストライピングに利用できるディスクが少ないと、パフォーマンスが低下する可能性があります。

- 可用性セットあたりの更新ドメイン/障害ドメインの数。ARM を利用して VM を作成する場合、最大 3 つの障害ドメインと 20 の更新ドメインに各可用性セットを割り当てることができます。この制限は、頻繁に繰り返される更新の対象となる大規模クラスターの回復力に影響を与えます。

また、メモリが 64 GB を超える VM は使用しないことをお勧めします。「[メモリの要件][]」で説明したように、各 VM の 30 GB を超える RAM を JVM に割り当てないようにすると、オペレーティング システムが残りのメモリを I/O バァッファリングに使用できるようになります。

これらの制約を念頭に置き、常にストレージ アカウントをまたいで VM の仮想ディスクを分散し、I/O スロットルの可能性を減らしてください。非常に大規模なクラスターでは、論理インフラストラクチャの設計をやり直し、個々の機能パーティションに分割しなければならないことがあります。たとえば、サブスクリプションをまたいでクラスターを分割しなければならないことがあります。VNET を接続するため、そのプロセスはさらに複雑になることがあります。

**Elasticsearch クラスターを水平方向に拡張する**

Elasticsearch の内部では、水平拡張性の上限は各インデックスに定義されているシャードの数で決定します。最初に多くのシャードをクラスターの同じノードに割り当てることができます。データの量が増えたら、ノードを追加し、シャードをノード全体で分散できます。理論上、ノードの数がシャードの数に達した場合にのみ、水平方向の拡張が止まります。

垂直方向の拡張と同様に、水平方向の拡張を実装するときは、次のような問題を考慮する必要があります。

- Azure VNET で接続できる VM の最大数。非常に大規模なクラスターの場合、これが水平拡張性の上限となります。この上限を回避するために複数の VNET をまたぐノード クラスターを作成できますが、その手法では、各ノードとそのピアにローカリティがないため、パフォーマンスが下がることがあります。

- VM サイズあたりのディスクの数。シリーズと SKU によっては、接続されるディスクの数が異なります。また、VM に付属する短期ストレージを利用し、高速データ ストレージの量を限定することも検討できます。ただし、その場合、復元性と回復について考慮する必要があります (詳細については、「Configuring, Testing, and Analyzing Elasticsearch Resilience and Recovery (Elasticsearch の復元性と回復の構成、テスト、分析)」を参照してください)。D シリーズ、DS シリーズ、Dv2 シリーズ、GS シリーズの VM では、短期ストレージに SSD が使用されます。

必要に応じて、Azure スケール セットを使用して VM を起動/停止することを検討してください (詳細については、「[仮想マシン スケール セットでのマシンの自動スケール][]」をご覧ください)。ただし、次の理由から、この方法は Elasticsearch クラスターに適さない場合があります。

- この方法はステートレス VM に最適です。Elasticsearch クラスターとの間でノードを追加または削除するたびに、シャードの割り当てが変更され、負荷が分散されます。このプロセスでは、大量のネットワーク トラフィックとディスク I/O が生成されることがあり、データ取り込みレートに深刻な影響を与えます。そのような影響があるとしても、動的に起動する VM を増やすことで利用可能な処理リソースとメモリ リソースが増えるという利点で相殺されるかどうかを評価する必要があります。

- VM は瞬時には起動しません。追加 VM が利用可能になるまで、あるいはシャットダウンされるまで数分かかることがあります。長引く需要の変化に対応しなければならない場合にのみ、この方法で拡張してください。

- 拡張後、実際に縮小を検討しなければならないことがありますか。 Elasticsearch クラスターから VM を削除する作業はリソースが集中的に使用されるプロセスであり、その VM に配置されているシャードとレプリカを復元し、1 つまたは複数の残りのノードでそれらを再作成することが Elasticsearch に要求されます。複数の VM を同時に削除すると、クラスターの統合性が崩れ、復元が難しくなることがあります。また、多くの Elasticsearch 実装は時間の経過と共に大きくなりますが、データの性質上、量の面では少なくならない傾向があります。ドキュメントは手動で削除できます。また、ドキュメントに TTL (Time to Live/有効時間) を設定できます。有効時間が過ぎると、ドキュメントは削除されます。ただし、ほとんどの場合、前もって割り当てられている領域は新しいドキュメントや変更されたドキュメントによりすぐに再利用されます。ドキュメントが削除または変更されると、インデックス内に断片化が発生することがあります。その場合、Elasticsearch HTTP [Optimize][] API (Elasticsearch 2.0.0 以前) または [Force Merge][] API (Elasticsearch 2.1.0 以降) を使用して最適化を実行できます。

### インデックスのシャードの数を決定する

クラスター内のノードの数は時間の経過と共に変わりますが、インデックス内のシャードの数はインデックスの作成後は変わりません。シャードを追加または削除するには、データのインデックスを再作成する必要があります。必要な数のシャードで新しいインデックスを作成し、古いインデックスから新しいインデックスにデータをコピーします (エイリアスを使用して、データのインデックスが再作成されたことをユーザーから隠すことができます。詳細については、「[Tuning data aggregation and Query Performance with Elasticsearch on Azure][]」をご覧ください)。そのため、クラスターで最初のインデックスを作成する前に、必要となりそうなシャードの数を決定することが重要です。次の手順でこの数を決定できます。

- 本稼働でデプロイする予定のものと同じハードウェア構成を利用し、シングル ノードのクラスターを作成します。

- 本稼働で使用する予定の構造に一致するインデックスを作成します。このインデックスにシャードを 1 つ与えます。レプリカは与えません。

- 特定の量の現実的運用データをインデックスに追加します。

- 一般的なクエリ、集約、その他のワークロードをインデックスに対して実行し、スループットと応答時間を計測します。

- スループットと応答時間が許容範囲内であれば、手順 3 (データを追加) からプロセスを繰り返します。

- シャードの容量に到達したようであれば (応答時間とスループットが許容範囲を超えたら)、ドキュメントの量をメモします。

- 1 つのシャードの容量から本稼働で予想されるドキュメントの数を推定し、必要な数のシャードを計算します (この推定は科学的に正確ではないため、計算には許容誤差を含めてください)。

> [AZURE.NOTE] 各シャードは Lucene インデックスとして実装され、メモリ、CPU パワー、ファイル ハンドルを利用することに注意してください。シャードの数が多ければ、それだけ多くのリソースが必要になります。

また、作成するシャードが多ければ、拡張性が上がり、データ取り込みのスループットが増えます (ワークロードとシナリオにもよります)。ただし、多くのクエリで効率性が下がることがあります。既定では、クエリはインデックスで使用されるすべてのシャードに問い合わせます (必要なデータが配置されているシャードがわかっている場合は、[カスタム ルーティング][]を使用してこの動作を変更できます)。

このプロセスではシャードの数の見積もりのみが生成されます。本稼働で予想されるドキュメントの量はわからないことがあります。その場合、(上記の) 初回の量と予想される増加率を決定してください。データベースのインデックスを変更する余裕ができるまでの期間のデータ増加を処理できる数のシャードを作成します。

イベント管理やログ記録などのシナリオに使用されるその他の方法には、インデックスの繰り返し利用などがあります。毎日取り込まれるデータに新しいインデックスを作成し、最新のインデックスを指すように毎日切り替えられるエイリアスを介してこのインデックスにアクセスします。この方法では、古いデータをさらに簡単に削除することができ (不要になった情報を含むインデックスを削除できます)、データ量を管理しやすくなります。

ノードの数とシャードの数は一致する必要がないことに注意してください。たとえば、50 のシャードを作成する場合、最初に 10 のノードにそれらのシャードを分散し、その後、作業量の増加に合わせてノードを追加し、システムを拡張できます。少数のノードに対して非常に多くのシャードを作成することは避けます (2 つのノードに 1,000 個のシャードを分散させるなど)。この構成では、理論上、1000 ノードまでシステムを拡張できますが、1 つのノードで 500 のシャードを実行すると、ノードの性能が落ちることがあります。

> [AZURE.NOTE] データの取り込みが激しいシステムの場合、素数のシャードを使用することを検討してください。その場合、ドキュメントをシャードに送信するために Elasticsearch で使用される既定のアルゴリズムでは、分散がさらに均等になります。

### セキュリティ

既定では、Elasticsearch は最小限のセキュリティを実装し、認証と権限承認の手段を提供しません。そのような側面から、基礎となるオペレーティング システムとネットワークを構成し、プラグインとサードパーティー ユーティリティを使用する必要があります。たとえば、[Shield][] や [Search Guard][] が使用されます。

> [AZURE.NOTE] Shield は Elastic が提供するユーザー認証、データ暗号化、ロール ベースのアクセス制御、IP フィルタリング、監査のプラグインです。場合によっては、ディスク暗号化など、他のセキュリティ対策を実装するように基礎オペレーティング システムを構成する必要があります。

運用システムでは、次の方法を検討する必要があります。

- クラスターへの不正アクセスを防止する。
- ユーザーを識別し、認証する。
- 認証されたユーザーに操作を実行する権限を与える。
- 不正操作またはシステムを壊す操作からクラスターを守る。
- 不正アクセスからデータを守る。
- 商用データ セキュリティの規制要件を満たす (適切な場合)

### クラスターへのアクセスを保護する

Elasticsearch はネットワーク サービスです。Elasticsearch クラスター内のノードは HTTP を利用してクライアント要求が入ってくるのを待ち、TCP チャンネルを利用して互いに通信します。許可のないクライアントが HTTP パスと TCP パスの両方で要求を送信するの防止するための対策をとる必要があります。次の項目について検討してください。

VNET または VM の受信/送信ネットワーク トラフィックを特定のポートのみに限定するネットワーク セキュリティ グループを定義します。

クライアント Web アクセス (9200) とプログラムによるネットワーク アクセス (9300) に使用される既定のポートを変更します。ファイアウォールを使用し、悪意のあるインターネット トラフィックから各ノードを保護します。

クライアントの場所と接続に基づき、インターネットに直接アクセスしないプライベート サブネットにクラスターを配置します。クラスターをサブネットの外に公開しなければならない場合、クラスターを守るための対策が施された中継 (Bastion) サーバーやプロキシを経由してすべての要求を送信します。

ノードに直接アクセスを与える必要がある場合、Elasticsearch Jetty プラグインを利用し、SSL 接続、認証、接続ログを提供します。あるいは、nginx プロキシ サーバーを構成し、HTTPS 認証を構成します。

> [AZURE.NOTE] nginx などのプロキシ サーバーを利用し、アクセスを機能に制限することもできます。たとえば、検索エンドポイントへの要求のみを許可するように nginx を構成し、クライアントが他の操作を実行するのを防止できます。

包括的なネットワーク アクセス セキュリティを増やす必要がある場合、Shield プラグインか Search Guard プラグインを使用します。

### ユーザーを識別し、認証する

クライアントからクラスターへの要求はすべて認証する必要があります。また、許可のないノードがクラスターに参加するのを防ぐ必要があります。システムへのバックドアを与え、認証が迂回されることがあります。

さまざまな種類の認証を実行する次のような Elasticsearch プラグインを利用できます。

- **HTTP 基本認証**: 認証のたびにユーザー名とパスワードが要求されます。SSL/TLS または同等レベルの保護ですべての要求を暗号化する必要があります。

- **LDAP と Active Directory の統合**: この方法では、LDAP または AD グループのロールをクライアントに割り当てる必要があります。

- **ネイティブ認証**: Elasticsearch クラスター内で定義されている ID を使用します。

- **TLS 認証**: クラスター内ですべてのノードを認証します。

- **IP フィルタリング**: 承認されていないサブネットのクライアントが接続できないようにします。また、これらのサブネットのノードがクラスターに参加できないようにします。

### クライアントの要求を承認する

認証は、このサービスの提供に使用される Elasticsearch プラグインに依存します。たとえば、基本認証を与えるプラグインは、一般的に、認証のレベルを定義する機能を与えます。LDAP または AD を使用するプラグインは、一般的に、クライアントをロールに関連付け、そのロールにアクセス権を割り当てます。どのプラグインを使用する場合も、次の点を考慮してください。

- クライアントが実行できる操作を制限する必要があるか。 たとえば、クライアントがクラスターの状態を監視したり、インデックスを作成および削除したりできる必要があるか。

- クライアントを特定のインデックスに制限する必要があるか。 これは、マルチテナント環境でテナントに独自のインデックス セットを割り当て、それらのインデックスに他のテナントがアクセスできないようにする場合に役立ちます。

- クライアントがインデックスに対するデータの読み取り/書き込みを実行できる必要があるか。 たとえば、インデックスを利用したデータ検索を実行する許可をクライアントに与えるが、そのインデックスにデータを追加したり、インデックスからデータを削除したりする権限は与えません。

現在のところ、ほとんどのセキュリティ プラグインにおいて、クラスターまたはインデックス レベルで操作が制御されます。インデックス内のドキュメント サブセット レベルでは制御されません。これは効率性の面からの処置です。そのため、1 つのインデックス内の特定のドキュメントに要求を制限することは簡単ではありません。そのレベルの細かな制御が必要な場合、ドキュメントを個別のインデックスに保存し、インデックスをグループにまとめるエイリアスを使用します。

たとえば、人事システムで、ユーザー A は部署 X の社員に関する情報が含まれるすべてのドキュメントにアクセスする必要があり、ユーザー B は部署 Y の社員に関する情報が含まれるすべてのドキュメントにアクセスする必要があり、ユーザー C は両方の部署の社員に関する情報が含まれるすべてのドキュメントにアクセスする必要がある場合、2 つのインデックス (部署 X 用と部署 Y 用) と両方のインデックスを参照するエイリアスを作成します。ユーザー A に最初のインデックスへの読み取りアクセスを与え、ユーザー B に 2 番目のインデックスへの読み取りアクセスを与え、ユーザー C にエイリアス経由で両方のインデックスへの読み取りアクセスを与えます。詳細については、「[Faking Index per User with Aliases][]」をご覧ください。

### クラスターを保護する

クラスターは厳重に保護しないと悪用されやすくなる可能性があります。

セキュリティの脆弱性につながるおそれがあるため、**Elasticsearch クエリの動的クエリ スクリプティングを無効にします**。クエリ スクリプティングではなく、ネイティブ スクリプトを使用します。ネイティブ スクリプトは Java で記述され、JAR ファイルにコンパイルされた Elasticsearch プラグインです。

現在のところ、動的クエリ スクリプティングは既定では無効になっています。相当な理由がない限り、有効にしないでください。

**クエリ文字列の検索をユーザーに公開しないでください**。クエリ文字列の検索では、ユーザーはリソースを大量に使用するクエリを妨げられることなく実行できます。そのような検索はクラスターのパフォーマンスに深刻な影響を与え、システムが DOS 攻撃にさらされることがあります。また、クエリ文字列検索では、個人情報が漏洩する可能性があります。

**操作で大量のメモリが使用されないようにします**。メモリ不足の例外が発生し、ノードで Elasticsearch のエラーが発生する可能性があります。大量のリソースを使用する操作を長時間続けた場合も、DOS 攻撃を招くことがあります。たとえば、次のようになります。

非常に大規模なフィールドをメモリに読み込む検索要求を回避します (クエリでこれらのフィールドに対して並べ替え、スクリプト、またはファセットを実行する場合)。次に例を示します。

- 複数のインデックスに同時に問い合わせる検索。

- 大量のフィールドを読み出す検索。そのような検索は膨大な量のフィールド データをキャッシュさせ、メモリを使い果たします。既定では、フィールド データ キャッシュのサイズは無制限ですが、elasticsearch.yml 構成ファイルで [indices.fielddata.cache.*](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-fielddata.html) プロパティを設定して利用できるリソースを制限できます。また、[フィールド データ サーキット ブレーカー][]を構成して、1 つのフィールドからキャッシュされたデータがメモリを使い果たすのを防いだり、[要求サーキット ブレーカー][]を構成して、個々のクエリがメモリを占有するのを阻止したりできます。このようなパラメーターを設定すると、クエリが失敗したり、タイムアウトになったりする可能性が増えます。
 
> [AZURE.NOTE] [Doc 値][]を使用すると、フィールド データをメモリに読み込むのではなく、ディスクに保存することで、インデックスのメモリ要件を減らすことができます。ノードでメモリが使い尽くされる可能性が少なくなりますが、速度は落ちます。

> [AZURE.NOTE] Elasticsearch では常に、現在のワークロードを実行するために必要なメモリがあるものと想定されます。メモリが不足すると、Elasticsearch サービスはクラッシュします。Elasticsearch には、リソース使用状況に関する情報を返すエンドポイント (HTTP [cat API][]) が用意されているので、この情報を入念に監視してください。

**進行中のメモリ セグメントをフラッシュするまでの待機時間が長すぎる**。これによりメモリ内バッファー領域を使い果たすことがあります。必要に応じて、データがディスクにフラッシュされるしきい値を減らすように [translog を構成][]します。

**大量のメタデータでインデックスを作成する**。フィールド名のバリエーションが多いドキュメントがインデックスに含まれると、たくさんのメモリが使用されます。詳細については、「[Mapping Explosion][]」をご覧ください。
  
長時間操作やクエリ集中操作の定義はシナリオによって変わります。あるクラスターで一般的に予想されるワークロードのプロファイルは別のクラスターのワークロードとはまったく異なる可能性があります。許容されない操作を決定するには、アプリケーションの広範囲の調査とテストが必要です。

先を見越す。大きな損害やデータの紛失を引き起こされる前に悪意のある行為を検出し、止めます。通常とは異なるデータ アクセス パターンをすばやく検出し、ユーザーのログイン要求が失敗したり、予想されていないノードがクラスターに参加したり、クラスターから離れたり、操作に想定外の長い時間がかかったりしたときに警告を発するようなセキュリティの監視と通知のシステムを利用することを検討してください。このようなタスクを実行できるツールとして、Elasticsearch [Watcher][] などがあります。

### データを保護する

SSL/TLS を利用して転送中のデータを保護できますが、Elasticsearch では、ディスクに保存されている情報を暗号化する機能が組み込まれていません。情報は普通のディスク ファイルに保存されます。そのファイルにアクセスできるユーザーはファイル内のデータを危険にさらすことがあります。たとえば、自分のクラスターにコピーできます。次の点を考慮してください。

- データを保持するために Elasticsearch で使用されるファイルを保護します。Elasticsearch 以外の ID に任意の読み取りまたは書き込みアクセスを許可しないでください。

- 暗号化ファイル システムを利用し、ファイルに保存されているデータを暗号化します。

> [AZURE.NOTE] Azure では、Linux と Windows の VM のディスク暗号化がサポートされるようになりました。詳細については、「[Windows および Linux IaaS VM プレビューの Azure Disk Encryption][]」をご覧ください。

### 規制要件を満たす

規制要件は主に、イベントの履歴を保守管理する監査操作に関連します。そのような操作のプライバシーを守ることで、外部機関による監視 (または再現) を回避できます。特に、次の方法について検討する必要があります。

- (成功と失敗に関係なく) すべての要求とシステムへのすべてのアクセス試行を追跡記録する方法。

- クライアントがクラスターに行う通信とクラスターが実行するノード間の通信を暗号化する方法。あらゆるクラスター通信に SSL/TLS を実装してください。Elasticsearch では、SSL/TLS を介して利用できるものと組織の要件が異なる場合、プラグ可能な暗号もサポートしています。

- あらゆる監査データを安全に保管する方法。監査情報は急速に増加します。監査情報の改ざんを防ぐために、堅牢な方法で保護する必要があります。

- 監査データを安全にアーカイブする方法。

### Monitoring

監視はオペレーティング システム レベルと Elasticsearch レベルの両方で重要です。

オペレーティング システム固有のツールを利用し、オペレーティング システム レベルで監視できます。Windows の場合、パフォーマンス モニターとパフォーマンス カウンターなどを利用できます。Linux の場合、*vmstat*、*iostat*、*top* などのツールを利用できます。オペレーティング システムで監視する主要な項目は、CPU 利用率、ディスク I/O ボリューム、ディスク I/O 待機時間、ネットワーク トラフィックなどです。効果的に調整された Elasticsearch クラスターでは、Elasticsearch プロセスの CPU 利用率は高く、ディスク I/O 待機時間は最小限に抑えられるはずです。

ソフトウェア レベルでは、要求のスループットと応答時間、失敗した要求の詳細を監視する必要があります。Elasticsearch にはさまざまな API があります。それを利用し、クラスターのさまざまな側面のパフォーマンスを観察できます。2 つの最も重要な API は *\_cluster/health* と *\_nodes/stats* です。*\_cluster/health* API を利用し、クラスターの全体的健全性のスナップショットを撮影できます。次の例のように、インデックスごとの詳細が表示されます。

`GET _cluster/health?level=indices`

次の出力例はこの API を使用して生成されました。

```json
{
    "cluster_name": "elasticsearch",
    "status": "green",
    "timed_out": false,
    "number_of_nodes": 6,
    "number_of_data_nodes": 3,
    "active_primary_shards": 10,
    "active_shards": 20,
    "relocating_shards": 0,
    "initializing_shards": 0,
    "unassigned_shards": 0,
    "delayed_unassigned_shards": 0,
    "number_of_pending_tasks": 0,
    "number_of_in_flight_fetch": 0,
    "indices": {
        "systwo": {
            "status": "green",
            "number_of_shards": 5,
            "number_of_replicas": 1,
            "active_primary_shards": 5,
            "active_shards": 10,
            "relocating_shards": 0,
            "initializing_shards": 0,
            "unassigned_shards": 0
        },
        "sysfour": {
            "status": "green",
            "number_of_shards": 5,
            "number_of_replicas": 1,
            "active_primary_shards": 5,
            "active_shards": 10,
            "relocating_shards": 0,
            "initializing_shards": 0,
            "unassigned_shards": 0
        }
    }
}
```

このクラスターには、2 つのインデックス (*systwo* と *sysfour*) があります。インデックスごとに監視する主要な統計値は status、active\_shards、unassigned\_shards です。ステータスは緑でなければなりません。active\_shards の数は number\_of\_shards と number\_of\_replicas を反映している必要があります。unassigned\_shards はゼロでなければなりません。

ステータスが「赤」の場合、インデックスの一部が欠けているか、壊れています。*active\_shards* 設定が *number\_of\_shards* - (*number\_of\_replicas* + 1) より小さく、unassigned\_shards がゼロ以外の場合、インデックスは破損しています。黄のステータスはインデックスが遷移状態にあることを示します。レプリカを追加したか、シャードの位置を変更したためです。繊維が完了すると、ステータスが緑に切り替わります。

長時間にわたり黄のままか、赤に変わった場合、オペレーティング システム レベルで重大な I/O イベントが発生していないか確認してください (ディスクやネットワークの故障など)。

\_nodes/stats API はクラスターの各ノードに関する広範囲の情報を出します。

`GET _nodes/stats`

生成される出力には、各ノードに保存されたインデックスに関する詳細 (ドキュメントのサイズや数など)、インデックスの作成、クエリ、検索、結合、キャッシュにかかった時間、オペレーティング システムとプロセスの情報、JVM に関する統計値 (ガベージ コレクションのパフォーマンスを含む)、スレッド プールなどがあります。詳細については、「[Monitoring Individual Nodes][]」をご覧ください。

Elasticsearch 要求の大部分が失敗し、*EsRejectedExecutionException* エラー メッセージが表示された場合、Elasticsearch は送信された処理に対応できなくなっています。その場合、Elasticsearch が後れをとる理由となっているボトルネックを特定する必要があります。次の項目について検討してください。

- ボトルネックがリソースの制約に起因する場合は、追加リソースの割り当てを検討します。たとえば、JVM に割り当てられているメモリが不十分なために過剰な数のガベージ コレクションが発生する場合、さらに多くのメモリを使用するように JVM を構成します。ノードで使用できるストレージの 50% まで使用できます (「[メモリの要件][]」をご覧ください)。

- クラスターが示す I/O 待機時間が長く、\_node/stats API を利用して回収された結合統計値に含まれる値が大きい場合、インデックスの書き込みが大量になっています。「[Optimizing Resources for Indexing Operations](guidance-elasticsearch-tuning-data-ingestion-performance.md#optimizing-resources-for-indexing-operations)」に記載されている注意点を見直して、インデックス作成のパフォーマンスを調整してください。

- データ取り込み操作を実行しているクライアント アプリケーションを調整し、その効果を確認します。この方法で大幅な改善が見られる場合、その調整を維持するか、書き込みが多いインデックスの負荷を分散するノードを増やすことを検討してください。詳細については、「[Tuning data ingestion performance for Elasticsearch on Azure][]」をご覧ください。

- インデックスの検索統計値から、クエリに時間がかかりすぎることが示された場合、クエリを最適化する方法を検討してください。詳細については、「[Query Tuning][]」をご覧ください。検索統計で報告された *query\_time\_in\_millis* 値と *query\_total* 値を使用して、クエリの効率性のおおよその目安を計算できます。*query\_time\_in\_millis* / *query\_total* という式で各クエリの平均時間がわかります。

### Elasticsearch を監視するためのツール

さまざまなツールを利用し、本稼働の Elasticsearch を毎日監視できます。これらのツールでは、通常、基礎となる Elasticsearch API を利用して情報を収集し、生データよりも観察しやすい方法で詳細を提示します。一般的な例としては、[Elasticsearch-Head][]、[Bigdesk][]、[Kopf][]、[Marvel][] などがあります。

Elasticsearch-Head、Bigdesk、Kopf は Elasticsearch ソフトウェアのプラグインとして実行されます。Marvel の最新バージョンは単独で実行できますが、データ キャプチャおよびホスティング環境を提供するには [Kibana][] が必要です。Marvel と Kibana を使用する利点は、Elasticsearch クラスターとは離れた環境に監視を実装できるということです。監視ツールが Elasticsearch ソフトウェアの一部として実行されている場合は発見できないような問題を Elasticsearch で見つけることができます。たとえば、Elasticsearch が繰り返し失敗したり、動作が非常に遅かったりする場合、Elasticsearch プラグインとして実行されるツールも影響を受け、監視と診断が難しくなります。

オペレーティング システム レベルでは、[Azure Operations Management Suite][] のログ分析機能や [Azure ポータルの Azure 診断][]などのツールを使用して、Elasticsearch ノードをホストしている VM のパフォーマンス データをキャプチャできます。もう 1 つの方法は、[Logstash][] を使用してパフォーマンスとログのデータをキャプチャし、この情報を別の Elasticsearch クラスターに保存して (アプリケーションに使用しているクラスターと同じクラスターを使用しないでください)、Kibana でデータを視覚化することです。詳細については、「[Microsoft Azure Diagnostics with ELK][]」をご覧ください。

### Elasticsearch パフォーマンスをテストするためのツール

Elasticsearch をベンチマーク解析するか、クラスターのパフォーマンス テストを実行する場合、他のツールを利用できます。これらのツールは、運用環境ではなく、開発またはテスト環境で使用するためのものです。頻繁に使用されるツールの例として [Apache JMeter][] があります。

JMeter は、このガイドに関連するドキュメントで説明されているベンチマーク解析や他の負荷テストに使用されました。これらのテストでの JMeter の構成と使用方法の詳細については、「[Azure での Elasticsearch のパフォーマンス テスト環境の作成][]」をご覧ください。

## 次のステップ

- [Elasticsearch: 決定版ガイド](https://www.elastic.co/guide/en/elasticsearch/guide/master/index.html)

[Running Elasticsearch on Azure]: guidance-elasticsearch-running-on-azure.md
[Tuning Data Ingestion Performance for Elasticsearch on Azure]: guidance-elasticsearch-tuning-data-ingestion-performance.md
[Azure での Elasticsearch のパフォーマンス テスト環境の作成]: guidance-elasticsearch-creating-performance-testing-environment.md
[Implementing a JMeter Test Plan for Elasticsearch]: guidance-elasticsearch-implementing-jmeter-test-plan.md
[Deploying a JMeter JUnit Sampler for Testing Elasticsearch Performance]: guidance-elasticsearch-deploying-jmeter-junit-sampler.md
[Tuning data aggregation and Query performance with Elasticsearch on Azure]: guidance-elasticsearch-tuning-data-aggregation-and-query-performance.md
[Configuring Resilience and Recovery on Elasticsearch on Azure]: guidance-elasticsearch-configuring-resilience-and-recovery.md
[Running the Automated Elasticsearch Resiliency Tests]: guidance-elasticsearch-configuring-resilience-and-recovery

[Apache JMeter]: http://jmeter.apache.org/
[Apache Lucene]: https://lucene.apache.org/
[仮想マシン スケール セットでのマシンの自動スケール]: virtual-machines-vmss-walkthrough/
[Windows および Linux IaaS VM プレビューの Azure Disk Encryption]: azure-security-disk-encryption/
[Azure Load Balancer]: load-balancer-overview/
[ExpressRoute]: expressroute-introduction/
[内部ロード バランサー]: load-balancer-internal-overview/
[仮想マシンのサイズ]: virtual-machines-size-specs/

[メモリの要件]: #memory-requirements
[ネットワークの要件]: #network-requirements
[ノード検出]: #node-discovery
[Query Tuning]: #query-tuning

[A Highly Available Cloud Storage Service with Strong Consistency]: http://blogs.msdn.com/b/windowsazurestorage/archive/2011/11/20/windows-azure-storage-a-highly-available-cloud-storage-service-with-strong-consistency.aspx
[Azure クラウド プラグイン]: https://www.elastic.co/blog/azure-cloud-plugin-for-elasticsearch
[Azure ポータルの Azure 診断]: https://azure.microsoft.com/blog/windows-azure-virtual-machine-monitoring-with-wad-extension/
[Azure Operations Management Suite]: https://www.microsoft.com/server-cloud/operations-management-suite/overview.aspx
[Azure クイックスタート テンプレート]: https://azure.microsoft.com/documentation/templates/
[Bigdesk]: http://bigdesk.org/
[cat API]: https://www.elastic.co/guide/en/elasticsearch/reference/1.7/cat.html
[translog を構成]: https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-translog.html
[カスタム ルーティング]: https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-routing-field.html
[Doc 値]: https://www.elastic.co/guide/en/elasticsearch/guide/current/doc-values.html
[Elasticsearch]: https://www.elastic.co/products/elasticsearch
[Elasticsearch-Head]: https://mobz.github.io/elasticsearch-head/
[Elasticsearch.Net と NEST]: http://nest.azurewebsites.net/
[Elasticsearch スナップショット/復元モジュール]: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html
[Faking Index per User with Aliases]: https://www.elastic.co/guide/en/elasticsearch/guide/current/faking-it.html
[フィールド データ サーキット ブレーカー]: https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-fielddata.html#fielddata-circuit-breaker
[Force Merge]: https://www.elastic.co/guide/en/elasticsearch/reference/2.1/indices-forcemerge.html
[ゴシップ プロトコル]: https://en.wikipedia.org/wiki/Gossip_protocol
[Kibana]: https://www.elastic.co/downloads/kibana
[Kopf]: https://github.com/lmenezes/elasticsearch-kopf
[Logstash]: https://www.elastic.co/products/logstash
[Mapping Explosion]: https://www.elastic.co/blog/found-crash-elasticsearch#mapping-explosion
[Marvel]: https://www.elastic.co/products/marvel
[Microsoft Azure Diagnostics with ELK]: https://github.com/mspnp/semantic-logging/tree/elk
[Monitoring Individual Nodes]: https://www.elastic.co/guide/en/elasticsearch/guide/current/_monitoring_individual_nodes.html#_monitoring_individual_nodes
[nginx]: http://nginx.org/en/
[ノード クライアント API]: https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/node-client.html
[Optimize]: https://www.elastic.co/guide/en/elasticsearch/reference/1.7/indices-optimize.html
[PubNub Changes Plugin]: http://www.pubnub.com/blog/quick-start-realtime-geo-replication-for-elasticsearch/
[要求サーキット ブレーカー]: https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-fielddata.html#request-circuit-breaker
[Search Guard]: https://github.com/floragunncom/search-guard
[Shield]: https://www.elastic.co/products/shield
[トランスポート クライアント API]: https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/transport-client.html
[トライブ ノード]: https://www.elastic.co/blog/tribe-node
[Watcher]: https://www.elastic.co/products/watcher
[Zen]: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-zen.html

<!---HONumber=AcomDC_0224_2016-->