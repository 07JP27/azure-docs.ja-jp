<properties
   pageTitle="Azure で Elasticsearch を実行する | Microsoft Azure"
   description="Azure に Elasticsearch をインストールし、構成し、実行する方法。"
   services=""
   documentationCenter="na"
   authors="mabsimms"
   manager="marksou"
   editor=""
   tags=""/>

<tags
   ms.service="guidance"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="02/05/2016"
   ms.author="mabsimms"/>

# Azure で Elasticsearch を実行する

これは[一連の記事の一部](guidance-elasticsearch-introduction.md)です。

## 概要

Elasticsearch は拡張性の高いオープン ソースの検索エンジンとデータベースです。大規模なデータセットに含まれる情報を高速で検索し、分析する場合に最適です。一般的なシナリオは、次のとおりです。

- 大規模な全文検索。検索語句の組み合わせに一致する文書をすばやく検索できます。
- イベントのログ記録。さまざまな情報源から情報が得られます。場合によっては、一連のイベントが特定の結論に導かれた経緯を解明するために、データを分析する必要があります。
- リモート デバイスやその他のソースから取得されたデータの格納。データにはさまざまな情報が含まれますが、共通の要件は、オペレーターがシステム全体の状態を理解できるように、一連のダッシュボードにこの情報を表示することです。アプリケーションでも情報を利用し、データの流れと結果として実行しなければならない事業活動についてすばやく決定できます。
- 在庫管理。商品が販売されると、在庫の変更が記録されます。ビジネス システムでこの情報を利用し、在庫状況を利用者に報告したり、製品の在庫が少なくなった場合に再発注したりできます。アナリストはデータを分析して傾向をとらえ、製品がよく売れる状況を見つけ出すことができます。
- 財務分析。市場情報がほぼリアルタイムで届きます。さまざまな金融商品の最新状況を示すダッシュボードを生成し、それを利用して買い/売りを決定できます。

この記事では、Elasticsearch の一般的構造を簡単に説明し、Azure を使用して Elasticsearch クラスターを実装する方法について説明します。この記事では主に、Elasticsearch クラスターのデプロイのベスト プラクティスを紹介します。システムのさまざまな機能的パフォーマンス/管理要件を取り上げ、要件に基づき、構成とトポロジを選択する際の考慮事項について説明します。

> [AZURE.NOTE] このガイドは [Elasticsearch][] の基本的知識を前提としています。

## Elasticsearch の構造

Elasticsearch は、検索エンジンとして機能するために高度に最適化されたドキュメント データベースです。ドキュメントは JSON 形式でシリアル化されます。データはインデックスで保存され、[Apache Lucene][] を利用して実装されます。ただし、詳細はビューから要約され、Elasticsearch を使用するために Lucene を完全に理解する必要はありません。

### クラスター、ノード、インデックス、シャード

Elasticsearch では、シャーディングを利用して複数のノードにデータを分散し、複製を利用して高可用性を実現する、クラスター化されたアーキテクチャを実装します。

ドキュメントはインデックスで保存されます。ドキュメント内のフィールドを指定し、インデックス内でそのドキュメントを一意に識別できます。あるいは、キー フィールドと値を自動生成できます。インデックスはドキュメントを物理的に整理するために使用され、また、ドキュメントの位置を見つけるための第一の手段として使用されます。さらに、Elasticsearch では、残りのフィールドで逆インデックスとして機能する一連の追加構造が自動的に作成されます。それにより、コレクション内で高速の検索と分析が可能になります。

インデックスは一連のシャードで構成されます。ドキュメントは、インデックス キーの値とインデックス内のシャード数に基づいてハッシュ メカニズムを利用し、シャード全体に均等に分散されます。ドキュメントがシャードに割り当てられると、そのインデックス キーが変更されるまで、そのシャードから移動しません。Elasticsearch では、クラスター内で利用できるすべてのデータ ノードにシャードが分散されます。1 つのノードは最初に、同じインデックスに属する 1 つまたは複数のシャードを保有できますが、新しいノードがクラスターに追加されると、Elasticsearch はシャードの位置を変更し、システム全体の負荷を分散します。ノードが移動されると、同じ再負荷分散が適用されます。

インデックスは複製できます。この場合、インデックスの各シャードがコピーされます。Elasticsearch では、インデックスの元のシャード (「プライマリ シャード」と呼ばれる) とそのレプリカが常に異なるノードに置かれます。

> [AZURE.NOTE] インデックスの作成後は、レプリカは追加できますが、インデックス内のシャードの数は簡単に変更できなくなります。

ドキュメントが追加または変更されると、すべての書き込み操作が最初にプライマリ シャードで実行され、次に各レプリカで実行されます。既定では、このプロセスは同期実行され、一貫性が維持されます。Elasticsearch では、データを書き込むときに、オプティミスティック同時実行制御とバージョン管理が利用されます。読み取り操作は、プライマリ シャードとそのレプリカのいずれかを利用して実行されます。

図 1 は、Elasticsearch クラスターの重要な側面が 3 つのノードで構成されていることを示しています。2 つのプライマリ シャードと各シャードの 2 つのレプリカ (合計で 6 つのシャード) で構成されるインデックスが作成されています。

![](media/guidance-elasticsearch-general-cluster1.png)

**図 1.**
2 つのプライマリ ノードと 2 つのレプリカ セットで構成されている単純な Elasticsearch クラスター

このクラスターでは、プライマリ シャード 1 とプライマリ シャード 2 が別々のノードに置かれ、付加が分散されています。レプリカも同様に分散されています。1 つのノードが故障しても、システムの機能を続行するために十分な情報が残りのノードにあります。必要に応じて、プライマリ シャードが利用不可能になった場合、Elasticsearch はレプリカ シャードをプライマリ シャードに昇進させます。
ノードが実行を開始するとき、新しいクラスターを開始するか (それがクラスターの最初のノードの場合)、既存のクラスターに参加できます。ノードが属するクラスターは elasticsearch.yml ファイルの *cluster.name* 設定により決定されます。

### ノード ロール

Elasticsearch クラスターのノードは次のロールを実行できます。

- インデックス データが含まれる 1 つまたは複数のシャードを格納できるデータ ノード。
- インデックス データを保有しないが、データ ノードに対するクライアント アプリケーションの受信要求を処理するクライアント ノード。
- インデックス データを保有しないが、クラスター周辺のルーティング情報 (ノードとそれに含まれるシャードの一覧) を保守管理し、配信する、利用できるノードを決定する、ノードが現れたり消えたりしたときにシャードの位置を変更する、ノードが故障したときに復元を調整するなど、クラスター管理操作を実行するマスター ノード。複数のノードをマスターとして構成できますが、実際には 1 つだけのノードが選ばれ、マスター機能を実行します。そのノードが故障した場合、もう一度選択が行われ、資格のある他のノードの 1 つが選ばれ、引き継ぎます。

既定では、Elasticsearch ノードは 3 つすべてのロールを実行しますが (それにより、開発と概念実証のために 1 台のコンピューターで完全に動作するクラスターを構築できます)、*elasticsearch.yml* ファイルの *node.data* 設定と *node.master* 設定を利用し、操作を次のように変更できます。

```yaml
node.data: true
node.master: false
```

**データ ノードの構成**

```yaml
node.data: false
node.master: false
```

**クライアント ノードの構成**

```yaml
node.data: false
node.master: true
```

**マスター ノードの構成**

> [AZURE.NOTE] 選ばれたマスター ノードは、クラスターの健全性のために重要です。他のノードは定期的に ping を実行し、引き続き利用できることを確認します。選ばれたマスター ノードがデータ ノードとしても機能している場合、ノードがビジー状態になり、ping に応答できないことがあります。そのような場合、マスターが故障していると見なされ、他のマスター ノードの 1 つが代わりに選ばれます。元のマスターが実際には利用できる場合、結果的にクラスターで 2 つのマスターが選ばれ、「スプリット ブレイン」問題が発生し、データの破損やその他の問題が発生することがあります。この問題が発生する可能性が少なくなるようにクラスターを構成する方法は、「Configuring, Testing, and Analyzing Elasticsearch Resilience and Recovery (Elasticsearch の回復力/復元の構成、テスト、分析)」というドキュメントにあります。ただし、結局のところ、中規模/大規模のクラスターでは、データの管理を担当しない専用マスター ノードを使用することが最善の方法となります。

クラスターのノードはクラスターの他のノード ([ゴシップ プロトコル][]を利用) とそれに含まれるシャードに関する情報を共有します。データを保存し、取得するクライアント アプリケーションはクラスター内のあらゆるノードに接続できます。要求は透過的に正しいノードに送信されます。クライアント アプリケーションがクラスターからデータを要求するとき、要求を最初に受信したノードが操作を指示し、関連ノードと通信してデータを取得し、結果を集計してクライアント アプリケーションに返します。クライアント ノードを利用して要求を処理することで、データ ノードがスキャッター/ギャザー作業から解放され、データに対するサービス提供に集中できます。データ ノードの HTTP トランスポートを無効にすることで、クライアント アプリケーションがデータ ノードと思いがけず通信する事態 (データ ノードがクライアント ノードとして機能し始めます) を回避できます。

```yaml
http.enabled: false
```

データ ノードは引き続き、同じネットワークにある他のデータ ノード、クライアント ノード、専用マスター ノードと Elasticsearch モジュール (TCP ソケットを利用してノード間で直接接続します) で通信できますが、クライアント アプリケーションは HTTP でクライアント ノードにのみ接続できます。図 2 は、Elasticsearch クラスターにある、専用マスター、クライアント、データ ノードの混成からなるトポロジを示しています。

![](media/guidance-elasticsearch-general-cluster2.png)

**図 2.**
さまざまな種類のノードを表示する Elasticsearch クラスター

### クライアント ノードを使用する場合の費用と利点

アプリケーションがクエリを Elasticsearch クラスターに送信するとき、アプリケーションの接続先となるノードがクエリ プロセスを指示します。ノードは要求を各データ ノードに転送し、結果を収集し、累積された情報をアプリケーションに返します。クエリに集約やその他の計算が含まれる場合、アプリケーションの接続先のノードは他のノードからデータを取得し、必要な演算を実行します。このスキャッター/ギャザー プロセスでは、大量の処理/メモリ リソースが使用されます。

専用クライアント ノードでこれらのタスクを実行することで、データ ノードをデータの管理と保管に集中させることができます。そのため、複雑なクエリや集約が伴う多くのシナリオでは、専用クライアント ノードを利用すると効率的になります。ただし、専用クライアント ノードの利用の効果は、多くの場合、シナリオ、ワークロード、クラスター サイズに依存します。たとえば、データ取り込みのワークロードはクライアント ノードを利用すると効率性が下がることがあります。データを格納するとき、付加的ネットワークの「ホップ」が必要になるためです。シャードが 6 つの 3 ノード クラスターでは、システムが専用クライアント ノードで構成されていない場合、すべての環境要因とノード読み込みが等しいとき、データを保存または変更するアプリケーションが 1/3 の確率で最も適切なシャードに直接接続します。1/3 のケースで、付加的なネットワーク ジャンプを実行する必要がなくなります。一方で、複雑な集約を実行するワークロードの場合、専用クライアントを利用すると効率的になることがあります。複雑な集約で実行される一連のスキャッター/ギャザー操作を 1 つのノードが担当します。混在環境では、特定のワークロードでクライアント ノードを利用した場合の効果を評価するためにパフォーマンス テストを実行する準備をしてください。

> [AZURE.NOTE] 「Maximizing Data Aggregation and Query Performance with Elasticsearch on Azure (Azure で Elasticsearch によるデータ集約とクエリのパフォーマンスを最大化する)」というドキュメントに、マイクロソフトのパターン/プラクティス開発チームがこの目的のために実行した一連のベンチマークがまとめてあります。

### クラスターに接続する

Elasticsearch は、クライアント アプリケーションを構築し、要求をクラスターに送信するための一連の REST API を公開します。.NET フレームワークを利用してアプリケーションを開発している場合、2 つ上のレベルの API である [Elasticsearch.Net と NEST][] を利用できます。

Java を利用してクライアント アプリケーションを開発している場合、[ノード クライアント API][] を利用し、クライアント ノードを動的に作成し、それをクラスターに追加できます。長時間接続の数が比較的少ない場合、クライアント ノードを動的に作成する方法が便利です。ノード API を利用して作成されたクライアント ノードには、マスター ノードによりクラスター ルーティング マップ (ノードとそれに含まれるシャードの詳細) が与えられます。この情報により、Java アプリケーションはデータにインデックスを作成したり、データを問い合わせたりするときに適切なノードに直接接続できます。他の API の利用時に比べ、ホップの数が少なくなります。クライアント ノードをクラスターに登録するための諸経費がこの手法のコストとなります。大量のクライアント ノードが現れては消える場合、クラスター ルーティング マップを保守管理し、配信することの影響が大きくなります。

**接続の負荷分散**

Elasticsearch は、接続の負荷分散を実装するためのいくつかのメカニズムを可能にします。次は、いくつかの共通手法を一覧にしたものです。

**クライアント ベースの負荷分散**: Elasticsearch.Net または NEST API を利用してクライアント アプリケーションを構築している場合、接続プールを利用し、ノード全体で接続要求をラウンドロビンできます。外部のロード バランサーがなくても、要求の負荷を分散できます。次のコード スニペットは、3 つのノードのアドレスで構成された *ElasticsearchClient* オブジェクトを作成する方法を示しています。クライアント アプリケーションからの要求がこれらのノード全体に分配されます。

```csharp
// C#
var node1 = new Uri("http://node1.example.com:9200");
var node2 = new Uri("http://node2.example.com:9200");
var node3 = new Uri("http://node3.example.com:9200");

var connectionPool = new SniffingConnectionPool(new[] {node1, node2, node3});
var config = new ConnectionConfiguration(connectionPool);
var client = new ElasticsearchClient(config);
```

> \[AZURE.NOTE] [トランスポート クライアント API][] により同様の機能が Java アプリケーションで利用できます。

**サーバー ベースの負荷分散**: 個別のロード バランサーを利用し、要求をノードに分配できます。この手法には、アドレスの透過性という長所があります。クライアント アプリケーションは各ノードの詳細で構成する必要がありません。クライアント コードを変更せずに、ノードを簡単に追加、削除、位置変更できます。図 3 は、ロード バランサーを利用し、一連のクライアント ノードに要求を送信する構成を示しています。ただし、クライアント ノードが使用されない場合、同じ方法を利用し、データ ノードに直接接続できます。

> \[AZURE.NOTE] [Azure Load Balancer][] を利用し、クラスターを公共のインターネットに公開できます。あるいは、クライアント アプリケーションとクラスターがすべて同じプライベート仮想ネットワーク (VNET) 内に含まれている場合、[内部ロード バランサー][]を利用できます。

![](media/guidance-elasticsearch-general-clientappinstances.png)

**図 3:**
Azure Load Balancer を使用して Elasticsearch クラスターに接続するクライアント アプリケーション インスタンス

**カスタムの負荷分散**: [nginx][] を Azure Load Balancer の代わりにリバース プロキシ サーバーとして利用できます。Nginx には、ラウンド ロビン、Least-Connected (現在、接続が最も少ない宛先に要求が送信される)、クライアントの IP アドレスに基づくハッシュなど、さまざまな負荷分散方法があります。

> [AZURE.NOTE] Azure VM として nginx サーバーをデプロイできます。可用性を維持するために、同じ Azure 可用性セットに 2 つ以上の nginx サーバーを作成してください。

負荷分散の使用と使用する実装を決定する際には次の点を検討してください。

- 同じノードに接続し、あるアプリケーションのすべてのインスタンスのすべての要求を処理すると、そのノードがボトルネックになることがあります。ノードで利用できるスレッドの数が使い尽くされると、要求が待ち行列に入り、待ち行列があまりに長くなると拒否されます (多数のユーザーにデプロイされるアプリケーション コードには単一ノードの接続詳細をハード コード化しないでください)。
- Elasticsearch.Net、NEST、Transport Client API のラウンドロビン メカニズムは、接続プールで次に利用できるノードに接続を再試行することで、失敗した接続要求を処理します。プール内の応答しないノードに対する接続には一時的に*停止 (dead)* の印が付きます。これは後で応答することがあります。プールはノードに ping を実行し、再度アクティブになっているかどうかを判断できます。
- Azure ロード バランサーは、要因 (クライアント IP アドレス、クライアント ポート、宛先 IP アドレス、宛先ポート、プロトコル タイプ) の数に基づき、透過的に要求をノードにリダイレクトできます。この方法に従い、特定のコンピューターで実行されているクライアント アプリケーションのインスタンスは、多くの場合、同じ Elasticsearch ノードにリダイレクトされます。ロード バランサーのプローブ構成にもよりますが、Elasticsearch サービスがこのノードで故障しても、VM 自体は動作を継続している場合、このノードに対するすべての接続がタイムアウトになるが、他のクライアント インスタンスの他のノードに対する接続は続行することがあります。
- ロード バランサーが実行するヘルス プローブ要求にノードが適切に応答しない場合、そのノードをローテーションが外すように Azure ロード バランサーを設定できます。

### ノード検出

Elasticsearch はピアツーピア通信を基盤としています。クラスターの他のノードを検出することがノードのライフサイクルにおいて重要な部分となります。ノードを検出することで、新しいデータ ノードをクラスターに動的に追加し、クラスターを透過的に拡張できます。また、あるデータ ノードが他のノードからの通信要求に応答できない場合、マスター ノードがそのデータ ノードの失敗を判断し、必要な手順を踏み、動作している他のデータ ノードにシャードを再割り当てすることができます。

Elasticsearch ノード検出は検出モジュールの使用により処理されます。検出モジュールは、別の検出メカニズムに切り替えられるプラグインです。既定の検出モジュール ([Zen][]) では、ノードは ping 要求を発行し、同じネットワークの他のノードを見つけます。他のノードが応答する場合、ゴシップ プロトコルで情報を交換します。その後、マスター ノードは新しいノードにシャードを配信し (データ ノードの場合)、クラスターの負荷を再び分散できます。

Zen 検出モジュールはマスターの選択プロセスとノード失敗を検出するプロトコルも処理します。

Elasticsearch バージョン 2.0 以前は、Zen 検出モジュールはノードが互いに通信するためにマルチキャスト通信を使用していました。その方法では、新しいノードを簡単にクラスターに導入できますが、同じネットワークの別の Elasticsearch インストールで同じクラスター名が使用されていた場合にセキュリティ上の問題を引き起こします。新しいインストールが同じクラスターに含まれると見なされ、シャードがこのインストールのノードに送信されることがあります。また、Azure Virtual Machines (VM) として Elasticsearch ノードを実行している場合、マルチキャスト メッセージングはサポートされません。そのような理由から、ユニキャスト メッセージを使用するように Zen 検出を構成し、elasticsearch.yml 構成ファイルに有効な連絡先ノードの一覧を指定してください。

> [AZURE.NOTE] Elasticsearch 2.0 以降では、マルチキャストは既定の検出メカニズムではなくなりました。

Azure VNET 内で Elasticsearch クラスターをホストしている場合、DHCP が割り当て、クラスターの各 VM に与えられたプライベート IP アドレスが割り当てられている状態を維持するように指定できます (静的)。これらの静的 IP アドレスを利用し、Zen 検出ユニキャスト メッセージングを構成できます。動的 IP アドレスで VM を利用している場合、VM が停止し、再起動した場合、新しい IP アドレスが割り当てられ、検出が難しくなる可能性があることに注意してください。そのような状況に対処するために、Zen 検出モジュールと [Azure クラウド プラグイン][]を交換できます。このプラグインは Azure API を使用し、Azure サブスクリプション情報に基づく検出メカニズムを実装します。

> [AZURE.NOTE] Azure クラウド プラグインの現行バージョンを利用するには、Elasticsearch ノードに Java キーストアの Azure サブスクリプションの管理証明書をインストールし、elasticsearch.yml ファイルにキーストアにアクセスするための場所と資格情報を指定する必要があります。このファイルはクリア テキストで保存されます。そのため、このファイルへのアクセスを Elasticsearch サービスを実行しているアカウントに限定することが重要になります。また、Azure リソース マネージャー (ARM) のデプロイではこの方法が利用できない場合があります。そのような理由から、マスター ノードに静的 IP アドレスを使用し、そのノードを利用してクラスター全体で Zen 検出ユニキャスト メッセージングを実装することが推奨されます。次の構成 (サンプル データ ノードの elasticsearch.yml ファイルからの抜粋) では、ホスト IP アドレスがクラスターのマスター ノードを参照しています。

>`discovery.zen.ping.multicast.enabled: false`  
`discovery.zen.ping.unicast.hosts: ["10.0.0.10","10.0.0.11","10.0.0.12"]`

## 一般的なシステム ガイドライン

Elasticsearch は、1 台のラップトップから高性能サーバーの集合まで、さまざまなコンピューター上で実行できます。ただし、メモリ、計算能力、高速ディスクなどのリソースが多ければ多いほど、性能はよくなります。次のセクションでは、Elasticsearch を実行するための基本的なハードウェアとソフトウェアの要件がまとめてあります。

### メモリの要件
Elasticsearch は高速化のためにメモリにデータを保存しようとします。一般的な企業向けまたは中規模の商用のノードを Azure にデプロイするには運用サーバーに 14GB ～ 28GB の RAM が必要になります (D3 または D4 VM)。たくさんのメモリを持ったノードを作成する代わりに、たくさんのノードで負荷を分散させます (たくさんのメモリを持った大規模ノードを使用した場合、故障時の復旧に時間がかかることが実験により証明されています)。 ただし、たくさんの小規模ノードでクラスターを作ると、可用性とスループットが上がりますが、そのようなシステムを運用し、保守管理する労力もたくさん必要になります。

サーバーで利用できるメモリの 50% を Elasticsearch のヒープに割り当てます。Linux を使用している場合、Elasticsearch を実行する前に ES\_HEAP\_SIZE 環境変数を設定します。あるいは、Windows または Linux を使用している場合、Elasticsearch を開始するとき、*Xmx* パラメーターと *Xms* パラメーターにメモリ サイズを指定できます。Java 仮想マシン (JVM) が実行時にヒープのサイズを変更するのを回避するために、両方のパラメーターを同じ値に設定します。ただし、30GB 以上を割り当てることはできません。オペレーティング システム ファイル キャッシュに残りのメモリを使用します。

> [AZURE.NOTE] Elasticsearch は Lucene ライブラリを活用し、インデックスを作成して管理します。Lucene 構造はディスク基盤の形式を利用します。ファイル システム キャッシュにそのような構造をキャッシュすると、性能が大幅に上がります。

> また、Elasticsearch は Java で記述されています。64 ビット マシンの Java の最大の最適ヒープ サイズは 30GB を少し超えるくらいです。このサイズを超えると、Java はヒープでオブジェクトを参照する拡張メカニズムの使用に切り替えます。このメカニズムが各オブジェクトのメモリ要件を増やし、性能を下げます。ヒープ サイズが 30GB を超える場合、既定の Java ガベージ コレクション (同時実行のマークとスイープ) を次善の方法で実行することもできます。Elasticsearch と Lucene は既定以外に対してはテストされていないため、別のガベージ コレクションに切り替えることは現在のところ推奨されていません。

メイン メモリをディスクにスワップすると性能に深刻な影響を与えるため、メモリをオーバーコミットしないでください。可能であれば、スワップは完全に無効にしてください (詳細はオペレーティング システムによって異なります)。それができない場合、次のように Elasticsearch 構成ファイルの *mlockall* 設定を有効にしてください。

```yaml
bootstrap.mlockall: true
```

この構成設定により、JVM はそのメモリをロックし、オペレーティング システムによるスワップ アウトを回避します。

### ディスクとファイル システムの要件

ソリッド ステート ドライブ (SSD) を利用してシャードを保存します。ディスクのサイズは、シャードで予想される最大量のデータを格納できるように決定してください。ただし、後でディスクを追加することもできます。ノードの複数のディスクにわたりシャードを拡張できます。

> [AZURE.NOTE] Elasticsearch は LZ4 アルゴリズムを利用して保存されるフィールドのためにデータを圧縮します。Elasticsearch 2.0 以降では、圧縮タイプを変更できます。*zip* ユーティリティと *gzip* ユーティリティで使用される DEFLATE に圧縮アルゴリズムを切り替えることができます。この圧縮方法ではリソース利用率が高くなることがありますが、アーカイブされているログ データなど、コールド インデックスには使用を検討してください。この方法では、インデックスのサイズを減らすことができます。

クラスターのすべてのノードのディスク レイアウトと容量を同じにすることは重要ではありません。ただし、あるノードのディスク容量が他のノードに比べて非常に大きければ、そのノードに多くのデータが集まり、それを処理するために大量の処理パワーが必要になります。結果的に、そのノードは他のノードに比べて「ホット」になり、性能に影響を与えます。

> [AZURE.NOTE] Azure には、Standard ストレージ、Premium ストレージ、短期ストレージなど、さまざまなディスク ストレージオプションがあります。Standard ストレージは回転するメディアが基盤となり、Premium ストレージでは SSD が使用されます。VM の実装に使用される SKU に基づき、短期ストレージは回転するメディア (A シリーズ VM) または SSD (D シリーズ VM 以降) として実装できます。ストレージの選択肢について検討する際には、予算と技術のバランスを考慮する必要があります。詳しくは、「Maximizing Data Ingestion Performance with Elasticsearch on Azure (Azure での Elasticsearch によるデータ取り込みパフォーマンスの最大化)」というドキュメントを参照してください。

可能であれば、RAID 0 (ストライピング) を採用してください。パリティとミラーリングを実装する他の形式の RAID は必要ありません。Elasticsearch には、レプリカという形式で独自の HA ソリューションがあるためです。また、Azure ディスクによりディスク データの 3 つのコピーが保存されます。

> [AZURE.NOTE] Elasticsearch 2.0.0 以前は、*path.data* 構成設定に複数のディレクトリを指定することで、ソフトウェア レベルでストライピングを実装することもできました。Elasticsearch 2.0.0 では、この形式のストライピングは利用できません。代わりに、異なるシャードを異なるパスに割り当てることができます。ただし、1 つのシャードのすべてのファイルが同じパスに書き込まれます。ストライピングが必要な場合、オペレーティング システム レベルまたはハードウェア レベルでデータをストライピングしてください。

VM に接続される Azure ディスクの合計 I/O スループットがディスクが属するストレージグループに制限されることにも注意してください。Standard ストレージのアカウント 1 つで最大 20,000 IOPS の要求を処理できます (この制限はプレミアムストレージには適用されません)。予想されるディスク I/O トラフィックよりこの数値が少ない場合、複数のストレージ アカウントにわたり、クラスターの VM のディスクを分散してください。1 つのサブスクリプションで最大 100 のストレージ アカウントを作成できることに注意してください。

Lucene ライブラリは大量のファイルを利用し、インデックス データを保存できます。Elasticsearch はかなりの数のソケットを開き、ノード間で通信したり、クライアントと通信したりできます。オペレーティング システムは適切な数のオープン ファイル記述子をサポートするように構成されていることを確認してください (十分なメモリが利用できる場合、最大 64000)。多くの Linux ディストリビューションの既定の構成では、オープン ファイル記述子の数が 1024 に制限され、少なすぎることに注意してください。

Elasticsearch はメモリがマッピングされた (mmap) IO と Java New IO (NIO) I/O を組み合わせ、データ ファイルとインデックスに対する同時アクセスを最適化します。Linux を使用している場合、十分な仮想メモリと 256K のメモリ マップ領域が利用できるようにオペレーティング システムを構成してください。

> [AZURE.NOTE] 多くの Linux ディストリビューションは、ディスクにデータを書き込むように調整されているとき、Completely Fair Queuing (CFQ) スケジューラーを使用するように初期設定されています。このスケジューラーは SSD には向いていません。NOOP スケジューラーか Deadline スケジューラーを使用するようにオペレーティング システムを再設定することを検討してください。いずれも SSD で効果を発揮します。

### CPU の要件

複数のコアを持つ CPU を使用します。コアが少なく高速の CPU よりコアの多さが勝ります。これは、既定の Elasticsearch スレッドプール サイズが利用できる CPU コア数に基づいて構成されているためです。Elasticsearch により使用されるアルゴリズムはこれらの計算に基づいて最適化されます。Elasticsearch の既定のスレッドプール設定を変更しないことが推奨されます。

> [AZURE.NOTE] Azure VM はさまざまな CPU 構成で利用できます。1 ～ 32 コアに対応しています。データ ノードの場合、標準の D シリーズ VM から始め、D3 (4 コア) または D4 (8 コア) SKU を選択すると効果的です。D3 はまた、14GB の RAM を提供します。D4 は 28GB です。プレミアム ディスク ストレージが必要な場合、DS シリーズ VM を利用できます (DS3 または DS4 マシンを検討してください)。スループットが限られる背景に CPU 性能が大きく関与すると考えられる場合、パワーの大きい 2.4 GHz Intel Xeon プロセッサを備えた Dv2 シリーズがあります。G シリーズ (Standard ストレージ用) と GS シリーズ (Premium ストレージ用) では、Xeon E5 V3 プロセッサが使用されています。大規模な集約など、大量の計算処理を必要とするワークロードで効果を発揮します。最新情報については、「[Sizes for Virtual Machines (Virtual Machines のサイズ)][]」をご覧ください。

### ネットワークの要件

実装するクラスターのサイズとボラティリティに基づき、Elasticsearch は 1 ～ 10Gbps のネットワーク帯域幅を必要とします。ノードがクラスターに追加されると、Elasticsearch はノード間でシャードを移行させます。Elasticsearch では、すべてのノード間の通信時間がおおよそ等しいと想定され、ノードで保存されているシャードの相対的位置は考慮されません。また、複製がシャード間で大量のネットワーク I/O を発生させることがあります。そのような理由から、地理的に分散されているノードでクラスターを作成しないでください。

Azure VM のネットワーク帯域幅は SKU だけでなく、VM が実行される物理ハードウェアの合計ネットワーク利用によっても制約されることに注意してください。VM がハードウェアを共有する場合、専用の機械で VM を実行するより帯域幅が少なくなりますが、デプロイは安価になります。つまり、VM に関しては、シリーズと SKU を選択する以外、ネットワーク帯域幅を決定する要素はほとんどありません。たとえば、複数の仮想 NIC で VM を作成できますが、その場合、VM が利用できる帯域幅全体は増えません。同じ物理ネットワーク リソースを要求して競合する仮想 NIC が増えるだけです。

### ソフトウェアの要件

Elasticsearch は Windows または Linux で実行できます。Elasticsearch サービスは Java jar ライブラリとしてデプロイされ、Elasticsearch パッケージに含まれる他の Java ライブラリに依存します。Elasticsearch を実行するには、Java 7 (更新 55 以降) または Java 8 (更新 20 以降) JVM をインストールする必要があります。

> [AZURE.NOTE] *Xmx* と *Xms* (Elasticsearch にコマンド ライン オプションとして指定 - 「[メモリの要件][]」参照) 以外のメモリ パラメーターでは既定の JVM 構成設定が変更されません。Elasticsearch は初期設定を利用して設計されています。変更すると、Elasticsearch の性能が下がります。

### Azure で Elasticsearch をデプロイする

1 つの Elasticsearch インスタンスをデプロイする作業は難しくありませんが、大量のノードを作成し、各ノードで Elasticsearch をインストールし、構成するのは時間がかかり、間違いが起こりやすくなります。Elasticsearch を Azure VM で実行する場合、2 つの方法で間違いが起こる可能性を減らすことができます。
- [Azure リソース マネージャー (ARM) テンプレート](http://azure.microsoft.com/documentation/templates/elasticsearch/)でクラスターを構築することです。このテンプレートは完全にパラメーター化されており、ノードを実装する VM のサイズとパフォーマンス レベル、使用するディスクの数、その他の共通用意を指定できます。このテンプレートでは、Windows Server 2012 か Ubuntu Linux 14.0.4 を基盤にクラスターを作成できます。
- 自動化または無人実行できるスクリプトを利用します。Elasticsearch クラスターを作成し、デプロイできるスクリプトは [Azure クイックスタート テンプレート][] サイトにあります。

## クラスターとノードの規模と拡張性に関する考慮事項

Elasticsearch では、さまざまなデプロイメント トポロジが可能であり、さまざまな要件と規模に対応するように設計されています。このセクションでは、いくつかの共通トポロジとそのトポロジに基づいてクラスターを実装する際の考慮事項について説明します。

### Elasticsearch トポロジ

図 4 は、Azure VM に基づくクラウドの Elasticsearch トポロジを設計するときの出発点を示しています。

![](media/guidance-elasticsearch-general-startingpoint.png)

**図 4:**
Azure で Elasticsearch クラスターを構築するとき推奨される出発点

このトポロジは 6 つのデータ ノード、3 つのクライアント ノード、3 つのマスター ノードで構成されています (マスターに選ばれるノードは 1 つだけであり、その選ばれたマスターが故障した場合に、他の 2 つから選択されます)。 各ノードは別の VM として実装されます。Azure Web アプリケーションはロード バランサーを介してクライアント ノードに送られます。この例では、すべてのノードは Web アプリケーションが同じ Azure VNET に置かれ、外の世界から効果的に隔離されます。クラスターを外部で利用する必要がある場合 (たとえば、オンプレミス クライアントを組み込むハイブリッド ソリューションの一環として)、Azure Load Balancer を利用し、パブリック IP アドレスを指定できますが、クラスターへの無許可のアクセスを防止するためにセキュリティ上の対策を増やす必要があります。オプションの「ジャンプ ボックス」は管理者だけが利用できる VM です。この VM には Azure VNET へのネットワーク接続が与えられますが、外部に向けられたネットワーク接続も与えられ、それを利用して管理者は外部ネットワークからログインできます (このログインは強力なパスワードまたは証明書で保護する必要があります)。管理者はジャンプ ボックスにログオンし、そこからクラスターの任意のノードに直接接続できます。代替手法としては、たとえば、組織と VNET の間でサイト間 VPN を利用したり、 [ExpressRoute][] をして VNET に接続したりできます。これらのメカニズムでは、クラスターを公共のインターネットに公開しなくても、クラスターに管理者アクセスできます。

VM の可用性を維持するために、データ ノードが同じ Azure 可用性セットにグループ化されます。同様に、クライアント ノードが別の可用性セットに保存され、マスター ノードが 3 番目の可用性セットに保存されます。

このトポロジは拡張が比較的簡単です。適切な種類のノードを追加し、elasticsearch.yml ファイルで同じクラスター名で構成するだけです。また、クライアント ノードは Azure ロード バランサーのバックエンド プールに追加する必要があります。

**クラスターの地理的位置検索**

リージョンをまたいでクラスターのノードを分散しないでください。ノード間通信の性能に影響を与えます (「[ネットワークの要件][]」参照)。異なるリージョンのユーザーの地理的に近いデータの位置を検索するには、複数のクラスターを作成する必要があります。そのような状況では、クラスターの同期方法 (あるいは、クラスターを同期するかどうか) を考慮する必要があります。考えられる解決策:

**[トライブ ノード][]を利用してクラスターに接続する**。 トライブ ノードは、複数の Elasticsearch クラスターに参加し、それらを 1 つの大きなクラスターとして表示できることを除き、クライアント ノードに似ています。データは各クラスターにローカル管理されますが (クラスター境界をまたいで更新が適用することはありません)、すべてのデータが表示されます。トライブ ノードはあらゆるクラスターでドキュメントを照会、作成、管理できます。主な制約は、トライブ ノードを利用して新しいインデックスを作成できないということです。インデックスの名前はすべてのクラスターで一意にする必要があります。そのため、トライブ ノードからアクセスするクラスターを設計するときは、インデックスの命名方法を考慮することが重要になります。

このメカニズムを使用し、ローカル クライアント アプリケーションでアクセスされる可能性が最も高いデータを各クラスターに含めることができます。ただし、待ち時間が長くなるとしても、そのクライアントはリモート データにアクセスし、変更できます。図 5 はこのトポロジの例です。クラスター 1 のトライブ ノードが強調表示されています。その他のクラスターにもトライブ ノードを与えることができますが、図には示されていません。

![](media/guidance-elasticsearch-general-tribenode.png)

**図 5:**
トライブ ノードを介して複数のクラスターにアクセスするクライアント アプリケーション

この例では、クライアント アプリケーションはクラスター 1 (同じリージョン内に併置) のトライブ ノードに接続しますが、このノードは、別のリージョンに配置されている可能性があるクラスター 2 とクラスター 3 にアクセスできるように構成されています。クライアント アプリケーションは、任意のクラスターのデータを取得または変更する要求を送信できます。

> [AZURE.NOTE] トライブ ノードは、クラスターに接続するためにマルチキャスト検出を必要とします。それはセキュリティ上の懸念事項となる可能性があります。詳細については、「[ノード検出][]」セクションを参照してください。

*	クラスター間で geo レプリケーションを実装するこの方法では、各クラスターで行われた変更が他のデータ センターに配置されているクラスターにほぼリアルタイムで適用されます。Elasticsearch には、この機能をサポートするサードパーティー プラグインを利用できます。たとえば、[PubNub Changes Plugin][] です。
*	[Elasticsearch スナップショット/復元モジュール][]を使用するデータの動きが非常に遅く、1 つのクラスターでのみ変更される場合、スナップショットを利用してデータの定期的なコピーを撮影し、他のクラスターでそのスナップショットを復元することを検討してください ([Azure クラウド プラグイン][]を利用している場合、Azure BLOB ストレージにスナップショットを保存できます)。ただし、データが急速に変化する場合やデータが複数のクラスターで変更される場合、この解決策はうまく機能しません。

**小規模トポロジ**

専用マスター、クライアント、データ ノードのクラスターで構成されている大規模トポロジは一部のシナリオには適していません。小規模の運用システムまたは開発システムを構築している場合、図 6 の 3 ノード クラスターを検討してください。クライアント アプリケーションは、クラスター内で利用できる任意のデータ ノードに直接接続します。クラスターには、P1 ～ P3 というラベルが付いた 3 つのシャード (増加を考慮) と R1 ～ R3 というラベルが付いたレプリカが含まれます。3 つのノードを使用することで、1 つのノードが故障してもデータが失われないように Elasticsearch はシャードとレプリカを配信できます。

![](media/guidance-elasticsearch-general-threenodecluster.png)

**図 6:**
3 つのシャードとレプリカが含まれる 3 ノード クラスター

スタンドアロン コンピューターで開発環境を実行している場合、マスター、クライアント、データ ストレージとして機能する 1 つのノードでクラスターを構成できます。あるいは、同じコンピューターで複数のノードをクラスターとして実行できます。Elasticsearch の複数のインスタンスを起動します。図 7 に例を示します。

![](media/guidance-elasticsearch-general-developmentconfiguration.png)

**図 7:**
複数の Elasticsearch ノードを同じコンピューターで実行する開発構成

いずれのスタンドアロン構成も運用環境には推奨されません。開発マシンに大量のメモリと複数の高速ディスクが搭載されていない限り、競合を引き起こす可能性があるためです。また、高い可用性が保証されません。マシンが故障すると、すべてのノードが失われます。

### クラスター ノードとデータ ノードを拡張する際の考慮事項

Elasticsearch は垂直 (大きく高性能なマシンを利用) と水平 (マシン間で負荷を分散) の 2 つの次元で拡張できます。

**Elasticsearch データ ノードを垂直方向に拡張する**

Azure VM を使用して Elasticsearch クラスターをホストしている場合、各ノードが 1 つの VM に対応できます。ノードの垂直拡張性の上限は、大部分は、VM の SKU と、個々のストレージ アカウントと Azure サブスクリプションに適用される全体的制約によって決まります。「[Azure Subscription and Service Limits, Quotas, and Constraints (Azure のサブスクリプションとサービスの制限事項、クォータ、制約)](azure-subscription-service-limits/)」ページに、上限に関する詳細があります。ただし、Elasticsearch クラスターの構築に関する限り、次の一覧の項目が最も関連します。また、相当な理由がない限り、64GB 以上のメモリを備えた VM は使用しないでください。「[メモリの要件][]」セクションの説明にあるように、各 VM の 30GB 以上の RAM を JVM に割り当て、I/O バァッファリングのためにオペレーティング システムに残りのメモリを活用させることはしないでください。
- 各ストレージ アカウントは 20,000 IOPS に制約されます。同じストレージ アカウントを使用し、たくさんの VHD を保持すると、VHD のパフォーマンスが限られることがあります。
- VNET のデータ ノードの数。Azure リソース マネージャー (ARM) を使用していない場合、VNET あたりの VM インスタンス上限は 2048 になります。多くの場合はこの数で十分ですが、非常に大きな構成で数千のノードが含まれる場合、この数に達することがあります。
- リージョン別のサブスクリプションあたりのストレージ アカウント数。リージョン別の Azure サブスクリプションあたり、最大 100 のストレージ アカウントを作成できます。ストレージ アカウントは仮想ディスクの保有に使用されます。各ストレージ アカウントには 500TB の領域制限があります。
- サブスクリプションあたりのコア数。既定の上限はサブスクリプションあたり 20 コアですが、マイクロソフトはこれを 10,000 コアまで追加できます。一部の VM サイズ (A9、A11、D14、DS14) には 16 コアを含めることができます。G5 VM には 32 コアが入ります。
- VM あたりのメモリ量。VM のサイズが小さければ、利用できるメモリ量が限られます (D1 マシンは 3.5GB で、D2 マシンは 7GB です)。このようなマシンは、良好なパフォーマンスを得るために大量のデータをキャッシュすることを Elasticsearch に要求するシナリオには適さない場合があります (たとえば、データの集約やデータ取り込み中の大量のドキュメントの分析)。
- VM サイズあたりの最大ディスク数。この制約によりクラスターのサイズとパフォーマンスを制限できます。ディスクが少なければ、保持できるデータがそれだけ少なくなります。ストライピングに利用できるディスクが少なければ、パフォーマンスが下がります。
- 可用性セットあたりの更新ドキュメント/障害ドメインの数。ARM を利用して VM を作成する場合、最大 3 つの障害ドメインと 20 の更新ドメインに各可用性セットを割り当てることができます。この制限は、頻繁に繰り返される更新の対象となる大規模クラスターの回復力に影響を与えます。

これらの制約を念頭に置き、常にストレージ アカウントをまたいで VM の仮想ディスクを分散し、I/O スロットルの可能性を減らしてください。非常に大規模なクラスターでは、論理インフラストラクチャの設計をやり直し、個々の機能パーティションに分割しなければならないことがあります。たとえば、サブスクリプションをまたいでクラスターを分割しなければならないことがあります。VNET を接続するため、そのプロセスはさらに複雑になることがあります。

>	[AZURE.NOTE] Azure ではストレージ アカウントが特定のストレージ スタンプに固定されることに注意してください。 これは、一貫性と可用性を維持するために使用される内部メカニズムです。 この機能の詳細については、 [厳密な整合性を利用した高可用性クラウド ストレージ サービス][] に関するドキュメントを参照してください。 特定のスタンプが原因でストレージが停止した場合、そのアカウントを使用して作成されたすべてのドライブでエラーが発生します。 このとき、そのドライブを使用する VM がすべて停止する可能性があります。 つまり、1 つの VM 用に複数のストレージ アカウントを使って別々のドライブをホストすると、その VM で障害が発生するリスクが高くなります。 このことから、ノードごとに 1 つのストレージ アカウントを使用し、そのアカウントにシステム ドライブとすべてのデータ ドライブを格納することをお勧めします。

**Elasticsearch クラスターを水平方向に拡張する**

Elasticsearch の内部では、水平拡張性の上限は各インデックスに定義されているシャードの数で決定します。最初に多くのシャードをクラスターの同じノードに割り当てることができます。データの量が増えたら、ノードを追加し、シャードをノード全体で分散できます。理論上、ノードの数がシャードの数に達した場合にのみ、水平方向の拡張が止まります。

垂直方向の拡張と同様に、水平方向の拡張を実装するときは、次のような問題を考慮する必要があります。

- Azure VNET で接続できる VM の最大数。非常に大規模なクラスターの場合、これが水平拡張性の上限となります。この上限を回避するために複数の VNET をまたぐノード クラスターを作成できますが、その手法では、各ノードとそのピアにローカリティがないため、パフォーマンスが下がることがあります。
- VM サイズあたりのディスクの数。シリーズと SKU によっては、接続されるディスクの数が異なります。また、VM に付属する短期ストレージを利用し、高速データ ストレージの量を限定することも検討できます。ただし、その場合、復元性と回復について考慮する必要があります (詳細については、「Configuring, Testing, and Analyzing Elasticsearch Resilience and Recovery (Elasticsearch の復元性と回復の構成、テスト、分析)」を参照してください)。D シリーズ、DS シリーズ、Dv2 シリーズ、GS シリーズの VM では、短期ストレージに SSD が使用されます。
- 仮想ディスクあたりの最大 IOPS。Standard ストレージで作成される通常の接続ディスクはディスクあたり 500 IOPS に制限されます。接続 SSD では、ディスクあたり最大 5000 IOPS をサポートできます。接続ディスク (短期ストレージではない) に SSD を使用するには、Premium ストレージ(DS シリーズまたは GS シリーズのマシン) をサポートする VM を作成する必要があります。

必要に応じて、Azure スケール セットを利用して VM を起動/停止することを検討してください (詳細については、「[Automatically scale machines in a Virtual Machine Scale Set (仮想マシン スケール セットでのマシンの自動スケール)][]」を参照してください)。ただし、次の理由から、この方法は Elasticsearch クラスターに適さない場合があります。

- この方法はステートレス VM に最適です。Elasticsearch クラスターとの間でノードを追加または削除するたびに、シャードの割り当てが変更され、負荷が分散されます。このプロセスでは、大量のネットワーク トラフィックとディスク I/O が生成されることがあり、データ取り込みレートに深刻な影響を与えます。そのような影響があるとしても、動的に起動する VM を増やすことで利用可能な処理リソースとメモリ リソースが増えるという利点で相殺されるかどうかを評価する必要があります。
- VM は瞬時には起動しません。追加 VM が利用可能になるまで、あるいはシャットダウンされるまで数分かかることがあります。長引く需要の変化に対応しなければならない場合にのみ、この方法で拡張してください。
- 拡張後、実際に縮小を検討しなければならないことがありますか。 Elasticsearch クラスターから VM を削除する作業はリソースが集中的に使用されるプロセスであり、その VM に配置されているシャードとレプリカを復元し、1 つまたは複数の残りのノードでそれらを再作成することが Elasticsearch に要求されます。複数の VM を同時に削除すると、クラスターの統合性が崩れ、復元が難しくなることがあります。また、多くの Elasticsearch 実装は時間の経過と共に大きくなりますが、データの性質上、量の面では少なくならない傾向があります。ドキュメントは手動で削除できます。また、ドキュメントに TTL (Time to Live/有効時間) を設定できます。有効時間が過ぎると、ドキュメントは削除されます。ただし、ほとんどの場合、前もって割り当てられている領域は新しいドキュメントや変更されたドキュメントによりすぐに再利用されます。ドキュメントが削除または変更されると、インデックス内に断片化が発生することがあります。その場合、Elasticsearch HTTP [Optimize][] API (Elasticsearch 2.0.0 以前) または [Force Merge][] API (Elasticsearch 2.1.0 以降) を利用し、最適化できます。

> [AZURE.NOTE] 最適化は非常にコストのかかる操作です。非常にアクティブなインデックスでは最適化を実行しないでください。ただし、休止状態にあるインデックスを最適化するのはよい方法です。これにより、検索に必要なリソースを減らすことができるためです。

### インデックスのシャードの数を決定する

クラスター内のノードの数は時間の経過と共に変わりますが、インデックス内のシャードの数はインデックスの作成後は変わりません。シャードを追加または削除する場合、データのインデックス作成をやり直す必要があります。必要な数のシャードで新しいインデックスを作成し、古いインデックスから新しいインデックスにデータをコピーします (エイリアスを利用し、データのインデックスがやり直された事実をユーザーから隠すことができます - 詳細については、「Maximizing Data Aggregation and Query Performance with Elasticsearch on Azure (Azure で Elasticsearch によるデータ集約とクエリのパフォーマンスを最大化する)」を参照してください)。そのため、クラスターで最初のインデックスを作成する前に、必要となりそうなシャードの数を決定することが重要です。次の手順でこの数を決定できます。

1. 本稼働でデプロイする予定のものと同じハードウェア構成を利用し、シングル ノードのクラスターを作成します。
2. 本稼働で使用する予定の構造に一致するインデックスを作成します。このインデックスにシャードを 1 つ与えます。レプリカは与えません。
3. 特定の量の現実的運用データをインデックスに追加します。
4. 一般的なクエリ、集約、その他のワークロードをインデックスに対して実行し、スループットと応答時間を計測します。
5. スループットと応答時間が許容範囲内であれば、手順 3 (データを追加) からプロセスを繰り返します。
6. シャードの容量に到達したようであれば (応答時間とスループットが許容範囲を超えたら)、ドキュメントの量をメモします。
7. 1 つのシャードの容量から本稼働で予想されるドキュメントの数を推定し、必要な数のシャードを計算します (この推定は科学的に正確ではないため、計算には許容誤差を含めてください)。

> [AZURE.NOTE] 各シャードは Lucene インデックスとして実装され、メモリ、CPU パワー、ファイル ハンドルを利用することに注意してください。シャードの数が多ければ、それだけ多くのリソースが必要になります。

また、作成するシャードが多ければ、拡張性が上がり、データ取り込みのスループットが増えます (ワークロードとシナリオにもよります)。ただし、多くのクエリで効率性が下がることがあります。既定では、クエリはインデックスで使用されるすべてのシャードに問い合わせます (必要なデータが配置されているシャードがわかっている場合、[カスタム ルーティング][]を利用し、この動作を変更できます)。

このプロセスではシャードの数の見積もりのみが生成されます。本稼働で予想されるドキュメントの量はわからないことがあります。その場合、(上記の) 初回の量と予想される増加率を決定してください。データベースのインデックスを変更する余裕ができるまでの期間のデータ増加を処理できる数のシャードを作成します。イベント管理やログ記録などのシナリオに使用されるその他の方法には、インデックスの繰り返し利用などがあります。毎日取り込まれるデータに新しいインデックスを作成し、最新のインデックスを指すように毎日切り替えられるエイリアスを介してこのインデックスにアクセスします。この方法では、古いデータをさらに簡単に削除し (不要になったインデックスを情報と共に削除できます)、データが管理しやすくなります。

ノードの数とシャードの数は一致する必要がないことに注意してください。たとえば、50 のシャードを作成する場合、最初に 10 のノードにそれらのシャードを分散し、その後、作業量の増加に合わせてノードを追加し、システムを拡張できます。ただし、少数のノードに対して例外的に多数のシャードを作成することは避けてください (たとえば、2 つのノードに 1000 のシャードを分散する)。この構成では、理論上、1000 ノードまでシステムを拡張できますが、1 つのノードで 500 のシャードを実行すると、ノードの性能が落ちることがあります。

> [AZURE.NOTE] データの取り込みが激しいシステムの場合、素数のシャードを使用することを検討してください。その場合、ドキュメントをシャードに送信するために Elasticsearch で使用される既定のアルゴリズムでは、分散がさらに均等になります。

### セキュリティに関する考慮事項

既定では、Elasticsearch は最小限のセキュリティを実装し、認証と権限承認の手段を提供しません。そのような側面から、基礎となるオペレーティング システムとネットワークを構成し、プラグインとサードパーティー ユーティリティを使用する必要があります。たとえば、[Shield][] や [Search Guard][] が使用されます。

> [AZURE.NOTE] Shield は Elastic が提供するユーザー認証、データ暗号化、ロール ベースのアクセス制御、IP フィルタリング、監査のプラグインです。場合によっては、ディスク暗号化など、他のセキュリティ対策を実装するように基礎オペレーティング システムを構成する必要があります。

運用システムでは、次の方法を検討する必要があります。

- クラスターへの不正アクセスを防止する。
- ユーザーを識別し、認証する。
- 認証されたユーザーに操作を実行する権限を与える。
- 不正操作またはシステムを壊す操作からクラスターを守る。
- 不正アクセスからデータを守る。
- 商用データ セキュリティの規制要件を満たす (適切な場合)

### クラスターへのアクセスを保護する

Elasticsearch はネットワーク サービスです。Elasticsearch クラスター内のノードは HTTP を利用してクライアント要求が入ってくるのを待ち、TCP チャンネルを利用して互いに通信します。許可のないクライアントが HTTP パスと TCP パスの両方で要求を送信するの防止するための対策をとる必要があります。次の項目について検討してください。

- VNET または VM の受信/送信ネットワーク トラフィックを特定のポートのみに限定するネットワーク セキュリティ グループを定義します。
- クライアント Web アクセス (9200) とプログラムによるネットワーク アクセス (9300) に使用される既定のポートを変更します。ファイアウォールを使用し、悪意のあるインターネット トラフィックから各ノードを保護します。
- クライアントの場所と接続に基づき、インターネットに直接アクセスしないプライベート サブネットにクラスターを配置します。クラスターをサブネットの外に公開しなければならない場合、クラスターを守るための対策が施された中継 (Bastion) サーバーやプロキシを経由してすべての要求を送信します。
- ノードに直接アクセスを与える必要がある場合、Elasticsearch Jetty プラグインを利用し、SSL 接続、認証、接続ログを提供します。あるいは、nginx プロキシ サーバーを構成し、HTTPS 認証を構成します。

> [AZURE.NOTE] nginx などのプロキシ サーバーを利用し、アクセスを機能に制限することもできます。たとえば、検索エンドポイントへの要求のみを許可するように nginx を構成し、クライアントが他の操作を実行するのを防止できます。

- 包括的なネットワーク アクセス セキュリティを増やす必要がある場合、Shield プラグインか Search Guard プラグインを使用します。

### ユーザーを識別し、認証する

クライアントからクラスターへの要求はすべて認証する必要があります。また、許可のないノードがクラスターに参加するのを防ぐ必要があります。システムへのバックドアを与え、認証が迂回されることがあります。

さまざまな種類の認証を実行する次のような Elasticsearch プラグインを利用できます。
- HTTP基本認証認証のたびにユーザー名とパスワードが要求されます。要求はすべて SSL/TLS または同じレベルの保護で暗号化する必要があります。
- LDAP と Active Directory の統合。この方法では、LDAP または AD グループのロールをクライアントに割り当てる必要があります。
- Elasticsearch クラスター自体に定義されている ID を利用したネイティブ認証。
- すべてのノードを認証するクラスター内の TLS 認証。
- IP フィルタリング。許可のないサブネットによる接続からクライアントを保護し、許可のないサブネットのクラスターへの参加からノードを保護します。

### クライアントの要求を承認する

認証は、このサービスの提供に使用される Elasticsearch プラグインに依存します。たとえば、基本認証を与えるプラグインは、一般的に、認証のレベルを定義する機能を与えます。LDAP または AD を使用するプラグインは、一般的に、クライアントをロールに関連付け、そのロールにアクセス権を割り当てます。特定のプラグインを使用するとき、次の点を考慮してください。
- クライアントが実行できる操作を制限する必要があるか。 たとえば、クライアントはクラスターの状態を監視できるか。インデックスを作成したり、削除したりできるか。
- クライアントにインデックスに関する制約を設定するべきか。 マルチテナント環境で、テナントに固有のインデックス セットを割り当て、そのセットには他のテナントがアクセスできないようにする場合、この制約は便利です。
- クライアントがデータを読み、インデックスに書き込めるようにするべきか。 たとえば、インデックスを利用したデータ検索を実行する許可をクライアントに与えるが、そのインデックスにデータを追加したり、インデックスからデータを削除したりする権限は与えません。

現在のところ、ほとんどのセキュリティ プラグインにおいて、クラスターまたはインデックス レベルで操作が制御されます。インデックス内のドキュメント サブセット レベルでは制御されません。これは効率性の面からの処置です。そのため、1 つのインデックス内の特定のドキュメントに要求を制限することは簡単ではありません。そのレベルの細かな制御が必要な場合、ドキュメントを個別のインデックスに保存し、インデックスをグループにまとめるエイリアスを使用します。たとえば、人事システムで、ユーザー A は部署 X の社員に関する情報が含まれるすべてのドキュメントにアクセスする必要があり、ユーザー B は部署 Y の社員に関する情報が含まれるすべてのドキュメントにアクセスする必要があり、ユーザー C は両方の部署の社員に関する情報が含まれるすべてのドキュメントにアクセスする必要がある場合、2 つのインデックス (部署 X 用と部署 Y 用) と両方のインデックスを参照するエイリアスを作成します。ユーザー A に最初のインデックスへの読み取りアクセスを与え、ユーザー B に 2 番目のインデックスへの読み取りアクセスを与え、ユーザー C にエイリアス経由で両方のインデックスへの読み取りアクセスを与えます。詳細については、「[Faking Index per User with Aliases (エイリアスでユーザーあたりのインデックスを偽造する)][]」を参照してください。

### クラスターを保護する

次のように厳重に保護しなければ、クラスターは悪用される可能性があります。

- セキュリティ上の脆弱性につながる可能性があるため、Elasticsearch クエリの動的クエリ スクリプティングを無効にします。クエリ スクリプティングではなく、ネイティブ スクリプトを使用します。ネイティブ スクリプトは Java で記述され、JAR ファイルにコンパイルされた Elasticsearch プラグインです。

> [AZURE.NOTE] 現在のところ、動的クエリ スクリプティングは既定では無効になっています。相当な理由がない限り、有効にしないでください。

- クエリ文字列の検索をユーザーに公開しないでください。クエリ文字列の検索では、ユーザーはリソースを大量に使用するクエリを妨げられることなく実行できます。そのような検索はクラスターのパフォーマンスに深刻な影響を与え、システムが DOS 攻撃にさらされることがあります。また、クエリ文字列検索では、個人情報が漏洩する可能性があります。
- 大量のメモリを使用する操作を禁止します。メモリ不足の例外が発生し、ノードで Elasticsearch が失敗します。大量のリソースを使用する操作を長時間続けた場合も、DOS 攻撃を招くことがあります。たとえば、次のようになります。
- 非常に大規模なフィールドをメモリに読み込もうとする検索要求 (そのようなフィールドでクエリがソーティング、スクリプティング、ファセッティングを実行する場合)。
  
> [AZURE.NOTE] [Doc 値][]を使用すると、フィールド データをメモリに読み込むのではなく、ディスクに保存することで、インデックスのメモリ要件を下げることができます。ノードでメモリが使い尽くされる可能性が少なくなりますが、速度は落ちます。

- 複数のインデックスに同時に問い合わせる検索。
- 大量のフィールドを読み出す検索。そのような検索は膨大な量のフィールド データをキャッシュさせ、メモリを使い果たします。既定では、フィールド データ キャッシュのサイズは無制限ですが、elasticsearch.yml 構成ファイルに [indices.fielddata.cache.*](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-fielddata.html) を設定し、利用できるリソースを制限できます。また、[フィールド データ サーキット ブレーカー][]を構成し、1 つのフィールドからキャッシュされたデータがメモリを使い尽くすのを防いだり、[要求サーキット ブレーカー][]を構成し、個々のクエリがメモリを独占するのを止めたりできます。このようなパラメーターを設定すると、クエリが失敗したり、タイムアウトになったりする可能性が増えます。
  
> [AZURE.NOTE] Elasticsearch では常に、現在のワークロードを実行するために必要なメモリがあるものと想定されます。メモリが不足すると、Elasticsearch サービスはクラッシュします。Elasticsearch はリソース使用状況 (HTTP [cat API][]) に関する情報を返すエンドポイントを提供します。細心の注意を払い、この情報を監視してください。

- 進行中のメモリ セグメントをフラッシュするのにあまりに長時間待機する。これによりメモリ内バッファー領域を使い果たすことがあります。必要であれば、データがディスクにフラッシュされるしきい値を減らすように [translog を設定][]します。

- 大量のメタデータでインデックスを作成する。フィールド名のバリエーションが多いドキュメントがインデックスに含まれると、たくさんのメモリが使用されます。詳細については、「[Mapping Explosion (マッピングの爆発的増加)][]」を参照してください。
  
> [AZURE.NOTE] 長時間操作やクエリ集中操作の定義はシナリオによって変わります。あるクラスターで一般的に予想されるワークロードのプロファイルは別のクラスターのワークロードとはまったく異なる可能性があります。許容されない操作を決定するには、アプリケーションの広範囲の調査とテストが必要です。

先を見越す。大きな損害やデータの紛失を引き起こされる前に悪意のある行為を検出し、止めます。通常とは異なるデータ アクセス パターンをすばやく検出し、ユーザーのログイン要求が失敗したり、予想されていないノードがクラスターに参加したり、クラスターから離れたり、操作に想定外の長い時間がかかったりしたときに警告を発するようなセキュリティの監視と通知のシステムを利用することを検討してください。そのようなタスクを実行できるツールに Elasticsearch [Watcher][] などがあります。

### データを保護する

SSL/TLS を利用して転送中のデータを保護できますが、Elasticsearch では、ディスクに保存されている情報を暗号化する機能が組み込まれていません。情報は普通のディスク ファイルに保存されます。そのファイルにアクセスできるユーザーはファイル内のデータを危険にさらすことがあります。たとえば、自分のクラスターにコピーできます。次の点を考慮してください。
- データが保存され、Elasticsearch で使用されるファイルを保護します。Elasticsearch 以外の ID に任意の読み取りまたは書き込みアクセスを許可しないでください。

- 暗号化ファイル システムを利用し、ファイルに保存されているデータを暗号化します。

> [AZURE.NOTE] Azure では、Linux と Windows の VM のディスク暗号化がサポートされるようになりました。詳細については、「[Azure Disk Encryption for Windows and Linux IaaS VMs Preview (Windows および Linux IaaS VM プレビューの Azure Disk Encryption)][]」を参照してください。

### 規制要件を満たす

規制要件は主に、イベントの履歴を保守管理する監査操作に関連します。そのような操作のプライバシーを守ることで、外部機関による監視 (または再現) を回避できます。特に、次の方法について検討する必要があります。

- (成功と失敗に関係なく) すべての要求とシステムへのすべてのアクセス試行を追跡記録する方法。
- クライアントがクラスターに行う通信とクラスターが実行するノード間の通信を暗号化する方法。あらゆるクラスター通信に SSL/TLS を実装してください。Elasticsearch では、SSL/TLS を介して利用できるものと組織の要件が異なる場合、プラグ可能な暗号もサポートしています。
- あらゆる監査データを安全に保管する方法。監査情報は急速に増加します。監査情報の改ざんを防ぐために、堅牢な方法で保護する必要があります。
- 監査データを安全にアーカイブする方法。

### 監視に関する考慮事項

監視はオペレーティング システム レベルと Elasticsearch レベルの両方で重要です。

オペレーティング システム固有のツールを利用し、オペレーティング システム レベルで監視できます。Windows の場合、パフォーマンス モニターとパフォーマンス カウンターなどを利用できます。Linux の場合、 *vmstat* 、 *iostat* 、 *top* などのツールを利用できます。オペレーティング システムで監視する主要な項目は、CPU 利用率、ディスク I/O ボリューム、ディスク I/O 待機時間、ネットワーク トラフィックなどです。効果的に調整された Elasticsearch クラスターでは、Elasticsearch プロセスの CPU 利用率は高く、ディスク I/O 待機時間は最小限に抑えられるはずです。

ソフトウェア レベルでは、要求のスループットと応答時間、失敗した要求の詳細を監視する必要があります。Elasticsearch にはさまざまな API があります。それを利用し、クラスターのさまざまな側面のパフォーマンスを観察できます。2 つの最も重要な API は *\_cluster/health* と *\_nodes/stats* です。*\_cluster/health* API を利用し、クラスターの全体的健全性のスナップショットを撮影できます。次の例のように、インデックスごとの詳細が表示されます。

`GET _cluster/health?level=indices`

次の出力例はこの API を使用して生成されました。

```json
{
    "cluster_name": "elasticsearch",
    "status": "green",
    "timed_out": false,
    "number_of_nodes": 6,
    "number_of_data_nodes": 3,
    "active_primary_shards": 10,
    "active_shards": 20,
    "relocating_shards": 0,
    "initializing_shards": 0,
    "unassigned_shards": 0,
    "delayed_unassigned_shards": 0,
    "number_of_pending_tasks": 0,
    "number_of_in_flight_fetch": 0,
    "indices": {
        "systwo": {
            "status": "green",
            "number_of_shards": 5,
            "number_of_replicas": 1,
            "active_primary_shards": 5,
            "active_shards": 10,
            "relocating_shards": 0,
            "initializing_shards": 0,
            "unassigned_shards": 0
        },
        "sysfour": {
            "status": "green",
            "number_of_shards": 5,
            "number_of_replicas": 1,
            "active_primary_shards": 5,
            "active_shards": 10,
            "relocating_shards": 0,
            "initializing_shards": 0,
            "unassigned_shards": 0
        }
    }
}
```

このクラスターには、「*systwo*」という名前のクラスターと「*sysfour*」という名前のクラスターがあります。インデックスごとに監視する主要な統計値は status、active\_shards、unassigned\_shards です。ステータスは緑でなければなりません。active\_shards の数は number\_of\_shards と number\_of\_replicas を反映している必要があります。unassigned\_shards はゼロでなければなりません。ステータスが「赤」の場合、インデックスの一部が欠けているか、壊れています。 *active\_shards* 設定が *number\_of\_shards* - (*number\_of\_replicas* + 1) 未満で、unassigned\_shards がゼロではない場合、インデックスは破損しています。黄のステータスはインデックスが遷移状態にあることを示します。レプリカを追加したか、シャードの位置を変更したためです。繊維が完了すると、ステータスが緑に切り替わります。長時間にわたり黄のままか、赤に変わった場合、オペレーティング システム レベルで重大な I/O イベントが発生していないか確認してください (ディスクやネットワークの故障など)。
\_nodes/stats API はクラスターの各ノードに関する広範囲の情報を出します。

`GET _nodes/stats`

生成される出力には、各ノードに保存されたインデックスに関する詳細 (ドキュメントのサイズや数など)、インデックスの作成、クエリ、検索、結合、キャッシュにかかった時間、オペレーティング システムとプロセスの情報、JVM に関する統計値 (ガベージ コレクションのパフォーマンスを含む)、スレッド プールなどがあります。詳細については、「[Monitoring Individual Nodes (個々のノードを監視する)][]」を参照してください。

Elasticsearch 要求の大きな部分が失敗し、*EsRejectedExecutionException* エラー メッセージが表示された場合、Elasticsearch は送られた作業に対応できなくなっています。その場合、Elasticsearch が後れをとる理由となっているボトルネックを特定する必要があります。次の項目について検討してください。

- JVM に割り当てられているメモリが十分ではなく、過度の数のガベージ コレクションを引き起こしているなど、ボトルネックがリソースの制約に起因する場合、追加リソースの割り当てを検討してください (この場合、もっとメモリを使用するように JVM を構成します。ノードで利用できるストレージの 50% まで使用できます。「[メモリの要件][]」を参照してください)。
- クラスターが示す I/O 待機時間が長く、\_node/stats API を利用して回収された結合統計値に含まれる値が大きい場合、インデックスの書き込みが大量になっています。「Optimizing Resources for Indexing Operations (インデックス作成操作用のリソースの最適化)」セクションの注意点をもう一度確認し、インデックス作成のパフォーマンスを調整してください。
- データ取り込み操作を実行しているクライアント アプリケーションを調整し、その効果を確認します。この方法で大幅な改善が見られる場合、その調整を維持するか、書き込みが多いインデックスの負荷を分散するノードを増やすことを検討してください。詳細については、「Maximizing Data Ingestion Performance with Elasticsearch on Azure (Azure での Elasticsearch によるデータ インジェスト パフォーマンスの最大化)」を参照してください。
- インデックスの検索統計値から、クエリに時間がかかりすぎることが示された場合、クエリを最適化する方法を検討してください。詳細については、「[Query Tuning (クエリのチューニング)][]」セクションを参照してください。検索統計値で報告された *query\_time\_in\_millis* 値と *query\_total* 値を利用し、クエリ効率性の大まかな指針を計算できます。*query\_time\_in\_millis* / *query\_total* という方程式で各クエリの平均時間がわかります。

### Elasticsearch を監視するためのツール

さまざまなツールを利用し、本稼働の Elasticsearch を毎日監視できます。これらのツールでは、通常、基礎となる Elasticsearch API を利用して情報を収集し、生データよりも観察しやすい方法で詳細を提示します。一般的な例としては、[Elasticsearch-Head][]、[Bigdesk][]、[Kopf][]、[Marvel][] などがあります。

Elasticsearch-Head、Bigdesk、Kopf は Elasticsearch ソフトウェアのプラグインとして実行されます。Marvel の最新版は独立して実行できますが、データ キャプチャとホスティング環境を提供するには [Kibana][] を必要とします。Marvel と Kibana を使用する利点は、Elasticsearch クラスターとは離れた環境に監視を実装できるということです。監視ツールが Elasticsearch ソフトウェアの一部として実行されている場合は発見できないような問題を Elasticsearch で見つけることができます。たとえば、Elasticsearch が繰り返し失敗したり、動作が非常に遅かったりする場合、Elasticsearch プラグインとして実行されるツールも影響を受け、監視と診断が難しくなります。

オペレーティング システム レベルでは、[Azure Operations Management Suite][] のログ分析機能や [Azure ポータルの Azure 診断][]などのツールを利用し、Elasticsearch ノードをホストしている VM のパフォーマンス データをキャプチャできます。もう 1 つの方法は [Logstash][] を利用してパフォーマンスとログのデータをキャプチャし、離れたところにある Elasticsearch クラスターにその情報を保存し (アプリケーションに使用しているクラスターと同じクラスターを使用しないでください)、Kibana でデータを視覚化することです。詳細については、「[Microsoft Azure Diagnostics with ELK (ELK による Microsoft Azure 診断)][]」を参照してください。

### Elasticsearch パフォーマンスをテストするためのツール

Elasticsearch をベンチマーク解析するか、クラスターのパフォーマンス テストを実行する場合、他のツールを利用できます。これらのツールは、運用環境ではなく、開発またはテスト環境で使用するためのものです。頻繁に使用されるツールは [Apache JMeter][] です。

JMeter は、このガイドに関連するドキュメントで説明されているベンチマーク解析や他の負荷テストに使用されました。JMeter の構成と使用に関する詳細は、「Running Performance Tests on Elasticsearch Using JMeter (JMeter を利用し、Elasticsearch のパフォーマンス テストを実行する)」にあります。

## 次のステップ
- [Elasticsearch: 決定版ガイド](https://www.elastic.co/guide/en/elasticsearch/guide/master/index.html)

[Apache JMeter]: http://jmeter.apache.org/
[Apache Lucene]: https://lucene.apache.org/
[Automatically scale machines in a Virtual Machine Scale Set (仮想マシン スケール セットでのマシンの自動スケール)]: virtual-machines-vmss-walkthrough/
[Azure Disk Encryption for Windows and Linux IaaS VMs Preview (Windows および Linux IaaS VM プレビューの Azure Disk Encryption)]: azure-security-disk-encryption/
[Azure Load Balancer]: load-balancer-overview/
[ExpressRoute]: expressroute-introduction/
[内部ロード バランサー]: load-balancer-internal-overview/
[Sizes for Virtual Machines (Virtual Machines のサイズ)]: virtual-machines-size-specs/

[メモリの要件]: #memory-requirements
[ネットワークの要件]: #network-requirements
[ノード検出]: #node-discovery
[Query Tuning (クエリのチューニング)]: #query-tuning

[A Highly Available Cloud Storage Service with Strong Consistency]: http://blogs.msdn.com/b/windowsazurestorage/archive/2011/11/20/windows-azure-storage-a-highly-available-cloud-storage-service-with-strong-consistency.aspx
[厳密な整合性を利用した高可用性クラウド ストレージ サービス]: http://blogs.msdn.com/b/windowsazurestorage/archive/2011/11/20/windows-azure-storage-a-highly-available-cloud-storage-service-with-strong-consistency.aspx
[Azure クラウド プラグイン]: https://www.elastic.co/blog/azure-cloud-plugin-for-elasticsearch
[Azure ポータルの Azure 診断]: https://azure.microsoft.com/blog/windows-azure-virtual-machine-monitoring-with-wad-extension/
[Azure Operations Management Suite]: https://www.microsoft.com/server-cloud/operations-management-suite/overview.aspx
[Azure クイックスタート テンプレート]: https://azure.microsoft.com/documentation/templates/
[Bigdesk]: http://bigdesk.org/
[cat API]: https://www.elastic.co/guide/en/elasticsearch/reference/1.7/cat.html
[translog を設定]: https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-translog.html
[カスタム ルーティング]: https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-routing-field.html
[Doc 値]: https://www.elastic.co/guide/en/elasticsearch/guide/current/doc-values.html
[Elasticsearch]: https://www.elastic.co/products/elasticsearch
[Elasticsearch-Head]: https://mobz.github.io/elasticsearch-head/
[Elasticsearch.Net と NEST]: http://nest.azurewebsites.net/
[Elasticsearch スナップショット/復元モジュール]: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html
[Faking Index per User with Aliases (エイリアスでユーザーあたりのインデックスを偽造する)]: https://www.elastic.co/guide/en/elasticsearch/guide/current/faking-it.html
[フィールド データ サーキット ブレーカー]: https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-fielddata.html#fielddata-circuit-breaker
[Force Merge]: https://www.elastic.co/guide/en/elasticsearch/reference/2.1/indices-forcemerge.html
[ゴシップ プロトコル]: https://en.wikipedia.org/wiki/Gossip_protocol
[Kibana]: https://www.elastic.co/downloads/kibana
[Kopf]: https://github.com/lmenezes/elasticsearch-kopf
[Logstash]: https://www.elastic.co/products/logstash
[Mapping Explosion (マッピングの爆発的増加)]: https://www.elastic.co/blog/found-crash-elasticsearch#mapping-explosion
[Marvel]: https://www.elastic.co/products/marvel
[Microsoft Azure Diagnostics with ELK (ELK による Microsoft Azure 診断)]: https://github.com/mspnp/semantic-logging/tree/elk
[Monitoring Individual Nodes (個々のノードを監視する)]: https://www.elastic.co/guide/en/elasticsearch/guide/current/_monitoring_individual_nodes.html#_monitoring_individual_nodes
[nginx]: http://nginx.org/en/
[ノード クライアント API]: https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/node-client.html
[Optimize]: https://www.elastic.co/guide/en/elasticsearch/reference/1.7/indices-optimize.html
[PubNub Changes Plugin]: http://www.pubnub.com/blog/quick-start-realtime-geo-replication-for-elasticsearch/
[要求サーキット ブレーカー]: https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-fielddata.html#request-circuit-breaker
[Search Guard]: https://github.com/floragunncom/search-guard
[Shield]: https://www.elastic.co/products/shield
[トランスポート クライアント API]: https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/transport-client.html
[トライブ ノード]: https://www.elastic.co/blog/tribe-node
[Watcher]: https://www.elastic.co/products/watcher
[Zen]: https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery-zen.html

<!-----HONumber=AcomDC_0211_2016-->
