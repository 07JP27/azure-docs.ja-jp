<properties
   pageTitle="Azure の Elasticsearch でのデータ集計およびクエリのパフォーマンスのチューニング | Microsoft Azure"
   description="Elasticsearch のクエリおよび検索のパフォーマンスを最適化するときの考慮事項の概要。"
   services=""
   documentationCenter="na"
   authors="mabsimms"
   manager="marksou"
   editor=""
   tags=""/>

<tags
   ms.service="guidance"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="na"
   ms.date="02/29/2016"
   ms.author="masimms"/>
   
# Azure の Elasticsearch でのデータ集計およびクエリのパフォーマンスのチューニング


この記事は[シリーズの一部](guidance-elasticsearch.md)です。

Elasticsearch を使用する主な理由は、データの検索をサポートするためです。ユーザーは、探している情報をすばやく見つけることができる必要があります。さらに、ユーザーがデータについて質問し、相関関係を発見し、ビジネス上の判断を下せる結論を得ることができるようなシステムでなければなりません。情報をデータと異なるものにしているのはこのような処理です。

このドキュメントでは、クエリと検索に関して最高のパフォーマンスが得られるシステムにする最善の方法を決定するときに考慮できるオプションについて説明します。

パフォーマンスに関するすべての推奨事項は、状況に適用されるシナリオ、インデックスを作成するデータの量、アプリケーションやユーザーがデータをクエリする頻度に大きく依存します。独自のデータとワークロードを使用して構成またはインデックス構造の変更の結果を慎重にテストし、特定のシナリオに対するメリットを評価する必要があります。そのため、このドキュメントでは、さまざまな構成を使用して実装されている 1 つの特定のシナリオに対して実行されたさまざまなベンチマークについても説明します。使用されている方法を調整して、実際のシステムのパフォーマンスを評価できます。これらのテストの詳細については、「[付録](#appendix-the-query-and-aggregation-performance-test)」を参照してください。

## インデックスとクエリのパフォーマンスに関する考慮事項

このセクションでは、高速なクエリと検索をサポートする必要があるインデックスを設計するときに考慮する必要のあるいくつかの一般的な要因について説明します。

### インデックスに複数のタイプを格納する

Elasticsearch のインデックスは、複数のタイプを含むことができます。このようなことはせず、タイプごとに個別のインデックスを作成する方がよい場合があります。次の点を考慮してください。

- タイプが異なると指定されるアナライザーが異なる場合があり、クエリがタイプ レベルではなくインデックス レベルで実行される場合は、Elasticsearch で使用する必要があるアナライザーがはっきりしないことがあります。詳細については、「[Avoiding Type Gotchas (タイプの注意事項の回避)](https://www.elastic.co/guide/en/elasticsearch/guide/current/mapping.html#_avoiding_type_gotchas)」を参照してください。

- 複数のタイプを保持するインデックスのシャードは、単一のタイプを含むインデックスのシャードより大きくなりがちです。シャードが大きいほど、クエリ実行時に Elasticsearch がデータのフィルター処理に必要な作業が多くなります。

- タイプによってデータ量に大きな差がある場合、少ないタイプの情報は多くのシャードの間にまばらに分散し、そのデータを取得する検索の効率が低下します。

    ![](./media/guidance-elasticsearch/query-performance1.png)

    ***図 1.異なるタイプでインデックスを共有した場合の影響***

    図 1 は、このような状況を示したものです。図の上部では、同じインデックスをタイプ A とタイプ B のドキュメントで共有しています。タイプ A のドキュメントの方がタイプ B より多く存在します。タイプ B の検索では、4 つのシャードすべてがクエリされます。図の下部では、タイプごとにインデックスを分けた場合の効果が示されています。この場合、タイプ A の検索でアクセスする必要があるシャードは 2 つだけです。

- 小さいシャードは大きいシャードより均等に分散でき、Elasticsearch によるノード間への負荷の分散が容易になります。

- タイプが異なると、保持期間が異なる場合があります。アクティブなデータとシャードを共有する古いデータをアーカイブするのは難しいことがあります。


ただし、次のような状況では、異なるタイプの間でインデックスを共有すると効率的な場合があります。

- 通常、検索が同じインデックスで保持されている異なるタイプを対象とする場合。

- 各タイプのドキュメントの数が少ない場合。タイプごとに個別にシャードのセットを管理すると、オーバーヘッドが大きくなります。


### インデックス タイプの最適化

Elasticsearch インデックスには、インデックスの作成に使用された元の JSON ドキュメントのコピーが含まれています。この情報は、インデックスを作成された各項目の [*\_source*](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html#mapping-source-field) フィールドに保持されています。このデータは検索できませんが、*取得*および*検索*要求では既定で返されます。ただし、このフィールドはオーバーヘッドを発生させ、記憶域を占めるので、シャードが大きくなり、実行される I/O の量が増加します。タイプごとに *\_source* フィールドを無効にできます。

```http
PUT my_index
{
  "mappings": {
    "my_type": {
      "_source": {
        "enabled": false
      }
    }
  }
}
```
このフィールドを無効にすると、次の操作を実行する機能も削除されます。

- *更新* API を使用してインデックス内のデータを更新する。

- 強調表示されたデータを返す検索を実行する。

- Elasticsearch のあるインデックスから別のインデックスに直接インデックスを再作成する。

- マッピングまたは分析の設定を変更する。

- 元のドキュメントを表示してクエリをデバッグする。


### データのインデックスの再作成

インデックスに使用可能なシャードの数は、最終的にインデックスの容量を決定します。必要になるシャードの数を最初に (情報に基づいて) 予測できますが、ドキュメントのインデックス再作成戦略を常に前もって考えておく必要があります。多くの場合、インデックスの再作成はデータの増加に合わせた意図的なタスクです。検索を最適化するため最初はインデックスに割り当てるシャードの数を少なくしておき、データの量が増えたら新しいシャードを割り当てます。それ以外では、データ量増加の推定が正しくないことがわかった場合は、さらに臨機応変にインデックス再作成の実行が必要になることがあります。

> [AZURE.NOTE] すぐに古くなるデータの場合は、インデックスの再作成が必要ないことがあります。その場合は、アプリケーションで各期間の新しいインデックスを作成する場合があります。たとえば、毎日新しいインデックスに格納されるパフォーマンス ログや監査データなどです。

<!-- -->

インデックスの再作成では、実質的に、古いインデックスのデータからの新しいインデックスの作成と、古いインデックスの削除が行われます。インデックスが大きい場合、この処理には時間がかかり、この処理の間もデータを検索可能にしておくことが必要な場合があります。そのためには、[各インデックスのエイリアス](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html)を作成し、クエリではエイリアスからデータを取得する必要があります。インデックスの再作成中はエイリアスが古いインデックスを参照するようにしておき、インデックスの再作成が完了したら新しいインデックスを参照するように切り替えます。この方法は、毎日新しいインデックスが作成される時間ベースのデータにアクセスする場合にも便利です。現在のデータにアクセスするには、新しいインデックスが作成されたらそれにロール オーバーするエイリアスを使用します。

### マッピングの管理

Elasticsearch では、ドキュメント内の各フィールドのデータを解釈する方法を決定するためにマッピングが使用されます。タイプごとに固有のマッピングがあり、実質的にそのタイプのスキーマを定義します。Elasticsearch はこの情報を使用して、あるタイプのドキュメントの各フィールドの逆インデックスを生成します。どのようなドキュメントでも、フィールドごとにデータ型 (*string*、*date*、*long* など) と値があります。インデックスを最初に作成するときにインデックスのマッピングを指定することも、または新しいドキュメントをタイプに追加するときに Elasticsearch で推測することもできます。ただし、次の点を考慮してください。

- 動的に生成されるマッピングは、ドキュメントがインデックスに追加されるときのフィールドの解釈方法によっては、エラーの原因になることがあります。たとえば、数値を保持するフィールド A を含むドキュメント 1 により、このフィールドが *long* であると指定するマッピングを Elasticsearch が追加するものとします。その後で追加されるドキュメントのフィールド A が非数値データの場合、エラーになります。この場合はおそらく、最初のドキュメントが追加されるときに、フィールド A を文字列と解釈する必要があります。インデックスの作成時にこのマッピングを指定すると、このような問題を回避するのに役立ちます。

- 過剰に大きなマッピングが生成されないように、ドキュメントをデザインします。マッピングが大きいと、検索実行時に大きなオーバーヘッドが発生し、大量のメモリを消費し、クエリでデータが見つからない原因になることもあります。ドキュメント内の同じタイプのフィールドには、一貫性のある名前付け規則を使用します。たとえば、ドキュメントごとに "first\_name"、"FirstName"、"forename" などと異なるフィールド名を使うのではなく、すべてのドキュメントで同じフィールド名を使用します。さらに、値をキーとして使わないようにします (これは列ファミリ データベースでの一般的な方法ですが、Elasticsearch では非効率性とエラーの原因になることがあります)。 詳細については、「[Mapping Explosion (マッピングの爆発的増加)](https://www.elastic.co/blog/found-crash-elasticsearch#mapping-explosion)」を参照してください。

- 必要に応じて、*not\_analyzed* を使用してトークン化を回避します。たとえば、あるドキュメントの *data* という名前の文字列フィールドに値 "ABC-DEF" が保持されていて、次のようにこの値と一致するすべてのドキュメントを検索するものとします。

  ```http
  GET /myindex/mydata/_search
  {
    "query" : {
      "filtered" : {
        "filter" : {
          "term" : {
            "data" : "ABC-DEF"
          }
        }
      }
    }
  }
  ```

    However, this search will fail to return the expected results due to the way in which the string ABC-DEF is tokenized when it is indexed; it will be effectively split into two tokens, ABC and DEF, by the hyphen. This feature is designed to support full text searching, but if you want the string to be interpreted as a single atomic item you should disable tokenization when the document is added to the index. You can use a mapping such as this:

  ```http
  PUT /myindex
  {
    "mappings" : {
      "mydata" : {
        "properties" : {
          "data" : {
            "type" : "string",
            "index" : "not_analyzed"
          }
        }
      }
    }
  }
  ```

  詳細については、「[Finding Exact Values (正確な値の検索)](https://www.elastic.co/guide/en/elasticsearch/guide/current/_finding_exact_values.html#_term_filter_with_text)」を参照してください。


### doc 値の使用

多くのクエリと集計では、検索操作の一部としてデータの並べ替えが必要になります。並べ替えでは、1 つまたは複数の用語をドキュメントのリストにマップできる必要があります。このプロセスを補助するため、Elasticsearch では並べ替えキーとして使用されるフィールドのすべての値をメモリに読み込むことができます。この情報は*フィールドデータ*と呼ばれます。この機能の目的は、フィールドデータをメモリにキャッシングすることで I/O を減らすことであり、同じデータをディスクから繰り返し読むより速くなる可能性があります。ただし、フィールドの基数が高い場合は、フィールドデータをメモリに格納すると、大量のヒープ領域を消費し、他の同時操作のパフォーマンスに影響を与えたり、記憶域を使い果たして Elasticsearch で障害が発生したりする可能性さえあります。

代わりの方法として、Elasticsearch では *doc 値*もサポートされています。doc 値はメモリ内のフィールドデータの項目と似ていますが、ディスクに格納され、データがインデックスに格納されるときに作成される点が異なります (フィールドデータはクエリ実行時に動的に構築されます)。 doc 値はヒープ領域を消費しないので、非常に多数の一意値を含む可能性があるフィールド間でデータの並べ替えまたは集計を行うクエリに適しています。さらに、ヒープの負荷が減ることで、データをディスクから取得する場合とメモリから読み取る場合のパフォーマンスの差を埋め合わせできます。ガベージ コレクションの発生頻度や、メモリを利用する他の同時操作が受ける影響も、低下する可能性があります。

次の例で示すように、doc 値は、*doc\_values* 属性を使用してインデックスのプロパティ単位で有効または無効にします。

```http
PUT /myindex
{
  "mappings" : {
    "mydata" : {
      "properties" : {
        "data" : {
          ...
          "doc_values": true
        }
      }
    }
  }
}
```
> [AZURE.NOTE] Elasticsearch バージョン 2.0.0 以降では、doc 値は既定で有効になっています。

doc 値を使用することによる厳密な影響は、実際のデータおよびクエリのシナリオと密接に関係するので、パフォーマンス テストを行って有用性を確認することを考える必要があります。また、doc 値は分析済みの文字列フィールドでは動作しないことにも注意してください。詳細については、「[Doc Values (doc 値)](https://www.elastic.co/guide/en/elasticsearch/guide/current/doc-values.html#doc-values)」を参照してください。

### レプリカを使用したクエリの競合の削減

クエリのパフォーマンス向上のためによく使われる方法は、各インデックスの多数のレプリカを作成するというものです。データ取得操作には、レプリカからデータをフェッチして対応できます。ただし、この方法はデータ取り込み操作のパフォーマンスに大きな影響を与える可能性があるので、複数のワークロードが関連するシナリオでは注意して使用する必要があります。さらに、この方法にメリットがあるのは、レプリカが複数のノードに分散されていて、同じインデックスの一部であるプライマリ シャードとリソースを競合しない場合だけです。インデックスのレプリカの数を動的に増減できることを憶えておいてください。

### シャード要求キャッシュの使用

Elasticsearch は、クエリによって要求されたローカル データを各シャードのメモリにキャッシュできます。データをディスク ストレージからではなくメモリから読み取ることができるので、同じデータを取得する検索の速度が向上します。このようにしてデータをキャッシュすれば、一部の検索操作でのパフォーマンスは向上しますが、その分、同時に実行されている他のタスクに費やすことのできるメモリは減少します。また、キャッシュから得られるデータが古くなっているおそれもあります。キャッシュ内のデータが無効になるのは、シャードが更新されてデータが変化したときだけです。更新の頻度は、インデックスの *refresh\_interval* 設定の値で制御できます。

既定ではインデックスの要求キャッシュは無効になっていますが、次のようにして有効にできます。

```http
PUT /myindex/_settings
{
  "index.requests.cache.enable": true
}
```

シャード要求キャッシュが最も適しているのは、履歴データやログ データのような比較的変化しない情報の場合です。

### クライアント ノードの使用

すべてのクエリは、要求を最初に受信したノードによって処理されます。このノードは、クエリ対象のインデックスのシャードが含まれている他のすべてのノードにさらに要求を送信し、応答を返すために結果を蓄積します。クエリにデータの集計または複雑な計算の実行が含まれる場合、最初のノードは適切な処理の実行を担当します。比較的少数の複雑なクエリをサポートするシステムの場合は、クライアント ノードのプールを作成してデータ ノードの負荷を軽減することを考えてください。逆に、多数の単純なクエリを処理する場合は、要求をデータ ノードに直接送信し、ロード バランサーを使用して要求を均等に分散させます。

### クエリのチューニング

Elasticsearch クエリのパフォーマンスを最大限に引き出すうえでのヒントを以下にまとめました。

- ワイルド カードを含んだクエリは可能な限り避ける。

- 同じフィールドがフルテキスト検索と完全一致の対象である場合、そのフィールドのデータを、解析済みの形式と未解析の形式で格納することを検討する。フルテキスト検索は解析済みのフィールドに対して行い、完全一致検索は未解析のフィールドに対して行います。

- 必要なデータのみを返す。対象となるドキュメントは大きくても、アプリケーションで必要な情報がフィールドの一部分にのみ格納されている場合は、ドキュメント全体ではなくその部分だけをクエリから返すようにします。そうすることで、クラスターのネットワーク帯域幅要件を下げることができます。

- データを検索する際はクエリではなく、可能な限りフィルターを使用する。フィルターは単に、ドキュメントが特定の条件と一致しているかどうかを判断するものです。それに対し、クエリではドキュメントの一致度も計算されます (スコアリング)。フィルターによって生成された値は内部的に、各ドキュメントの一致/不一致を示すビットマップとして保存され、Elasticsearch でキャッシュすることができます。以後、同じフィルター条件が適用された場合、そのビットマップをキャッシュから取得すれば、一致するドキュメントをすばやくフェッチすることができます。詳細については、「[Internal Filter Operation (内部フィルター操作)](https://www.elastic.co/guide/en/elasticsearch/guide/current/_finding_exact_values.html#_internal_filter_operation)」を参照してください。

- 静的な比較には *bool* フィルターを使用し、*and* フィルターと *or* フィルター、*not* フィルターの使用は、スクリプトや *geo-** フィルターを伴うものなど動的計算フィルターに限定する。

- *geo-** フィルターを伴う *and*/*or*/*not* と *bool* フィルターとを 1 つのクエリの中で組み合わせる場合、*and*/*or*/*not の geo-** フィルターは、作用の対象となるデータセットを最小限に抑えるために最後に置いてください。

    同様に、負荷の大きいフィルター操作は、*post\_filter* を使って実行してください。これらのフィルターは最後に実行されます。

- ファセットではなく集計を使用する。分析を伴う集計計算や、候補となる値が多数存在する集計計算は避けます。

    > **注**: ファセットは、Elasticsearch Version 2.0.0 で廃止されました。

- 一致する項目の件数を正確に把握する必要がある場合を除き、*value\_count* 集計よりも*カーディナリティ*集計を優先的に使用する。正確な件数はすぐに変化してしまう可能性があります。また、アプリケーションで必要となるのは多くの場合、おおよその概算です。

- スクリプトは避ける。クエリやフィルターに含まれるスクリプトは負荷が大きく、しかも結果がキャッシュされません。長時間実行されるスクリプトは検索スレッドを際限なく消費し、後続の要求がキューに格納される原因となります。キューがいっぱいになると、それ以上の要求は拒否されます。

## 集計と検索のパフォーマンスのテストと分析

このセクションでは、さまざまなクラスターおよびインデックス構成に対して実行された一連のテストの結果について説明します。実施したテストは以下の 2 種類です。

- ***取り込み/クエリ複合*テスト**。このテストは、一括挿入操作 (各操作では 1,000 個のドキュメントが追加されました) を実行してテスト用に設定された空のインデックスを使用して開始されました。同時に、直近 15 分間に追加されたドキュメントを検索して集計を生成するように設計された複数のクエリが、5 秒間隔で繰り返されました。大規模なデータを取り込んでほぼリアルタイムで問い合わせるという、処理能力が問われるようなワークロードの実態を再現するために、テストの実行には概して 24 時間の猶予を与えるようにしました。

- ***クエリ単体*テスト**。*取り込み/クエリ複合*テストに似ていますが、取り込みの部分が省略されている点、また各ノードのインデックスに、あらかじめ 1 億件のドキュメントが投入されている点が異なります。こちらは静的なデータとなるため、実行する一連のクエリも変更されています。直近 15 分間に追加されたドキュメントという時間的制約が取り除かれました。テストの実行時間は 90 分です。データの量が決まっているので、パフォーマンス パターンを特定するのに必要な時間も短くなります。

---

インデックス内の各ドキュメントのスキーマは同じでした。次の表はスキーマのフィールドをまとめたものです。

名前 | 型 | メモ |
  ----------------------------- | ------------ | -------------------------------------------------------- |
 Organization | String | 200 個の一意の組織が生成されます。 |
 CustomField1 ～ CustomField5 |String |これら 5 つの文字列フィールドには空の文字列が設定されます。|
 DateTimeRecievedUtc |Timestamp |ドキュメントが追加された日付と時刻です。|
 Host |String |このフィールドには空の文字列が設定されます。|
 HttpMethod |String |このフィールドには、"POST"、"GET"、"PUT" のいずれかの値が設定されます。|
 HttpReferrer |String |このフィールドには空の文字列が設定されます。|
 HttpRequest |String |このフィールドには、長さが 10 ～ 200 文字のランダムなテキストが設定されます。|
 HttpUserAgent |String |このフィールドには空の文字列が設定されます。|
 HttpVersion |String |このフィールドには空の文字列が設定されます。|
 OrganizationName |String |このフィールドには、Organization フィールドと同じ値が設定されます。|
 SourceIp |IP |このフィールドには、データの「生成元」を示す IP アドレスが設定されます。 |
 SourceIpAreaCode |Long |このフィールドには 0 が設定されます。|
 SourceIpAsnNr |String |このフィールドには "AS#####" が設定されます。|
 SourceIpBase10 |Long |このフィールドには 500 が設定されます。|
 SourceIpCountryCode |String |このフィールドには、2 文字の国コードが設定されます。 |
 SourceIpCity |String |このフィールドには、国の都市を示す文字列が設定されます。 |
 SourceIpLatitude |Double |このフィールドには、ランダムな値が設定されます。|
 SourceIpLongitude |Double |このフィールドには、ランダムな値が設定されます。|
 SourceIpMetroCode |Long |このフィールドには 0 が設定されます。|
 SourceIpPostalCode |String |このフィールドには空の文字列が設定されます。|
 SourceLatLong |Geo point |このフィールドには、ランダムな地理的ポイントが設定されます。|
 SourcePort |String |このフィールドには、ランダムな数値の文字列表現が設定されます。|
 TargetIp |IP |このフィールドには、0.0.100.100 ～ 255.9.100.100 の範囲のランダムな IP アドレスが設定されます。|
 SourcedFrom |String |このフィールドには、文字列 "MonitoringCollector" が設定されます。|
 TargetPort |String |このフィールドには、ランダムな数値の文字列表現が設定されます。|
 Rating |String |このフィールドには、20 個の異なる文字列からランダムに選択された値が設定されます。|
 UseHumanReadableDateTimes |Boolean |このフィールドには false が設定されます。|
 
毎回テスト時には、以下のクエリを一括実行しました。以後、これらのクエリの名称は斜体で示しています。なお、*クエリ単体*テストについては、時間的条件 (直近 15 分間に追加されたドキュメント) を排除しました。

- 過去 15 分間に追加されたドキュメントの *Rating* ごとの数 (*Rating 別数*)

- 過去 15 分間に追加されたドキュメントの 5 分ごとの数 (*時間別数*)

- 過去 15 分間に追加されたドキュメントの、国別かつ *Rating* 値別の数 (*国別ヒット数*)

- 過去 15 分間に追加されたドキュメントで、最も頻度が多かった上位 15 の組織 (*上位 15 組織*)

- 過去 15 分間に追加されたドキュメントでの異なる組織の数 (*固有組織数*)

- 過去 15 分間に追加されたドキュメントの数 (*合計ヒット数*)

- 過去 15 分間に追加されたドキュメントでの異なる *SourceIp* 値の数 (*固有 IP 数*)


インデックスの定義とクエリの詳細は、[付録](#appendix-the-query-and-aggregation-performance-test)に記載しています。

テストの目的は、以下に示した可変要素の影響を把握することにあります。

- **ディスクの種類**。Standard Storage (HDD) を使用した D4 VM の 6 ノード クラスターと、Premium Storage (SSD) を使用した DS4 VM の 6 ノード クラスターでテストを実行しました。

- **マシンのサイズ - スケールアップ**。DS3 VM で構成される 6 ノード クラスター (*小規模*クラスター)、DS4 VM のクラスター (*中規模*クラスター)、DS14 マシンのクラスター (*大規模*クラスター) でテストを実行しました。次の表では、各 VM SKU の主な特性をまとめます。

 クラスター | VM の SKU | コアの数 | データ ディスクの数 | RAM (GB) |
---------|---------------|-----------------|----------------------|----------|
 Small | Standard DS3 | 4 | 8 | 14 |
 Medium | Standard DS4 | 8 | 16 | 28 |
 Large | Standard DS14 | 16 | 32 | 112 |

- **クラスター サイズ - スケールアウト**。1 ノード、3 ノード、6 ノードから成る DS14 VM のクラスターに対してテストを実行しました。

- **インデックス レプリカの数**。1 つのレプリカと 2 つのレプリカを使って構成したインデックスを使用してテストを実施しました。

- **doc 値**。最初にインデックス設定 *doc\_values* を *true* に設定してテストを実行しました (既定値)。次に、*doc\_values* を *false* に設定して選択したテストを繰り返しました。

- **キャッシュ**。インデックスに対するシャード要求キャッシュを有効にしてテストを実施しました。

- **シャード数**。少数の大きいシャードを含んだインデックスと多数の小さいシャードを含んだインデックスとでクエリの実行効率を比較するために、シャード数を変えながらテストを繰り返しました。


## パフォーマンスの結果 - ディスクの種類

ディスク パフォーマンスの評価は、D4 VM (HDD を使用) の 6 ノード クラスターと DS4 VM (SSD を使用) の 6 ノード クラスターに対して*取り込み/クエリ複合*テストを実行することによって行いました。Elasticsearch の構成はどちらのクラスターも同じです。データは各ノードの 16 個のディスクに分散し、各ノードでは Elasticsearch を実行する JVM に 14 GB の RAM が割り当てられていました。残りのメモリ (やはり 14 GB) はオペレーティング システム用に残されていました。各テストを 24 時間実行しました。この時間は、データの量が増えたことによる影響が明らかになり、システムが安定することを想定して選択されました。以下の表は、テストに含まれる各種操作の応答時間に注目して、その結果をまとめたものです。

 クラスター | 操作/クエリ | 平均応答時間 (ミリ秒) |
---------|----------------------------|----------------------------|
 D4 | データの取り込み | 978 |
 | Rating 別数 | 103 |
 | 時間別数 | 134 |
 | 国別ヒット数 | 199 |
 | 上位 15 組織 | 137 |
 | 固有組織数 | 139 |
 | 固有 IP 数 | 510 |
 | 合計ヒット数 | 89
 DS4 | データの取り込み | 511 |
 | Rating 別数 | 187 |
 | 時間別数 | 411 |
 | 国別ヒット数 | 402 |
 | 上位 15 組織 | 307 |
 | 固有組織数 | 320 |
 | 固有 IP 数 | 841 |
 | 合計ヒット数 | 236 |

一見して、D4 クラスターより DS4 クラスターの方がクエリ実行パフォーマンスが低く、応答時間で約 2 倍以上悪いように見えます。これでは全体の様子はわかりません。次の表では、各クラスターで実行された取り込み操作の数を示します (各操作では 1000 個のドキュメントが読み込まれることに注意してください)。

 クラスター | 取り込み操作数 |
---------|-------------------------|
 D4 | 264769 |
 DS4 | 503157 |

DS4 クラスターは、テストの間に D4 クラスターの約 2 倍のデータを読み込むことができました。したがって、各操作の応答時間を分析するときは、各クエリでスキャンする必要があるドキュメントの数、および返されたドキュメントの数も考慮する必要があります。インデックスのドキュメントの量は継続的に増加しているので、これらは動的な数値です。単純に、503137 を 264769 で割り (各クラスターによって実行された取り込み操作の数)、その結果に D4 クラスターで実行された各クエリの平均応答時間を掛けただけでは、比較できる情報は得られません。この方法では、取り込み操作によって同時に実行された I/O の量が無視されています。代わりに、テストの進行に伴って、物理的にディスクに書き込まれたデータ量とディスクから読み取られたデータ量を測定する必要があります。JMeter テスト計画では、各ノードについてこの情報が取得されます。集計された結果は次のとおりです。

 クラスター | 各操作による平均書き込み/読み取りバイト数 |
---------|----------------------------------------------|
 D4 | 13471557 |
 DS4 | 24643470 |

このデータは、DS4 クラスターが D4 クラスターの約 1.8 倍の I/O 速度を維持できたことを示しています。ディスクの特性は考えずに、他のすべてのリソースが同じであるとすると、違いは HDD ではなく SSD を使用したことによるものです。

この結論を正当化するものとして、次のグラフでは各クラスターによる時間を追った I/O 実行の様子を示します。

![](./media/guidance-elasticsearch/query-performance2.png)

<!-- -->

***図 2.D4 クラスターと DS4 クラスターのディスク アクティビティ***

D4 クラスターのグラフでは大きな変動が示されています (特にテストの前半)。これはおそらく、I/O 速度を抑えるためのスロットルによるものです。テストの初期の段階では、分析するデータが少ないので、クエリは速く実行できます。したがって、D4 クラスターのディスクは IOPS 能力に近く動作していますが、各 I/O 操作では多くのデータを返されていない可能性があります。DS4 クラスターはさらに高い IOPS 速度をサポートでき、同じほどのスロットルは受けません。I/O 速度はより一定です。この理論を裏付けるため、次の 2 つのグラフでは、ディスク I/O によって CPU がどのようにブロックされるかを示します (グラフに示されているディスク待機時間は、CPU が I/O の待機に使用した時間の割合です)。

![](./media/guidance-elasticsearch/query-performance3.png)

***図 3.D4 クラスターと DS4 クラスターの CPU ディスク I/O 待機時間***

I/O 操作が CPU をブロックするには 2 つの主要な理由があることを理解することが重要です。

- I/O サブシステムは、ディスクとの間でデータを読み書きしている可能性があります。

- I/O サブシステムは、ホスト環境によってスロットルされる可能性があります。最大スループットは、HDD を使用して実装されている Azure ディスクが 500 IOPS、SSD を使用して実装されている Azure ディスクが 5000 IOPS です。


D4 クラスターの場合、テストの前半で I/O 待機に費やされた時間は、I/O 速度を示すグラフと密接に逆相関しています。低 I/O の期間は、CPU がブロックされている時間が長い期間に対応します。これは I/O がスロットルされていることを示します。クラスターに追加されたデータが多くなると状況は一変し、テストの後半では、I/O 待機時間のピークは I/O スループットのピークと対応しています。この時点では、CPU は実際の I/O の実行中にブロックされています。ここでも、DS4 クラスターでは、I/O 待機時間がはるかに一定であり、各ピークは I/O パフォーマンスの谷ではなく同等のピークと一致しています。これは、スロットルがほとんどまたはまったく発生していないことを意味します。

考慮すべき要因がもう 1 つあります。テスト中に、D4 クラスターでは 10584 件の取り込みエラーと 21 件のクエリ エラーが発生しました。DS4 クラスターのテストではエラーは発生しませんでした。

## パフォーマンスの結果 – スケールアップ

スケールアップ テストは、DS3、DS4、DS14 の各 VM の 6 ノード クラスターに対してテストを実行することによって行いました。DS4 の VM は CPU コア数とメモリ量が共に DS3 の 2 倍、DS14 マシンは CPU リソースが DS4 の 2 倍、メモリ量が DS4 の 4 倍になっていることから、これらの SKU を選択しました。以下の表は、各 SKU の主な特徴を比較したものです。

 SKU | CPU コア数 | メモリ (GB) | 最大ディスク IOPS | 最大帯域幅 (MB/秒)|
------|-------------|-------------|---------------|--------------|
 DS3 | 4 | 14 | 12,800| 128 |
 DS4 | 8 | 28 | 25,600| 256 |
 DS14 | 16 | 112 | 50,000| 512 |

以下の表は、小規模 (DS3)、中規模 (DS4)、大規模 (DS14) のクラスターにおけるテストの実行結果をまとめたものです。各 VM ではデータを保持するためにSSD を使用しました。各テストを 24 時間実行しました。

> **注**: この表は、成功した要求の数をクエリの種類ごとに示しています (失敗は含まれていません)。いずれの種類のクエリも、テスト中に試行される要求の数はほぼ同じです。なぜなら、すべてのクエリ (Rating 別数、時間別数、国別ヒット数、上位 15 組織、固有組織数、固有 IP 数、合計ヒット数) は、JMeter テスト プランによって、*テスト トランザクション*と呼ばれる 1 つの単位でまとめて実行されるためです (このトランザクションは、取り込み操作を実行するタスクとは独立しています。つまり取り込み操作を実行するタスクは別のスレッドで実行されます)。テスト プランが反復されるごとに 1 つのテスト トランザクションが実行されます。したがって、完了したテスト トランザクションの数は、各トランザクションの中で最も時間のかかったクエリの応答時間の尺度となります。

| クラスター | 操作/クエリ | 要求の数 | 平均応答時間 (ミリ秒) |
|--------------|----------------------------|--------------------|----------------------------|
| 小規模 (DS3) | データの取り込み | 207284 | 3328 |
| | Rating 別数 | 18444 | 268 |
| | 時間別数 | 18444 | 340 |
| | 国別ヒット数 | 18445 | 404 |
| | 上位 15 組織 | 18439 | 323 |
| | 固有組織数 | 18437 | 338 |
| | 固有 IP 数 | 18442 | 468 |
| | 合計ヒット数 | 18428 | 294   
|||||
| 中規模 (DS4) | データの取り込み | 503157 | 511 |
| | Rating 別数 | 6958 | 187 |
| | 時間別数 | 6958 | 411 |
| | 国別ヒット数 | 6958 | 402 |
| | 上位 15 組織 | 6958 | 307 |
| | 固有組織数 | 6956 | 320 |
| | 固有 IP 数 | 6955 | 841 |
| | 合計ヒット数 | 6958 | 236 |
|||||
| 大規模 (DS14) | データの取り込み | 502714 | 511 |
| | Rating 別数 | 7041 | 201 |
| | 時間別数 | 7040 | 298 |
| | 国別ヒット数 | 7039 | 363 |
| | 上位 15 組織 | 7038 | 244 |
| | 固有組織数 | 7037 | 283 |
| | 固有 IP 数 | 7037 | 681 |
| | 合計ヒット数 | 7038 | 200 |

これらの数字を見ると、このテストに関して言えば、DS4 クラスターと DS14 クラスターのパフォーマンスはほぼ同じ結果を示しています。DS3 クラスターのクエリ操作の応答時間が一見、比較的優勢に見えます。また、実行されたクエリ操作の数も、DS4 クラスターと DS14 クラスターをはるかに凌いでいます。しかし取り込みの速度と、その結果として検索対象となったドキュメントの数に注目してください。DS3 クラスターは、他のクラスターに比べて取り込みの処理能力が圧倒的に低く、テストの終了時までにデータベースに格納されたドキュメントは、他の 2 つのクラスターで読み取られたドキュメントの 40% にすぎませんでした。これは、DS3 の VM で利用できる処理リソースやネットワーク、ディスク帯域幅が、DS4 または DS14 の VM と違うことに起因していると考えられます。しかし DS4 VM は、利用できるリソースが DS3 VM の 2 倍で、DS14 は、リソースが DS4 VM の 2 倍 (メモリにいたっては 4 倍) ということを踏まえると、1 つ疑問が残ります。DS4 クラスターと DS14 クラスターの取り込み速度の差が、DS3 クラスターと DS4 クラスターの差と比べて著しく小さいのはなぜでしょうか。 これは、Azure VM のネットワーク使用率と帯域幅の制限によるものと考えられます。以下のグラフは、このデータを 3 つのすべてのクラスターについて示したものです。

![](./media/guidance-elasticsearch/query-performance4.png)

***図 4.*取り込み/クエリ複合*テスト実行下での DS3、DS4、DS14 クラスターのネットワーク使用率***

<!-- -->

Azure VM に関して使用できるネットワーク帯域幅の制限は公開されておらず、変化する可能性もありますが、DS4 と DS14 のどちらのテストにおいてもネットワーク アクティビティは平均約 2.75 GBps で横ばいになったようです。その上限に達したことが、スループットが頭打ちになった主な要因と考えられます。DS3 クラスターのネットワーク アクティビティは他のクラスターに比べるとかなり低いことから、相対的なパフォーマンスの低さは、ネットワーク以外のリソース利用に何らかの制約があった可能性が高いといえます。

取り込み操作の影響を排除し、ノードをスケールアップしたときにクエリのパフォーマンスがどのように変化するかを示すために、同じノードを使用して一連のクエリ単体テストを実施しました。以下の表は、各クラスターで得られた結果をまとめたものです。

> [AZURE.NOTE] *クエリ単体*テストのクエリによって実行された要求の数とパフォーマンスを、*取り込み/クエリ複合*テストの結果と比較しないでください。クエリは変更されており、使用されたドキュメントの量も異なります。

| クラスター | 操作/クエリ | 要求の数 | 平均応答時間 (ミリ秒) |
|--------------|----------------------------|--------------------|----------------------------|
| 小規模 (DS3) | Rating 別数 | 464 | 11758 |
| | 時間別数 | 464 | 14699 |
| | 国別ヒット数 | 463 | 14075 |
| | 上位 15 組織 | 464 | 11856 |
| | 固有組織数 | 462 | 12314 |
| | 固有 IP 数 | 461 | 19898 |
| | 合計ヒット数 | 462 | 8882  
|||||
| 中規模 (DS4) | Rating 別数 | 1045 | 4489 |
| | 時間別数 | 1045 | 7292 |
| | 国別ヒット数 | 1053 | 7564 |
| | 上位 15 組織 | 1055 | 5066 |
| | 固有組織数 | 1051 | 5231 |
| | 固有 IP 数 | 1051 | 9228 |
| | 合計ヒット数 | 1051 | 2180 |
|||||
| 大規模 (DS14) | Rating 別数 | 1842 | 1927 |
| | 時間別数 | 1839 | 4483 |
| | 国別ヒット数 | 1838 | 4761 |
| | 上位 15 組織 | 1842 | 2117 |
| | 固有組織数 | 1837 | 2393 |
| | 固有 IP 数 | 1837 | 7159 |
| | 合計ヒット数 | 1837 | 642 |

これで各クラスターにおける平均応答時間の傾向が、先ほどよりもわかりやすくなりました。ネットワーク使用率は、前回 DS4 クラスターと DS14 クラスターで使用された (取り込み/クエリ複合テストでネットワークの処理能力が追い付かない原因となった可能性のある) 2.75 GBps や、DS3 クラスターの 1.5 GBps よりも十分に下回っています。具体的には、以下のグラフに示すすべての場合において 200 MBps 程度となっています。

![](./media/guidance-elasticsearch/query-performance5.png)

***図 5.*クエリ単体*テスト実行下での DS3、DS4、DS14 クラスターのネットワーク使用率***

これで、DS3 クラスターと DS4 クラスターにおける制限要因は CPU 使用率にありそうだ、ということがわかってきました。CPU 使用率はほとんどの時間、100% 近い水準で推移しています。DS14 クラスターでは、平均 CPU 使用率は 80% を少し上回る程度にすぎません。それでも CPU 使用率が高いことに変わりありませんが、利用できる CPU コア数が多いことの利点ははっきりと見て取れます。次の図は、DS3、DS4、DS14 クラスターの CPU 使用パターンを示しています。

![](./media/guidance-elasticsearch/query-performance6.png)

***図 6.*クエリ単体*テスト実行下での DS3 クラスターと DS14 クラスターの CPU 使用率***

## パフォーマンスの結果 – スケールアウト

ノード数によってシステムがスケールアウトするようすを示すために、1、3、6 ノードから成る DS14 クラスターを使ってテストを実施しました。今回実行するのは*クエリ単体*テストのみで、1 億件のドキュメントを使用し、実行時間は 90 分としました。

> [AZURE.NOTE] スケールアウトがデータ取り込み操作の動作に与える影響について詳しくは、「[Maximizing Data Ingestion Performance with Elasticsearch on Azure (Azure での Elasticsearch によるデータ インジェスト パフォーマンスの最大化)](https://github.com/mspnp/azure-guidance/blob/master/Elasticsearch-Data-Ingestion-Performance.md)」を参照してください。

| クラスター | 操作/クエリ | 要求の数 | 平均応答時間 (ミリ秒) |
|---------|----------------------------|--------------------|----------------------------|
| 1 ノード | Rating 別数 | 288 | 6216 |
| | 時間別数 | 288 | 28933 |
| | 国別ヒット数 | 288 | 29455 |
| | 上位 15 組織 | 288 | 9058 |
| | 固有組織数 | 287 | 19916 |
| | 固有 IP 数 | 284 | 54203 |
| | 合計ヒット数 | 287 | 3333 |
|||||
| 3 ノード | Rating 別数 | 1194 | 3427 |
| | 時間別数 | 1194 | 5381 |
| | 国別ヒット数 | 1191 | 6840 |
| | 上位 15 組織 | 1196 | 3819 |
| | 固有組織数 | 1190 | 2938 |
| | 固有 IP 数 | 1189 | 12516 |
| | 合計ヒット数 | 1191 | 1272 |
|||||
| 6 ノード | Rating 別数 | 1842 | 1927 |
| | 時間別数 | 1839 | 4483 |
| | 国別ヒット数 | 1838 | 4761 |
| | 上位 15 組織 | 1842 | 2117 |
| | 固有組織数 | 1837 | 2393 |
| | 固有 IP 数 | 1837 | 7159 |
| | 合計ヒット数 | 1837 | 642 |

クラスターのクエリ パフォーマンスは、ノード数によって非線形的ではあるものの大きな差が生じます。単一ノード クラスターと比べ、3 ノード クラスターは約 4 倍の数のクエリを実行します。6 ノード クラスターになると処理量は 6 倍になります。この非線形性をわかりやすく説明するために、3 つのクラスターで CPU がどのように消費されているかを次のグラフに示します。

![](./media/guidance-elasticsearch/query-performance7.png)

***図 7.*クエリ単体*テスト実行下での 1、3、6 ノード クラスターの CPU 使用率***

単一ノード クラスターと 3 ノード クラスターは、CPU がボトルネックになっています。一方 6 ノード クラスターは、CPU 使用率が高いものの、処理能力にはまだ余力が残っています。このケースでは、スループットを下げている要因が他にありそうです。この点は、9 ノードと 12 ノードでテストすれば確認できます。ノード数が増えることで、処理能力にもっと余裕がでてくると考えられます。

上の表のデータはさらに、クエリの平均応答時間が変化するようすを示しています。これは特定のタイプのクエリを想定してシステムの拡張方法をテストするうえで非常に重要な情報です。検索によっては、ノード数を増やすことで、その効率にはっきりとした差が生まれるからです。その理由としては、クラスター内のノード数とドキュメント数の比が増えていくことにあると考えられます。個々のクラスターに存在するドキュメント数は 1 億件です。Elasticsearch は、データの集計を伴う検索の実行時、集計プロセスの一環として、取得したデータを各ノードのメモリ内で処理してバッファーに格納します。ノード数が増えれば、1 つのノードで行う一連のプロセス (取得、バッファリング、処理) の対象となるデータが減ります。

## パフォーマンスの結果 - レプリカ数

レプリカが 1 つであるインデックスに対して*取り込み/クエリ複合*テストを実行しました。また、2 レプリカ構成のインデックスを使用する 6 ノードの DS4 クラスターと DS14 クラスターに対しても同じテストを実行しました。すべてのテストを 24 時間実行しました。次の表は、レプリカ数が 1 つの場合と 2 つの場合とで比較した結果を示しています。

| クラスター | 操作/クエリ | 平均応答時間 (ミリ秒) - 1 レプリカ | 平均応答時間 (ミリ秒) - 2 レプリカ | 応答時間の差 (%) |
|---------|----------------------------|----------------------------------------|-----------------------------------------|-------------------------------|
| DS4 | データの取り込み | 511 | 655 | +28% |
| | Rating 別数 | 187 | 168 | -10% |
| | 時間別数 | 411 | 309 | -25% |
| | 国別ヒット数 | 402 | 562 | +40% |
| | 上位 15 組織 | 307 | 366 | +19% |
| | 固有組織数 | 320 | 378 | +18% |
| | 固有 IP 数 | 841 | 987 | +17% |
| | 合計ヒット数 | 236 | 236 | +0% |
||||||
| DS14 | データの取り込み | 511 | 618 | +21% |
| | Rating 別数 | 201 | 275 | +37% |
| | 時間別数 | 298 | 466 | +56% |
| | 国別ヒット数 | 363 | 529 | +46% |
| | 上位 15 組織 | 244 | 407 | +67% |
| | 固有組織数 | 283 | 403 | +42% |
| | 固有 IP 数 | 681 | 823 | +21% |
| | 合計ヒット数 | 200 | 221 | +11% |

レプリカ数が増えると取り込み速度は低下しました。ドキュメントごとに書き込むコピー数が増え、生成されるディスク I/O が増えるので、当然そのようになります。この点は、1 レプリカのインデックスを持つ DS14 クラスターと 2 レプリカのインデックスを持つ DS14 クラスターを示した以下のグラフにも表れています。1 レプリカのインデックスの場合、平均 I/O 速度は 16,896,573 バイト/秒でした。2 レプリカのインデックスの場合、平均 I/O 速度は 33,986,843 バイト/秒と、ちょうど 2 倍強となっています。

![](./media/guidance-elasticsearch/query-performance8.png)

***図 8.*取り込み/クエリ複合*テスト実行下での 1 レプリカ ノードと 2 レプリカ ノードのディスク I/O 速度***

| クラスター | クエリ | 平均応答時間 (ミリ秒) - 1 レプリカ | 平均応答時間 (ミリ秒) - 2 レプリカ |
|---------|----------------------------|----------------------------------------|-----------------------------------------|
| DS4 | Rating 別数 | 4489 | 4079 |
| | 時間別数 | 7292 | 6697 |
| | 国別ヒット数 | 7564 | 7173 |
| | 上位 15 組織 | 5066 | 4650 |
| | 固有組織数 | 5231 | 4691 |
| | 固有 IP 数 | 9228 | 8752 |
| | 合計ヒット数 | 2180 | 1909 |
|||||
| DS14 | Rating 別数 | 1927 | 2330 |
| | 時間別数 | 4483 | 4381 |
| | 国別ヒット数 | 4761 | 5341 |
| | 上位 15 組織 | 2117 | 2560 |
| | 固有組織数 | 2393 | 2546 |
| | 固有 IP 数 | 7159 | 7048 |
| | 合計ヒット数 | 642 | 708 |

この結果を見ると、平均応答時間が DS4 クラスターでは短くなっているのに、DS14 クラスターでは長くなっていることがわかります。この矛盾を説明するには、それぞれのテストで実行されたクエリの数にも注目する必要があります。

| クラスター | クエリ | 実行数 - 1 レプリカ | 実行数 - 2 レプリカ |
|---------|----------------------------|------------------------------|-------------------------------|
| DS4 | Rating 別数 | 1054 | 1141 |
| | 時間別数 | 1054 | 1139 |
| | 国別ヒット数 | 1053 | 1138 |
| | 上位 15 組織 | 1055 | 1141 |
| | 固有組織数 | 1051 | 1136 |
| | 固有 IP 数 | 1051 | 1135 |
| | 合計ヒット数 | 1051 | 1136 |
|||||
| DS14 | Rating 別数 | 1842 | 1718 |
| | 時間別数 | 1839 | 1716 |
| | 国別ヒット数 | 1838 | 1714 |
| | 上位 15 組織 | 1842 | 1718 |
| | 固有組織数 | 1837 | 1712 |
| | 固有 IP 数 | 1837 | 1712 |
| | 合計ヒット数 | 1837 | 1712 |

このデータは、DS4 クラスターによって実行されたクエリの数が、平均応答時間の短縮に従って増えていることを示しています。ところがまた、DS14 クラスターについては逆の現象が起こっています。ここで 1 つ重要な要素は、1 レプリカ テストと 2 レプリカ テストにおける DS4 クラスターの CPU 使用率にむらがあるということです。つまり、CPU 使用率が 100% 近いノードと、処理能力に余力のあるノードとが存在します。パフォーマンスが向上したのは、クラスターの複数のノードに対して処理を分散する能力が上昇したからであると考えてまず間違いないでしょう。次の画像は、使用頻度の最も高い VM と最も低い VM (ノード 4 とノード 3) における CPU 処理の推移を示しています。

![](./media/guidance-elasticsearch/query-performance9.png)

***図 9.*クエリ単体*テスト実行下での DS4 クラスターにおける使用頻度の最も低いノードと最も高いノードの CPU 使用率***

DS14 クラスターにはこれが当てはまりません。どちらのテストについても、すべてのノードで CPU 使用率が低くなっています。2 つ目のレプリカを利用できることの利点が薄れ、むしろオーバーヘッドになっているのです。

![](./media/guidance-elasticsearch/query-performance10.png)

***図 10.*クエリ単体*テスト実行下での DS14 クラスターにおける使用頻度の最も低いノードと最も高いノードの CPU 使用率***

以上の結果からわかるように、複数のレプリカを使用するかどうかを決める際には、システムのベンチマークを慎重に行う必要があります。インデックスごとに少なくとも 1 つのレプリカを必ず使用することをお勧めしますが (ノードの障害が発生したときにデータが失われるリスクをあえて取る場合を除く)、実際のワークロードやクラスターで利用できるハードウェア リソースによっては、それ以上レプリカを増やすと、システムに負荷がかかる割にはメリットがほとんどないという可能性があります。

## パフォーマンスの結果 – doc 値

doc 値を有効にし、フィールドの並べ替えに使用されるデータを Elasticsearch がディスクに格納するようにして、*取り込み/クエリ複合*テストを実施しました。doc 値を無効にし、Elasticsearch がフィールドデータを動的に構築してメモリにキャッシュするようにして、テストを繰り返しました。すべてのテストを 24 時間実行しました。以下の表は、D4、DS4、DS14 の VM を使って構築された 6 ノードのクラスターに対して実行されたテストの応答時間を比較したものです (D4 クラスターには標準的なハード ディスクが、DS4 クラスターと DS14 クラスターには SSD が使用されています)。

| クラスター | 操作/クエリ | 平均応答時間 (ms) - doc 値有効 | 平均応答時間 (ms) - doc 値無効 | 応答時間の差 (%) |
|---------|----------------------------|-------------------------------------------------|--------------------------------------------------|-------------------------------|
| D4 | データの取り込み | 978 | 835 | -15% |
| | Rating 別数 | 103 | 132 | +28% |
| | 時間別数 | 134 | 189 | +41% |
| | 国別ヒット数 | 199 | 259 | +30% |
| | 上位 15 組織 | 137 | 184 | +34% |
| | 固有組織数 | 139 | 197 | +42% |
| | 固有 IP 数 | 510 | 604 | +18% |
| | 合計ヒット数 | 89 | 134 | +51% |
||||||
| DS4 | データの取り込み | 511 | 581 | +14% |
| | Rating 別数 | 187 | 190 | +2% |
| | 時間別数 | 411 | 409 | -0.5% |
| | 国別ヒット数 | 402 | 414 | +3% |
| | 上位 15 組織 | 307 | 284 | -7% |
| | 固有組織数 | 320 | 313 | -2% |
| | 固有 IP 数 | 841 | 955 | +14% |
| | 合計ヒット数 | 236 | 281 | +19% |
||||||
| DS14 | データの取り込み | 511 | 571 | +12% |
| | Rating 別数 | 201 | 232 | +15% |
| | 時間別数 | 298 | 341 | +14% |
| | 国別ヒット数 | 363 | 457 | +26% |
| | 上位 15 組織 | 244 | 338 | +39% |
| | 固有組織数 | 283 | 350 | +24% |
| | 固有 IP 数 | 681 | 909 | +33% |
| | 合計ヒット数 | 200 | 245 | +23% |

次の表では、テストごとの取り込み操作の実行回数を比較しています。

| クラスター | 取り込み操作回数 - doc 値有効 | 取り込み操作回数 - doc 値無効 | 取り込み操作回数の差 (%) |
|---------|----------------------------------------------|-----------------------------------------------|-----------------------------------------|
| D4 | 264769 | 408690 | +54% |
| DS4 | 503137 | 578237 | +15% |
| DS14 | 502714 | 586472 | +17% |

doc 値を無効にしたときに取り込み速度が向上しているのは、ドキュメントの挿入時にディスクに書き込まれるデータの量が減少するためです。特に HDD でデータを格納する D4 VM でのパフォーマンスの向上が際立っています。このケースでは、取り込み操作の応答時間も 15% 短縮されました (このセクションの 1 つ目の表を参照)。その要因は、doc 値を有効にした状態でのテストでは IOPS の限界付近で動作していた HDD への負荷が小さくなったことにあると考えられます。詳細については、「ディスクの種類」のテストを参照してください。次のグラフは、doc 値を有効 (値はディスクに保持される) にした D4 VM と doc 値を無効 (値はメモリに保持される) にした D4 VM との間で I/O パフォーマンスを比較しています。

![](./media/guidance-elasticsearch/query-performance11.png)

***図 11.doc 値を有効にした場合と無効にした場合の D4 クラスターのディスク アクティビティの比較***

対照的に、SSD を使用する VM の取り込みの値を見ると、ドキュメント数がわずかに増加するだけでなく、取り込み操作の応答時間も増えていることがわかります。小さな例外が 1 ～ 2 個あるものの、クエリの応答時間も悪化しました。doc 値を有効にした状態で SSD が IOPS の限界付近で動作している可能性は低いので、パフォーマンスの変化はむしろ、処理アクティビティの増加と JVM ヒープの管理オーバーヘッドに起因するものと思われます。このことは、doc 値を有効にしたときと無効にしたときの CPU 使用率を比較すれば一目瞭然です。次のグラフは、DS4 クラスターに関してこのデータに注目したものです。doc 値が有効であるときに 30% ～ 40% の水準にあった CPU 使用率の大部分が、doc 値を無効にしたときには 40%～50% 水準に移動しています (DS14 クラスターも同様の傾向を示しました)。

![](./media/guidance-elasticsearch/query-performance12.png)

***図 12.doc 値を有効にした場合と無効にした場合の DS4 クラスターの CPU 使用率の比較***

doc 値がクエリ パフォーマンスに与える影響をデータの取り込みから切り離して考えるために、doc 値を有効にしたときと無効にしたときの DS4 クラスターと DS14 クラスターに対して 2 つのクエリ単体テストを実行しました。以下の表は、そのテストの結果をまとめたものです。

| クラスター | 操作/クエリ | 平均応答時間 (ms) - doc 値有効 | 平均応答時間 (ms) - doc 値無効 | 応答時間の差 (%) |
|---------|----------------------------|-------------------------------------------------|--------------------------------------------------|-------------------------------|
| DS4 | Rating 別数 | 4489 | 3736 | -16% |
| | 時間別数 | 7293 | 5459 | -25% |
| | 国別ヒット数 | 7564 | 5930 | -22% |
| | 上位 15 組織 | 5066 | 3874 | -14% |
| | 固有組織数 | 5231 | 4483 | -2% |
| | 固有 IP 数 | 9228 | 9474 | +3% |
| | 合計ヒット数 | 2180 | 1218 | -44% |
||||||
| DS14 | Rating 別数 | 1927 | 2144 | +11% |
| | 時間別数 | 4483 | 4337 | -3% |
| | 国別ヒット数 | 4761 | 4840 | +2% |
| | 上位 15 組織 | 2117 | 2302 | +9% |
| | 固有組織数 | 2393 | 2497 | +4% |
| | 固有 IP 数 | 7159 | 7639 | +7% |
| | 合計ヒット数 | 642 | 633 | -1% |

冒頭で述べたように、Elasticsearch 2.0 以降では doc 値が既定で有効になります。DS4 クラスターを対象とするテストでは、doc 値を無効にすることで全体的にプラスの効果が認められます。一方、DS14 クラスターでは、概してその逆の傾向になっています (doc 値を無効にすることでパフォーマンスが向上するケースが 2 つありますが、向上の度合いはほんのわずかです)。

DS4 クラスターでは、どちらのケースの CPU 使用率も、2 つのテストの間 100% に近い状態となっていました。つまり、このクラスターは、CPU がボトルネックになっているということです。ところが、処理されたクエリの数は 7369 から 5894 と約 20% 減少しています (下の表を参照)。doc 値を無効にした場合、Elasticsearch によってフィールドデータがメモリ内で動的に生成されることを思い出してください。これが CPU の処理能力を消費します。この構成では、ディスク I/O の割合は少なくなりますが、既にその能力の限界近くで動作している CPU に、より大きな負荷がかかります。doc 値を無効にしたときの方がクエリの応答時間が短いのに、実行されたクエリの数が少ないのは、そのためです。

DS14 テストでは、doc 値を有効にした場合も無効にした場合も、CPU アクティビティは高いですが 100% ではありません。doc 値を有効にしたテストでは、クエリの実行回数がわずかに増えました (約 4%)。

| クラスター | クエリ | 実行回数 - doc 値有効 | 実行回数 - doc 値無効 |
|---------|----------------------------|---------------------------------------|----------------------------------------|
| DS4 | Rating 別数 | 1054 | 845 |
| | 時間別数 | 1054 | 844 |
| | 国別ヒット数 | 1053 | 842 |
| | 上位 15 組織 | 1055 | 846 |
| | 固有組織数 | 1051 | 839 |
| | 固有 IP 数 | 1051 | 839 |
| | 合計ヒット数 | 1051 | 839  
||||| |
| DS14 | Rating 別数 | 1772 | 1842 |
| | 時間別数 | 1772 | 1839 |
| | 国別ヒット数 | 1770 | 1838 |
| | 上位 15 組織 | 1773 | 1842 |
| | 固有組織数 | 1769 | 1837 |
| | 固有 IP 数 | 1768 | 1837 |
| | 合計ヒット数 | 1769 | 1837 |

## パフォーマンスの結果 - シャード要求キャッシュ

インデックス データを各ノードのメモリにキャッシュすることによって得られるパフォーマンス上の効果を実証するために、インデックス キャッシュを有効にした DS4 と DS14 の 6 ノード クラスターで*クエリ/取り込み複合*テストを実施しました。詳細については、セクション「[シャード要求キャッシュの使用](#using-the-shard-request-cache)」を参照してください。既に同じインデックスを使って (ただしインデックス キャッシュは無効にして) 行ったテストがあるので、その結果と比較しました。以下の表は、その結果をまとめたものです。このデータの対象となった範囲は、テストの開始から 90 分のみであることに注意してください。90 分あれば相対的な傾向がはっきり見えてくるので、テストを続行しても、それ以上の知見はおそらく得られません。

| クラスター | 操作/クエリ | 平均応答時間 (ms) - インデックス キャッシュ無効 | 平均応答時間 (ms) - インデックス キャッシュ有効 | 応答時間の差 (%) |
|---------|----------------------------|---------------------------------------------------|--------------------------------------------------|-------------------------------|
| DS4 | データの取り込み | 504 | 3260 | +547% |
| | Rating 別数 | 218 | 273 | +25% |
| | 時間別数 | 450 | 314 | -30% |
| | 国別ヒット数 | 447 | 397 | -11% |
| | 上位 15 組織 | 342 | 317 | -7% |
| | 固有組織数 | 370 | 324 | -12%% |
| | 固有 IP 数 | 760 | 355 | -53% |
| | 合計ヒット数 | 258 | 291 | +12% |
||||||
| DS14 | データの取り込み | 503 | 3365 | +569% |
| | Rating 別数 | 234 | 262 | +12% |
| | 時間別数 | 357 | 298 | -17% |
| | 国別ヒット数 | 416 | 383 | -8% |
| | 上位 15 組織 | 272 | 324 | -7% |
| | 固有組織数 | 330 | 321 | -3% |
| | 固有 IP 数 | 674 | 352 | -48% |
| | 合計ヒット数 | 227 | 292 | +29% |

このデータには、興味深い点が 2 つあります。

-  インデックス キャッシュを有効にした結果、データの取り込み速度が著しく落ちている。

-  インデックス キャッシュによって、全種類のクエリの応答時間が必ずしも向上していない。Rating 別数クエリや合計ヒット数クエリなど、一部の集計操作には悪影響が生じることもある。
 

なぜこのような動作になるのかを理解するためには、テスト ラン時、それぞれのケースにおいて、正常に実行されたクエリの数を考慮する必要があります。このデータを次の表に示します。

| クラスター | 操作/クエリ | 操作/クエリの数 - インデックス キャッシュ無効 | 操作/クエリの数 - インデックス キャッシュ有効 |
|---------|----------------------------|-------------------------------------------------|------------------------------------------------|
| DS4 | データの取り込み | 38611 | 13232 |
| | Rating 別数 | 524 | 18704 |
| | 時間別数 | 523 | 18703 |
| | 国別ヒット数 | 522 | 18702 |
| | 上位 15 組織 | 521 | 18706 |
| | 固有組織数 | 521 | 18700 |
| | 固有 IP 数 | 521 | 18699 |
| | 合計ヒット数 | 521 | 18701  
|||| |
| DS14 | データの取り込み | 38769 | 12835 |
| | Rating 別数 | 528 | 19239 |
| | 時間別数 | 528 | 19239 |
| | 国別ヒット数 | 528 | 19238 |
| | 上位 15 組織 | 527 | 19240 |
| | 固有組織数 | 524 | 19234 |
| | 固有 IP 数 | 524 | 19234 |
| | 合計ヒット数 | 527 | 19236 |

キャッシュを有効にすると、キャッシュが無効なときと比べて取り込み速度が約 1/3 になりますが、実行されたクエリの数は 34 倍に増えています。クエリに伴うディスク I/O が大幅に減少し、ディスク リソースを奪い合う状況も解消されました。このことは以下の図 13 に表れています。このグラフは、4 つすべてのケースの I/O アクティビティを比較したものです。

![](./media/guidance-elasticsearch/query-performance13.png)

***図 13.インデックス キャッシュを無効にしたときと有効にしたときのディスク I/O アクティビティ (*取り込み/クエリ複合*テスト)***

ディスク I/O の減少は、I/O の完了待ちに費やされる CPU 時間も減少することを意味します。このことは図 14 によく表れています。

![](./media/guidance-elasticsearch/query-performance14.png)

***図 14. インデックス キャッシュを無効にしたときと有効にしたときのディスク I/O の完了待ちに費やされる CPU 時間 (*取り込み/クエリ複合*テスト)***

ディスク I/O が減少したことで、Elasticsearch が、メモリに保持されているデータをクエリへの応答として返す機会 (時間的割合) が大幅に増えたと考えられます。その結果 CPU 使用率が増加しています。これは、4 つすべてのケースの CPU 使用率を見れば明らかです。以下のグラフは、キャッシュを有効にしたときの方が、CPU の使用時間が長いことを示しています。

![](./media/guidance-elasticsearch/query-performance15.png)

***図 15.インデックス キャッシュを無効にしたときと有効にしたときの*取り込み/クエリ複合*テストの CPU 使用率***

どちらのシナリオもテスト期間におけるネットワーク I/O の量に大きな違いはありませんでした。キャッシュを無効にした場合は、テスト期間中に緩やかな劣化が見られましたが、もっと長時間 (24 時間) のテスト ランでは、この指標が約 2.75 GBps で横ばいとなりました。以下の画像は、DS4 クラスターにおけるこのデータを示しています (DS14 クラスターのデータもほぼ同じです)。

![](./media/guidance-elasticsearch/query-performance16.png)

***図 16.インデックス キャッシュを無効にしたときと有効にしたときのネットワーク トラフィック量 (*取り込み/クエリ複合*テスト)***

[スケールアップ](#performance-results-scaling-up) テストで説明したように、Azure VM のネットワーク帯域幅の制限は公開されておらず、変化する可能性もありますが、CPU とディスクのアクティビティ レベルが極端に大きいわけではないことから、このシナリオでの制限要因はネットワーク使用率であることがうかがえます。

当然ながらキャッシュは、データの変更頻度が低いシナリオの方が適しています。このシナリオにおけるキャッシュの効果に注目するために、キャッシュを有効にして*クエリ単体*テストを実施しました。以下の表はその結果を示しています (これらのテストは 90 分間にわたって実行され、テスト対象インデックスには 1 億件分のドキュメントが格納されています)。

| クラスター | クエリ | 平均応答時間 (ミリ秒) | 実行されたクエリ数 |
|---------|----------------------------|----------------------------|-------------------------|
| | | **キャッシュ無効** | **キャッシュ有効** |
| DS4 | Rating 別数 | 4489 | 210 |
| | 時間別数 | 7292 | 211 |
| | 国別ヒット数 | 7564 | 231 |
| | 上位 15 組織 | 5066 | 211 |
| | 固有組織数 | 5231 | 211 |
| | 固有 IP 数 | 9228 | 218 |
| | 合計ヒット数 | 2180 | 210  
|||| |
| DS14 | Rating 別数 | 1927 | 211 |
| | 時間別数 | 4483 | 219 |
| | 国別ヒット数 | 4761 | 236 |
| | 上位 15 組織 | 2117 | 212 |
| | 固有組織数 | 2393 | 212 |
| | 固有 IP 数 | 7159 | 220 |
| | 合計ヒット数 | 642 | 211 |

キャッシュを無効にしたテストのパフォーマンスの差は、VM で利用できるリソースが DS4 と DS14 とで違うことが原因です。キャッシュを有効にしたテストでは、どちらのケースもデータがメモリから直接取得されるようになって平均応答時間が大幅に短縮されました。DS4 クラスターと DS14 クラスターの応答時間は、キャッシュが無効であるときには大きな差があったにもかかわらず、キャッシュを有効にした場合は結果が酷似していました。また、それぞれのテストに含まれる各クエリの応答時間にも、差はほとんどありません。いずれも約 220 ms となっています。2 つのクラスターのディスク I/O 速度と CPU 使用率はごく低い値となりました。いったんすべてのデータがメモリに格納されると、I/O も処理もほとんど発生しないためです。そのときのネットワーク I/O 速度は、キャッシュを無効にしてテストしたときとほぼ同程度であり、このテストの制限要因がネットワーク帯域幅であることを裏付けています。この情報を DS4 クラスターに関して示したグラフは次のとおりです。DS14 クラスターの分析結果もほぼ同じです。

![](./media/guidance-elasticsearch/query-performance17.png)

***図 17.インデックス キャッシュを有効にしたときのディスク I/O、CPU 使用率、ネットワーク使用率 (*クエリ単体*テスト)***

前出の表に掲載されている数字は、DS4 アーキテクチャと比べて DS14 を使用することの優位性はほとんどないことを示しています。実際、DS14 クラスターによって生成されたサンプルの数は、DS4 クラスターで生成した場合よりも 5% 下回っていました。しかしこれも、ネットワークの制限に起因している可能性があります。またネットワークの制限は、時間の経過と共に変化することが考えられます。

## パフォーマンスの結果 - シャード数

このテストの目的は、インデックス用に作成されたシャードの数が、そのインデックスのクエリのパフォーマンスに影響するかどうかを確かめることです。

インデックスのシャード構成が、データの取り込み速度に影響を与える場合があることは、以前実施した別のテストで証明済みです。これらのテストは、「[Maximizing Data Ingestion Performance with Elasticsearch on Azure (Azure での Elasticsearch によるデータ インジェスト パフォーマンスの最大化)](https://github.com/mspnp/azure-guidance/blob/master/Elasticsearch-Data-Ingestion-Performance.md)」で説明されています。クエリのパフォーマンスを解明するためのテストも同様の手法に基づいて実施しました。ただし、テストの対象は、DS14 ハードウェア上で動作する 6 ノード クラスターに限定しました。このアプローチによって変動要因を極力排除し、パフォーマンスの差の原因がシャードのボリュームにあると考えることができます。

異なるプライマリ シャード数 (7、13、23、37、61) で構成された同じインデックスのコピーに対して*クエリ単体*テストを実施しました。インデックスは 1 億件分のドキュメントを含んでおり、レプリカが 1 つ存在するので、クラスター全体でシャード数は 2 倍になります。各テストの実行時間は 90 分です。その結果を以下の表にまとめています。記載してある平均応答時間は、テスト 1 回につき実行される一連のクエリをすべて含んだ JMeter テスト トランザクションの応答時間です。詳細については、「[パフォーマンスの結果 - スケールアップ](#performance-results-scaling-up)」セクションの注を参照してください。

| シャード数 | シャードのレイアウト (レプリカを含む 1 ノードあたりのシャード数) | 実行されたクエリ数 | 平均応答時間 (ミリ秒) |
|---------------------------|----------------------------------------------------|-----------------------------|------------------------|
| 7 (レプリカを含めると 14) | 3-2-2-2-2-3 | 7461 | 40524 |
| 13 (26) | 5-4-5-4-4-4 | 7369 | 41055 |
| 23 (46) | 7-8-8-7-8-8 | 14193 | 21283 |
| 37 (74) | 13-12-12-13-12-12 | 13399 | 22506 |
| 61 (122) | 20-21-20-20-21-20 | 14743 | 20445 |

この結果を見ると、13 (26) シャード クラスターと 23 (46) シャード クラスターには、パフォーマンスに大きな違いがあることがわかります。スループットは約 2 倍に、応答時間は半分になっています。その要因は、Elasticsearch が検索要求を処理する際に使用する構造と VM の構成にあると考えられます。検索要求はキューに格納され、個々の検索要求は単一の検索スレッドによって処理されます。Elasticsearch ノードによって作成される検索スレッドの数は、ノードのホストとなるマシンで使用できるプロセッサ数に関係しています。この結果から、1 ノードあたりのシャード数が 4 ～ 5 個では、処理リソースが十分に活用されないことがうかがえます。そのことは、テストの実行中に CPU 使用率を観察すると確認できます。次の画像は、13 (26) シャード テストの実行中に Marvel から撮影したスナップショットです。

![](./media/guidance-elasticsearch/query-performance18.png)

***図 18.7 (14) シャード クラスターにおける*クエリ単体*テストの CPU 使用率***

これらの数字を 23 (46) シャード テストの数字と比較しましょう。

![](./media/guidance-elasticsearch/query-performance19.png)

***図 19.23 (46) シャード クラスターにおける*クエリ単体*テストの CPU 使用率***

CPU 使用率は、23 (46) シャード テストの方がはるかに上回っています。それぞれのノードには 7 個または 8 個のシャードが存在します。DS14 アーキテクチャには 16 のプロセッサが備わっており、シャード数が多い方が、そのコア数を Elasticsearch で有効活用することができます。上の表の数字を見ると、シャード数がこのポイントを超えた場合、パフォーマンスにわずかな向上が見られることもありますが、多数のシャードを管理するオーバーヘッドが大きくなって、その利点が弱まってしまうことがわかります。以上のテストから、1 ノードあたりの最適なシャード数は、各ノードで利用できるプロセッサ コア数の半分であると推測できます。ただしこれは、クエリのみを実行したときに得られた結果であることに注意してください。システムにデータをインポートする場合は、データ取り込み操作のパフォーマンスにシャーディングが及ぼす影響も考慮する必要があります。この点について詳しくは、「[Maximizing Data Ingestion Performance with Elasticsearch on Azure (Azure での Elasticsearch によるデータ インジェスト パフォーマンスの最大化)](https://github.com/mspnp/azure-guidance/blob/master/Elasticsearch-Data-Ingestion-Performance.md)」を参照してください。

## 概要

Elasticsearch には、インデックスを構築して大規模なクエリ操作に耐えるようそれらをチューニングするための選択肢が豊富にあります。このドキュメントでは、クエリを使用目的としてデータベースをチューニングする一般的な構成と手法を簡単に説明しました。しかし高速検索にデータベースを最適化することと、大量のデータの取り込みをサポートすることとの間にはトレードオフがあることも認識しておく必要があります。クエリにとっては良いことが、挿入操作にとっては逆効果であったり、その反対のケースもあります。さまざまなワークロードが混在するシステムでは、ちょうどよいバランスを見極め、それに応じてシステムのパラメーターを調整する必要があります。

加えて、データの構造や、システムが構築されているハードウェアの制限などによっても、各種の構成と手法の妥当性が変わってきます。このドキュメントで紹介したテストの多くでは、ハードウェア プラットフォームの選択がスループットに与える影響をわかりやすく示すと共に、同じ戦略でも状況によって効果を発揮したり逆効果になったりすることもあるという話をしました。大切なことは、利用できる選択肢をよく知り、独自のデータを使って徹底したベンチマークを実行して最適な組み合わせを突き止めることです。

Elasticsearch データベースはいつまでも同じ形を保っているとは限りません。時間の経過に伴って拡大していく可能性が高いので、データを構造化するための戦略も定期的に見直す必要があります。たとえばスケールアップやスケールアウト、データの再インデクシングとシャードの増加が必要になることもあります。システムの規模が大きく複雑になっていく過程で絶えずパフォーマンスをテストし、顧客に保証している SLA があれば、それらが満たされていることを確認してください。

## 付録: クエリと集計のパフォーマンス テスト

この付録では、Elasticsearch クラスターに対して実行されたパフォーマンス テストについて説明します。このテストは、独立した一連の VM で実行する JMeter を使用して実行されました。テスト環境の構成の詳細については、ドキュメント「How-To: Create a Performance Testing Environment for Elasticsearch (方法: Elasticsearch 用のパフォーマンス テスト環境の作成)」を参照してください。独自のテストを実行するには、この付録のガイダンスに従って JMeter テスト計画を手動で作成するか、または別に使用可能な自動テスト スクリプトを使用できます。詳細については、「How-To: Run the Automated Elasticsearch Query Tests (方法: 自動 Elasticsearch クエリ テストの実行)」を参照してください。

データ クエリのワークロードでは、以下に記載した一連のクエリを実行し、同時に大量ドキュメントのアップロードを実行しました (データのアップロードは、「[Maximizing Data Ingestion Performance with Elasticsearch on Azure (Azure での Elasticsearch によるデータ インジェスト パフォーマンスの最大化)](https://github.com/mspnp/azure-guidance/blob/master/Elasticsearch-Data-Ingestion-Performance.md)」に記載されているデータ取り込みテストと同じ手法に従い、JUnit テストを使って実行しました)。 このワークロードの目的は、検索が実行されている間も新しいデータが絶えず追加される運用環境をシミュレートすることです。クエリは、直近 15 分以内に追加されたドキュメントから最新のデータのみを取得するように作成しました。

各ドキュメントは、*idx* という名前の 1 つのインデックスに格納し、それぞれに *doc* タイプを割り当てました。次の HTTP 要求を使用してインデックスを作成できます。*number\_of\_replicas* と *number\_of\_shards* の設定は、多くのテストで次に示す値とは異なりました。また、doc 値ではなくフィールドデータを使用したテストでは、各プロパティに *"doc\_values" : false* 属性による注釈付けを行いました。

> **重要**。各テストを実行する前に、インデックスを削除して再作成しました。

``` http
PUT /idx
{  
    "settings" : {
        "number_of_replicas": 1,
        "refresh_interval": "30s",
        "number_of_shards": "5",
        "index.translog.durability": "async"    
    },
    "doc": {
        "mappings": {
            "event": {
                "_all": {
                    "enabled": false
                },
                "_timestamp": {
                    "enabled": true,
                    "store": true,
                    "format": "date_time"
                },
                "properties": {
                    "Organization": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField1": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField2": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField3": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField4": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "CustomField5": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "DateTimeReceivedUtc": {
                        "type": "date",
                        "format": "dateOptionalTime"
                    },
                    "Host": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpMethod": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpReferrer": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpRequest": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpUserAgent": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "HttpVersion": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "OrganizationName": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIp": {
                        "type": "ip"
                    },
                    "SourceIpAreaCode": {
                        "type": "long"
                    },
                    "SourceIpAsnNr": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpBase10": {
                        "type": "long"
                    },
                    "SourceIpCity": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpCountryCode": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpLatitude": {
                        "type": "double"
                    },
                    "SourceIpLongitude": {
                        "type": "double"
                    },
                    "SourceIpMetroCode": {
                        "type": "long"
                    },
                    "SourceIpPostalCode": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceIpRegion": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourceLatLong": {
                        "type": "geo_point",
                        "doc_values": true,
                        "lat_lon": true,
                        "geohash": true
                    },
                    "SourcePort": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "SourcedFrom": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "TargetIp": {
                        "type": "ip"
                    },
                    "TargetPort": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "Rating": {
                        "type": "string",
                        "index": "not_analyzed"
                    },
                    "UseHumanReadableDateTimes": {
                        "type": "boolean"
                    }
                }
            }
        }
    }
}
```

テストでは以下のクエリが実行されました:
* 過去 15 分間に追加されたドキュメントの Rating ごとの数

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "bool": {
        "must": [
          {
            "range": {
              "DateTimeReceivedUtc": {
                "gte": "now-15m",
                "lte": "now"
              }
            }
          }
        ],
        "must_not": [],
        "should": []
      }
    },
    "from": 0,
    "size": 0,
    "aggs": {
      "2": {
        "terms": {
          "field": "Rating",
          "size": 5,
          "order": {
            "_count": "desc"
          }
        }
      }
    }
  }
  ```

* 過去 15 分間に追加されたドキュメントの 5 分ごとの数

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "bool": {
        "must": [
          {
            "range": {
              "DateTimeReceivedUtc": {
                "gte": "now-15m",
                "lte": "now"
              }
            }
          }
        ],
        "must_not": [],
        "should": []
      }
    },
    "from": 0,
    "size": 0,
    "sort": [],
    "aggs": {
      "2": {
        "date_histogram": {
          "field": "DateTimeReceivedUtc",
          "interval": "5m",
          "time_zone": "America/Los_Angeles",
          "min_doc_count": 1,
          "extended_bounds": {
            "min": "now-15m",
            "max": "now"
          }
        }
      }
    }
  }
  ```

* 過去 15 分間に追加されたドキュメントの、国別かつ Rating 値別の数

  ```HTTP
  GET /idx/doc/_search
  {
    "query": {
      "filtered": {
        "query": {
          "query_string": {
            "query": "*",
            "analyze_wildcard": true
          }
        },
        "filter": {
          "bool": {
            "must": [
              {
                "query": {
                  "query_string": {
                    "query": "*",
                    "analyze_wildcard": true
                  }
                }
              },
              {
                "range": {
                  "DateTimeReceivedUtc": {
                    "gte": "now-15m",
                    "lte": "now"
                  }
                }
              }
            ],
            "must_not": []
          }
        }
      }
    },
    "size": 0,
    "aggs": {
      "2": {
        "terms": {
          "field": "Rating",
          "size": 5,
          "order": {
            "_count": "desc"
          }
        },
        "aggs": {
          "3": {
            "terms": {
              "field": "SourceIpCountryCode",
              "size": 15,
              "order": {
                "_count": "desc"
              }
            }
          }
        }
      }
    }
  }
  ```

* 過去 15 分間に追加されたドキュメントで、最も頻度が多かった上位 15 の組織

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "filtered": {
        "query": {
          "query_string": {
            "query": "*",
            "analyze_wildcard": true
          }
        },
        "filter": {
          "bool": {
            "must": [
              {
                "query": {
                  "query_string": {
                    "query": "*",
                    "analyze_wildcard": true
                  }
                }
              },
              {
                "range": {
                  "DateTimeReceivedUtc": {
                    "gte": "now-15m",
                    "lte": "now"
                  }
                }
              }
            ],
            "must_not": []
          }
        }
      }
    },
    "size": 0,
    "aggs": {
      "2": {
        "terms": {
          "field": "Organization",
          "size": 15,
          "order": {
            "_count": "desc"
          }
        }
      }
    }
  }
  ```

* 過去 15 分間に追加されたドキュメントでの異なる組織の数

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "filtered": {
        "query": {
          "query_string": {
            "query": "*",
            "analyze_wildcard": true
          }
        },
        "filter": {
          "bool": {
            "must": [
              {
                "query": {
                  "query_string": {
                    "query": "*",
                    "analyze_wildcard": true
                  }
                }
              },
              {
                "range": {
                  "DateTimeReceivedUtc": {
                    "gte": "now-15m",
                    "lte": "now"
                  }
                }
              }
            ],
            "must_not": []
          }
        }
      }
    },
    "size": 0,
    "aggs": {
      "2": {
        "cardinality": {
          "field": "Organization"
        }
      }
    }
  }
  ```

* 過去 15 分間に追加されたドキュメントの数

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "filtered": {
        "query": {
          "query_string": {
            "query": "*",
            "analyze_wildcard": true
          }
        },
        "filter": {
          "bool": {
            "must": [
              {
                "query": {
                  "query_string": {
                    "analyze_wildcard": true,
                    "query": "*"
                  }
                }
              },
              {
                "range": {
                  "DateTimeReceivedUtc": {
                    "gte": "now-15m",
                    "lte": "now"
                  }
                }
              }
            ],
            "must_not": []
          }
        }
      }
    },
    "size": 0,
    "aggs": {}
  }
  ```

* 過去 15 分間に追加されたドキュメントでの異なる SourceIp 値の数

  ```http
  GET /idx/doc/_search
  {
    "query": {
      "filtered": {
        "query": {
          "query_string": {
            "query": "*",
            "analyze_wildcard": true
          }
        },
        "filter": {
          "bool": {
            "must": [
              {
                "query": {
                  "query_string": {
                    "query": "*",
                    "analyze_wildcard": true
                  }
                }
              },
              {
                "range": {
                  "DateTimeReceivedUtc": {
                    "gte": "now-15m",
                    "lte": "now"
                  }
                }
              }
            ],
            "must_not": []
          }
        }
      }
    },
    "size": 0,
    "aggs": {
      "2": {
        "cardinality": {
          "field": "SourceIp"
        }
      }
    }
  }
  ```

<!---HONumber=AcomDC_0302_2016-->