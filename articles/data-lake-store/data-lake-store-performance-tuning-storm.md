---
title: "Azure Data Lake Store の Storm パフォーマンス チューニング ガイドライン | Microsoft Docs"
description: "Azure Data Lake Store の Storm パフォーマンス チューニング ガイドライン"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: stewu
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 12/19/2016
ms.author: stewu
translationtype: Human Translation
ms.sourcegitcommit: ebf876f946eceddce9c8c990d8b28fcb969bec23
ms.openlocfilehash: 112226028c053cc91f9fb2bc0e5978f7cb2343ed


---
# <a name="performance-tuning-guidance-for-storm-on-hdinsight-and-azure-data-lake-store"></a>HDInsight での Storm と Azure Data Lake Store のパフォーマンス チューニング ガイダンス

Storm トポロジのパフォーマンスをチューニングする際は、いくつかの要因を考慮する必要があります。  スパウトとボルトによる処理 (I/O とメモリのどちらを大量に消費する場合でも) の特性を理解しておくことが重要です。

## <a name="prerequisites"></a>前提条件 

* **Azure サブスクリプション**。 [Azure 無料試用版の取得](https://azure.microsoft.com/pricing/free-trial/)に関するページを参照してください。 
* **Azure Data Lake Store アカウント**。 このアカウントを作成する手順については、「 [Azure Data Lake Store の使用を開始する](data-lake-store-get-started-portal.md) 
* Data Lake Store アカウントにアクセスできる **Azure HDInsight クラスター**。 [Data Lake Store を使用する HDInsight クラスターの作成](data-lake-store-hdinsight-hadoop-use-portal.md)に関するページを参照してください。 クラスターのリモート デスクトップが有効になっていることを確認します。 
* **Azure Data Lake Store で Storm クラスターを実行している**。  詳細については、[HDInsight での Storm](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-storm-overview) に関する記事を参照してください。 
* **ADLS のパフォーマンス チューニング ガイドライン**。  一般的なパフォーマンスの概念については、[Data Lake Store のパフォーマンス チューニング ガイダンス](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-performance-tuning-guidance)に関する記事を参照してください。  

**トポロジの並列処理のチューニング**

Azure Data Lake Store との間で I/O の同時実行性を高めることで、パフォーマンスが向上することがあります。  
Storm トポロジでは、並列処理を決定する一連の設定が用意されています。
* ワーカー プロセスの数: ワーカーは VM 間で均等に分散されます。
* スパウトの Executor インスタンスの数
* ボルトの Executor インスタンスの数
* スパウト タスクの数
* ボルト タスクの数

たとえば、クラスターに 4 つの VM と 4 つのワーカー プロセス、32 個のスパウトの Executor と 32 個のスパウト タスク、256 個のボルトの Executor と 512 個のボルト タスクがあるとします。

ワーカー ノードである各スーパーバイザーでは、4 つのスパウト スレッドと 64 個のボルト スレッドを管理する、単一のワーカー JVM プロセスが使用されます。 各スレッド内では、タスクが順番に実行されます。 上記の構成では、スパウトの各スレッドが 1 つのタスクを持ち、ボルトの各スレッドが 2 つのタスクを持ちます。

Storm に関連するさまざまなコンポーネントと、それらが並列処理のレベルに与える影響は次のとおりです。
* ヘッド ノード (Storm では Nimbus と呼ばれます) は、ジョブの送信と管理に使用されます。 これらのノードは、並列処理の次数に影響を与えません。
* スーパーバイザー ノード – これは、Azure HDInsight ではワーカー ノードの Azure VM に対応します。
* ワーカー タスクは、VM で実行される Storm のプロセスです。 各ワーカー タスクは、Java JVM インスタンスに対応します。 Storm は、指定したワーカー プロセスの数ができる限り均等になるようにワーカー ノードに分散させます。
* スパウトとボルトの Executor インスタンス: 各 Executor インスタンスは、ワーカー (JVM) 内で実行されるスレッドに対応します。
* Storm のタスク: 各スレッドで実行される論理タスクです。 これによって並列処理のレベルが変わることはないので、Executor ごとに複数のタスクが必要かどうかを評価する必要があります。

## <a name="guidance"></a>ガイダンス

Azure Data Lake を使用する場合、次の方法でパフォーマンスを最大限高めることができます。
* 小さなサイズの追加データを大きなサイズのデータに結合する (4 MB が理想的)。
* 同時要求をできる限り多く実行する。 各ボルト スレッドはブロッキング読み取りを行うので、NIC と CPU の使用率を適切に保つためには、コアごとに 8 ～ 12 個のスレッドが必要です。  大規模な VM だと、より多くの同時要求を実行できます。  

## <a name="example"></a>例

D13v2 Azure VM を持つ 8 つのワーカー ノードから成るクラスターがあるとします。  D13v2 VM は 8 コアなので、8 つのワーカー ノードすべてで合計 64 個のコアがあります。

たとえば、コアあたり 8 つのボルト スレッドを実行したとします。 64 個のコアがあるので、合計 512 個のボルトの Executor インスタンス (つまりスレッド) が必要になります。 この場合、たとえば、VM ごとに&1; つの JVM を起動し、主に JVM 内でスレッドの同時実行を使用することで、同時実行を実現します。 つまり、8 つのワーカー タスク (Azure VM ごとに 1 つずつ) と 512 個のボルトの Executor が必要です。 この構成下では、Storm は各ワーカー ノードに&1; つの JVM を提供しながら、ワーカーをワーカー ノード (別名スーパーバイザー ノード) 間で均等に分散させようとします。 スーパーバイザー内では、Storm は各スーパーバイザー (つまり JVM) にスレッドを 8 つずつ提供しながら、Executor をスーパーバイザー間で均等に分散させようとします。

## <a name="further-tuning"></a>さらなるチューニング
基本的なトポロジを作成したら、任意のパラメーターをチューニングするかどうかを検討できます。
* **ワーカー ノードごとの JVM の数:** 大規模なデータ構造 (ルックアップ テーブルなど) をメモリ内でホストしている場合、JVM ごとに個別のコピーが必要になります。それに対し、JVM の数が少ないと、同じ構造を多くのスレッド間で使用できます。 JVM の数を変更しても、ボルトの I/O には、これらの JVM 間で追加されたスレッドの数ほどの大きな変化は発生しません。 わかりやすくするために、JVM はワーカーごとに&1; つにしておくことをお勧めしますが、ボルトの処理内容や必要なアプリケーション処理によっては、この数をチューニングする必要があるかどうかを評価する必要があります。
* **スパウトの Executor の数:** ここでの例では、ボルトを Azure Data Lake への書き込みのために使用しているので、スパウトの数はボルトのパフォーマンスとは直接の関連性を持ちません。 ただし、スパウトで発生する処理または I/O の量によっては、最良のパフォーマンスを得るためにスパウトをチューニングすることがあります。 最低でも、ボルトをビジー状態に保つ (つまり、スパウトの出力レートをボルトのスループットと一致させる) ために十分なスパウトを確保する必要があります。 実際の構成はスパウトに依存するため、このホワイト ペーパーの範囲外となります。
* **タスクの数:** 各ボルトは&1; つのスレッドとして実行されます。 ボルトごとにタスクを追加しても、同時実行数が増えることはありません。 タスクを追加する利点があるのは、タプルの受信確認処理に要する時間がボルトの実行時間の大部分を占める場合のみです。 ボルトから受信確認を送信する前に、数が多いタプルは大きな追加データとしてグループ化することをお勧めしているので、ほとんどの場合、タスクを増やす利点はありません。
* **ローカルまたはシャッフル グループ化:** この設定を有効にすると、タプルは同じワーカー プロセス内のボルトに送信されます。 これにより、プロセス間での通信とネットワーク呼び出しが減少します。 ほとんどのトポロジにおいてこれをお勧めします。

開始のためのアプローチとしては、基本的なシナリオから開始して、独自のデータで上記のパラメーターの調整をテストし、パフォーマンスを最適化することをお勧めします。

## <a name="tuning-the-spout"></a>スパウトのチューニング

**タプルのタイムアウト**

topology.message.timeout.secs – この設定は、メッセージの完了と受信確認の受信にどれだけの時間がかかったら失敗と見なすかを決定します。

**ワーカー プロセスごとの最大メモリ**

Worker.childopts - この設定では、Java ワーカーに追加のコマンド ライン パラメーターを指定できます。 ここで最もよく使用される設定は、JVM ヒープに割り当てられた最大メモリを決定する XmX です。

**スパウトでの保留の最大数**

Topology.max.spout.pending - この構成は、任意の時点でフライト状態 (トポロジのどのノードでも受信確認されていない状態) でいられる、スパウト スレッドあたりのタプルの数を決定します。

適切な計算を行うには、まず各タプルのサイズを予測します。 次に、1 つのスパウト スレッドにどれだけのメモリがあるかを確認します。 1 つのスレッドに割り当てられたメモリの合計をこの値で割ると、スパウトでの保留パラメーターの最大値が得られます。

## <a name="tuning-the-bolt"></a>ボルトのチューニング
ADLS に書き込む場合は、サイズ同期ポリシー (クライアント側のバッファー) を 4 MB に設定することをお勧めします。  これにより、フラッシュまたは hsync() は、バッファーのサイズが上記の値である場合にのみ実行されるようになります。  ワーカー VM 上の ADLS ドライバーは、ユーザーが hsync() を明示的に実行しない限り、このバッファー処理を自動的に行います。

既定の ADLS Storm ボルトには、このパラメーターをチューニングするために使用できるサイズ同期ポリシー パラメーター (fileBufferSize) が用意されています。

I/O 集中型のトポロジでは、各ボルト スレッドによって独自のファイルへの書き込みとファイルのローテーション ポリシー (fileRotationSize) の設定が行われるようにすることをお勧めします。  ファイルが特定のサイズに達すると、ストリームは自動的にフラッシュされ、新しいファイルに書き込まれます。  ローテーションにあたってのファイルの推奨サイズは 1 GB です。

**受信確認のタイミング:** Storm では、タプルがボルトによって明示的に受信確認されるまで、スパウトがそのタプルを保持し続けます。  タプルがボルトによって読み取られているものの、まだ受信確認されていない場合は、ボルトが Azure Data Lake Store のバックエンドへの保持の処理を行ったことがまだ保証されていないということになります。  タプルが受信確認されると、ボルトによる保持がスパウトに保証されるので、スパウトは読み取り元にかかわらずソース データを削除できます。  

**ADLS のパフォーマンスを最大限高めるためのヒント:** ボルトでのタプル データのバッファーを 4 MB にし、1 つの 4 MB の書き込みとして ADLS バックエンドに書き込みを行うことをお勧めします。 データが (hflush() の呼び出しによって) ストアに正常に書き込まれると、ボルトはスパウトにデータの受信確認を送信できます。 これが、ここで解説されているサンプルのボルトが行っている処理です。 hflush() の呼び出しとタプルの受信確認までに保持するタプルの数を増やすこともできます。 ただし、この場合、スパウトで保持する必要があるフライト中のタプルの数が増えるので、JVM ごとに必要なメモリの量は増加します。

アプリケーションによっては、パフォーマンス以外の他の理由から、受信確認をより頻繁に行わなければならない場合があります (データのサイズが 4 MB 未満)。 ただし、ストレージ バックエンドへの I/O のスループットに影響する可能性があるため、顧客はボルトの I/O のパフォーマンスとのトレードオフについて慎重に評価する必要があります。

タプルの着信レートが十分に高くなく、4 MB のバッファー入力に長い時間がかかる場合は、いくつかの方法で改善を試みることができます。
* ボルトの数を減らし、4 MB のバッファーの数を減らす。
* 時間ベースまたはカウント ベースのポリシーを設定する。このポリシーでは x 回目のフラッシュごとまたは y ミリ秒ごとに hflush() がトリガーされ、これまで蓄積されたタプルについては受信確認が送信されます。

この場合のスループットは比較的低いものの、イベント レートの低下とスループットの最大化は最大の目的ではないことに注意してください。  イベント レートが低下するとしてもリアルタイム パイプラインを希望する場合は、上記の対応策により、タプルがストアに流れるまでのエンド ツー エンドの時間を短縮することができます。  また、着信タプル レートが低い場合にも、タプルがバッファー処理または処理されている間にタイムアウトしないように topology.message.timeout_secs パラメーターを調整することがあるのでご注意ください。

## <a name="interpreting-storm-ui"></a>Storm UI の解釈  
実行中のトポロジは、Storm UI で監視することができます。 UI で確認する必要がある主なパラメーターは以下のとおりです。

* **プロセスの実行における待ち時間の合計** –&1; つのタプルがスパウトによって出力され、ボルトによって処理されて、受信確認されるまでの平均時間です。

* **ボルト プロセスの待ち時間の合計** – ボルトに到着したタプルが受信確認を受信するまでの平均時間です。

* **ボルトの execute の待ち時間の合計** – ボルトの execute メソッドにかかった平均時間です。

* **エラーの数** – タイムアウトするまでに完全に処理できなかったタプルの数を示します。

* **容量** – システムがどれだけビジーな状態であるかを測る目安です。 この数が 1 である場合、ボルトは最高速度で動作しています。 1 未満である場合は、並列処理を増やします。 1 を超えている場合は、並列処理を減らします。

## <a name="common-troubleshooting-scenarios"></a>一般的なトラブルシューティングのシナリオ
* **タイムアウトするタプルの数が多い** – トポロジの各ノードを確認して、ボトルネックの場所を特定します。 最も一般的な原因は、ボルトがスパウトに追いつくことができずに、処理を待機しているタプルが内部バッファーで輻輳してしまうことです。 タイムアウト値を増やすことを検討するか、スパウトでの保留の最大数を減らしてください。

* **プロセスの実行における待ち時間の合計が長いが、ボルトでのプロセスの待ち時間は短い** – この場合、いずれかのタプルが十分な速さで処理されていません。 十分な数の acker があることを確認してください。 考えられる別の原因としては、ボルトが処理を開始するまでにキューで待機する時間が長すぎることが挙げられます。 スパウトでの保留の最大数を減らしてください。

* **ボルトの execute の待ち時間が長い** – これは、ボルトの execute() メソッドに時間がかかりすぎていることを示します。 コードを最適化するか、書き込みのサイズまたはフラッシュの動作を確認してください。

## <a name="limitation"></a>V12 へのアップグレード
ADLS の調整: ADLS から提供された帯域幅の上限に達すると、タスクの失敗が発生し始めます。 このことは、タスク ログで調整エラーを監視することで確認できます。  コンテナーのサイズを増やすことで、並列処理を減らせます。  ジョブのためにより高い同時実行性が必要な場合は、お問い合わせください。   
調整されているかどうかを確認するには、クライアント側でデバッグ ログを有効にする必要があります。 その方法は次のとおりです。

1. [Ambari]、[Storm]、[構成]、[Advanced storm-worker-log4j (storm-worker-log4j の詳細)] の順にクリックし、次の変更を行います。  &lt;root level="info"&gt; を &lt;root level="debug"&gt; に変更します。  すべてのノードとサービスを再起動し、構成を有効にします。
2. ワーカー ノード (/var/log/storm/worker-artifacts/&lt;TopologyName&gt;/&lt;port&gt;/worker.log の直下) の Storm トポロジ ログで、ADLS 調整の例外を監視します。

## <a name="additional-tuning"></a>その他のチューニング
Storm におけるその他のパフォーマンスのチューニングについては、こちらの[ブログ](https://blogs.msdn.microsoft.com/shanyu/2015/05/14/performance-tuning-for-hdinsight-storm-and-microsoft-azure-eventhubs/)を参照してください。

## <a name="examples-to-run"></a>実行例
[GitHub](https://github.com/hdinsight/storm-performance-automation) にある例をお試しください。



<!--HONumber=Jan17_HO2-->


