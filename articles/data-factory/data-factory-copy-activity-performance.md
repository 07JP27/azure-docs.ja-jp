<properties
	pageTitle="コピー アクティビティのパフォーマンスとチューニングに関するガイド | Microsoft Azure"
	description="コピー アクティビティによる Azure Data Factory でのデータ移動のパフォーマンスに影響する主な要因について説明します。"
	services="data-factory"
	documentationCenter=""
	authors="spelluru"
	manager="jhubbard"
	editor="monicar"/>

<tags
	ms.service="data-factory"
	ms.workload="data-services"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="article"
	ms.date="03/07/2016"
	ms.author="spelluru"/>


# コピー アクティビティのパフォーマンスとチューニングに関するガイド
この記事では、Azure Data Factory でのデータ移動 (コピー アクティビティ) のパフォーマンスに影響する主な要因について説明します。また、内部テスト実行時の実際のパフォーマンスを一覧表示すると共に、コピー アクティビティのパフォーマンスを最適化するさまざまな方法を説明します。

## Azure Data Factory でのデータ移動の概要
コピー アクティビティにより、Azure Data Factory ではデータ移動が実行されます。また、このアクティビティは、安全で信頼性が高く、スケーラブルでパフォーマンスに優れた方法によって[さまざまなデータ ストア](data-factory-data-movement-activities.md#supported-data-stores-for-copy-activity)間でデータをコピーできる、[グローバルに利用可能な Data Movement Service](data-factory-data-movement-activities.md#global) によって動作します。Data Movement Service では、ソース データ ストアとシンク データ ストアの場所に基づいて、データ移動操作を実行するのに最適なリージョンが自動的に選択されます。現時点では、シンク データ ストアに最も近いリージョンが使用されています。

このデータ移動がさまざまなシナリオでどのように行われるかを説明します。

### 2 つのクラウド データ ストア間でのデータのコピー
ソース データ ストアとシンク (コピー先) データ ストアの両方がクラウドにある場合、コピー アクティビティは、次の段階を経てデータをソースからシンクにコピー/移動します。

1.	ソース データ ストアからデータを読み取る
2.	入力データセット、出力データセット、コピー アクティビティの構成に基づいて、シリアル化/逆シリアル化、圧縮/圧縮解除、列マッピング、型変換を実行する
3.	コピー先データ ストアにデータを書き込む

![2 つのクラウド データ ストア間でのデータのコピー](./media/data-factory-copy-activity-performance/copy-data-between-two-cloud-stores.png)

**注:** 点線で囲んだ段階 (圧縮、列マッピングなど) は、ユース ケースによって利用できる場合とそうでない場合があります。


### オンプレミス データ ストアとクラウド データ ストア間でのデータのコピー
[オンプレミスのデータ ストアと、クラウドのデータ ストアの間でデータを安全に移動する](data-factory-move-data-between-onprem-and-cloud.md)には、Data Management Gateway をインストールする必要があります。これは、オンプレミスのコンピューター上でハイブリッドなデータ移動と処理を可能にするエージェントです。このシナリオでは、Data Management Gatewa によって、入力データセット、出力データセット、コピー アクティビティの構成に基づいて、シリアル化/逆シリアル化、圧縮/圧縮解除、列マッピング、型変換が実行されます。

![オンプレミスのデータ ストアとクラウドのデータ ストア間でのデータのコピー](./media/data-factory-copy-activity-performance/copy-data-between-onprem-and-cloud.png)

## パフォーマンス チューニングの手順
コピー アクティビティを使用した Azure Data Factory ソリューションのパフォーマンスを調整する場合には、以下の一般的な手順を実行することをお勧めします。

1.	**ベースラインの確立。** 開発フェーズでは、代表的なサンプル データに対してコピー アクティビティを使用してパイプラインをテストします。Azure Data Factory の[スライシング モデル](data-factory-scheduling-and-execution.md#time-series-datasets-and-data-slices)を使用することで、操作するデータの量を制限できます。

	Azure プレビュー ポータルで、出力データセットに関する [データ スライス] ブレードと [アクティビティの実行の詳細] ブレード (これらはコピー アクティビティの期間とコピーされたデータのサイズを表示) を調べて、実行時間とパフォーマンス特性を収集します。

	![アクティビティ実行の詳細](./media/data-factory-copy-activity-performance/activity-run-details.png)

	ご使用のシナリオのパフォーマンスと構成は、内部的な観測値に基づいて公開されているコピー アクティビティの[パフォーマンス リファレンス](#performance-reference) (下記参照) と比較することができます。
2. **パフォーマンスの診断と最適化**。パフォーマンスの観測値が期待値を下回った場合は、パフォーマンスのボトルネックを特定し、ボトルネックを除去またはその影響を軽減するために最適化を実行する必要があります。この記事では、パフォーマンスの診断に関する詳細な説明は省略しますが、いくつかの一般的な考慮事項を以下に一覧します。
	- [ソース](#considerations-on-source)
	- [シンク](#considerations-on-sink)
	- [シリアル化/逆シリアル化](#considerations-on-serializationdeserialization)
	- [圧縮](#considerations-on-compression)
	- [列マッピング](#considerations-on-column-mapping)
	- [Data Management Gateway](#considerations-on-data-management-gateway)
	- [その他の考慮事項](#other-considerations)
3. **構成をデータ全体に拡大する**。実行結果とパフォーマンスに問題がなければ、図中のデータ全体を網羅するようにデータセットの定義とパイプラインのアクティブな期間を拡張することができます。

## パフォーマンス リファレンス
> [AZURE.IMPORTANT] **免責事項:** 以下のデータは、ガイダンスとして、また大まかな計画策定用の参考として公開したものです。帯域幅、ハードウェア、構成などがクラス最良の条件であることを前提とします。このデータは参照用としてのみ使用してください。観察するデータ移動のスループットは、さまざまな変数の影響を受けます。データ移動のニーズを満たすようにパフォーマンスをチューニングして向上させることが可能な方法については、後述のセクションを参照してください。パフォーマンス向上のための機能強化が行われた場合、このデータは更新されます。

![パフォーマンス マトリックス](./media/data-factory-copy-activity-performance/CopyPerfRef.png)

> [AZURE.NOTE] **近日公開予定:** 現在、基本的なパフォーマンス特性を向上させる処理を行っており、まもなく上記の表は、より高いスループット値に更新されます。

注意する点:

- スループットは、次の数式を使用して計算されます。[ソースから読み取られたデータ サイズ]/[コピー アクティビティの実行時間]
- 上記の数値を計算するには、[TPC-H](http://www.tpc.org/tpch/) データ セットが利用されます。
- Microsoft Azure データ ストアの場合、ソースとシンクは同じ Azure リージョンにあります。
- ハイブリッド (オンプレミスからクラウド、またはクラウドからオンプレミス) のデータ移動では、次の構成を使用して、オンプレミスのデータ ストアとは異なるコンピューター上で Data Management Gateway (単一インスタンス) がホストされました。ゲートウェイ上で 1 つアクティビティを実行した場合、コピー操作では、このコンピューターの CPU/メモリ リソースおよびネットワーク帯域幅のごく一部しか消費されませんでした。
	<table>
	<tr>
		<td>CPU</td>
		<td>32 Cores 2.20GHz Intel Xeon® E5-2660 v2</td>
	</tr>
	<tr>
		<td>メモリ</td>
		<td>128 GB</td>
	</tr>
	<tr>
		<td>ネットワーク</td>
		<td>インターネット インターフェイス: 10 Gbps。イントラネット インターフェイス: 40 Gbps</td>
	</tr>
	</table>

## ソースに関する考慮事項
### 全般
基になるデータ ストアが、コピー アクティビティ (ただし、これに限定されない) に対して実行されるその他のワークロードに圧倒されないことを確認します。

Microsoft データ ストアの場合は、データ ストアに限定した[監視とチューニングに関するトピック](#appendix-data-store-performance-tuning-reference)を参照してください。データ ストアのパフォーマンス特性に関する説明と、応答時間を短縮しスループットを最大限に高める方法が記載されています。

### ファイル ベースのデータ ストア
*(Azure BLOB、Azure Data Lake、オンプレミスのファイル システムなど)*

- **ファイル サイズとファイル数の平均**: コピー アクティビティはデータをファイルごとに転送します。移動するデータ量は同じで、データを少数の大きなファイルで構成するのでなく多数の小さなファイルで構成した場合、ファイルごとにブートス トラップ フェーズが存在するため、全体的なスループットは低下します。したがって、可能であれば、小さなファイルをまとめて大きなファイルとすることで、スループットを高めてください。
- **ファイルの形式と圧縮**: パフォーマンスを向上させるその他の方法については、「[シリアル化/逆シリアル化に関する考慮事項](#considerations-on-serializationdeserialization)」と「[圧縮に関する考慮事項](#considerations-on-compression)」を参照してください。
- さらに、**Data Management Gateway** を使用する必要がある**オンプレミスのファイル システム**のシナリオについては、「[ゲートウェイに関する考慮事項](#considerations-on-data-management-gateway)」を参照してください。

### リレーショナル データ ストア
*(Azure SQL Database、Azure SQL Data Warehouse、SQL Server データベース、Oracle データベース、MySQL データベース、DB2 データベース、Teradata データベース、Sybase データベース、PostgreSQL データベースなど)*

- **データ パターン**: テーブル スキーマは、コピーのスループットに影響を与えます。同じ量のデータをコピーする場合、行のサイズが小さいよりも行のサイズが大きい方がパフォーマンスは高くなります。これは、データベースは行数が少なくバッチが少なくなれば、それだけ効率的にデータを取得できるからです。
- **クエリまたはストアド プロシージャ**: データをより効率的にフェッチできるように、コピー アクティビティ ソースで指定するクエリまたはストアド プロシージャのロジックを最適化します。
- さらに、SQL Server や Oracle など、**Data Management Gateway** を使用する必要ある**オンプレミスのリレーショナル データベース**の場合は、「[ゲートウェイに関する考慮事項](#considerations-on-data-management-gateway)」を参照してください。

## シンクに関する考慮事項

### 全般
基になるデータ ストアが、コピー アクティビティ (ただし、これに限定されない) に対して実行されるその他のワークロードに圧倒されないことを確認します。

Microsoft データ ストアの場合は、データ ストアに限定した[監視とチューニングに関するトピック](#appendix-data-store-performance-tuning-reference)を参照してください。データ ストアのパフォーマンス特性に関する説明と、応答時間を短縮しスループットを最大限に高める方法が記載されています。

### ファイル ベースのデータ ストア
*(Azure BLOB、Azure Data Lake、オンプレミスのファイル システムなど)*

- **コピー動作**: 別のファイル ベースのデータ ストアからデータをコピーする場合、コピー アクティビティは "copyBehavior" プロパティを介して、階層の維持、階層の平坦化、ファイルのマージという 3 種類の動作を提供します。階層の維持または階層の平坦化では、パフォーマンス オーバーヘッドはほとんどありませんが、ファイルのマージでは余分にパフォーマンス オーバーヘッドが発生します。
- **ファイルの形式と圧縮**: パフォーマンスを向上させるその他の方法については、「[シリアル化/逆シリアル化に関する考慮事項](#considerations-on-serializationdeserialization)」と「[圧縮に関する考慮事項](#considerations-on-compression)」を参照してください。
- **Azure BLOB** では、現在のところ、最適化されたデータ転送およびスループットに対してブロック BLOB をサポートしているだけです。
- さらに、**Data Management Gateway** を使用する必要がある**オンプレミスのファイル システム**のシナリオについては、「[ゲートウェイに関する考慮事項](#considerations-on-data-management-gateway)」を参照してください。

### リレーショナル データ ストア
*(Azure SQL Database、Azure SQL Data Warehouse、SQL Server データベースなど)*

- **コピー動作**: コピー アクティビティは、"sqlSink"用に構成されたプロパティに応じて、以下に示すさまざまな方法でデータを宛先データベースに書き込みます。
	- 既定では、Data Movement Service は、一括コピー API を使用して、データを追加モードで挿入します。この場合、最高のパフォーマンスが得られます。
	- シンク内でストアド プロシージャを構成した場合、データベースでは、一括読み込みではなく、行ごとにデータが適用されます。このため、パフォーマンスは大幅に低下します。データのサイズが大きい場合、適用できるときは、代わりに "sqlWriterCleanupScript" プロパティ (下記参照) の使用を検討してください。
	- "sqlWriterCleanupScript" プロパティを構成すると、サービスはコピー アクティビティの実行のたびに、まずスクリプトをトリガーし、次に一括コピー API を使用してデータを挿入します。たとえば、テーブル全体を最新のデータで上書きするには、ソースから新しいデータを一括で読み込む前に、まず、すべてのレコードを削除するスクリプトを指定することができます。
- **データのパターンとバッチ サイズ**:
	- テーブル スキーマは、コピーのスループットに影響を及ぼします。同じ量のデータをコピーする場合、行のサイズが小さいよりも行のサイズが大きい方がパフォーマンスは高くなります。これは、データベースが、バッチがより少ないデータを効率的にコミットできることに理由があります。
	- コピー アクティビティは、データを一連のバッチで挿入します。この場合、バッチに含まれる行数は "writeBatchSize" プロパティを使用して設定できます。データの行のサイズが小さい場合は、"writeBatchSize" プロパティをより大きな値に設定することで、バッチ オーバーヘッドの縮小の利点を生かし、スループットを向上させることができます。データの行のサイズが大きい場合に、writeBatchSize の値を大きくするときは注意してください。値が大きいと、データベースのオーバー ロードによってコピー障害が発生するおそれがあります。
- さらに、SQL Server や Oracle など、**Data Management Gateway** を使用する必要ある**オンプレミスのリレーショナル データベース**の場合は、「[ゲートウェイに関する考慮事項](#considerations-on-data-management-gateway)」を参照してください。


### NoSQL ストア
*(Azure テーブル、Azure DocumentDB など)*

- **Azure テーブル**の場合:
	- **パーティション**: インターリーブされたパーティションへのデータ書き込みを行うと、パフォーマンスが大幅に低下します。データが複数のパーティションに順次、効率的に挿入されるようにパーティション キーでソース データを並び替えることも、データを単一のパーティションに書き込むようにロジックを調整することもできます。
- **Azure DocumentDB** の場合:
	- **バッチ サイズ**: "writeBatchSize" プロパティは、ドキュメントを作成する DocumentDB サービスへの並列要求の数を示します。"writeBatchSize" を増やすとパフォーマンスがよくなります。DocumentDB に送信される並列要求の数が増えるためです。ただし、DocumentDB に書き込む際はスロットルに注意してください (エラー メッセージ "要求処理率が大きい")。スロットルは、ドキュメントのサイズ、ドキュメント内の語句の数、ターゲット コレクションの索引作成ポリシーなど、複数の要因によって発生する可能性があります。コピーのスループットを高めるには、より適切なコレクション (S3 など) の使用を検討してください。

## シリアル化/逆シリアル化に関する考慮事項
入力データセットまたは出力データセットがファイルであると、シリアル化および逆シリアル化が実行されることがあります。現在、コピー アクティビティでは Avro および Text (CSV や TSV など) データ形式をサポートしています。

**コピー動作:**

- ファイル ベースのデータ ストア間でファイルをコピーする場合:
	- 入力データセットと出力データセットが両方とも、同じファイル形式を持っているか、またはファイル形式が設定されていない場合、Data Movement Service は、シリアル化/逆シリアル化を実行することなく、バイナリ コピーを実行します。そのため、ソースとシンクとのファイル形式設定が異なるシナリオの場合と比較して、良好なスループットが示されます。
	- 入力データセットと出力データセットは両方とも Text 形式で、エンコードの種類のみが異なる場合、Data Movement Service はシリアル化/逆シリアル化を実行することなく、エンコード変換のみを行います。結果、バイナリ コピーの場合と比較していくらかのパフォーマンス オーバーヘッドが発生します。
	- 入力データセットと出力データセットのファイル形式が異なるか、または構成が異なる場合 (区切り記号のように)、Data Movement Service は、ソース データをストリームに逆シリアル化し、変換し、望ましい出力形式にシリアル化します。この場合、前のシナリオと比較してはるかに大きなパフォーマンス オーバーヘッドが発生します。
- ファイルとファイル ベース以外のデータ ストアとの間でコピーを行う場合 (たとえば、ファイル ベースのストアとリレーショナル ストアとの間)、シリアル化または逆シリアル化の手順が必要であり、その結果、大幅なパフォーマンス オーバーヘッドが発生します。

**ファイルの形式:** ファイル形式の選択は、コピーのパフォーマンスに影響を与えます。たとえば、Avro は、データと一緒にメタデータを格納するコンパクトなバイナリ形式であり、Hadoop エコシステムでの処理とクエリで幅広くサポートされています。ただし、Avro の場合は、シリアル化/逆シリアル化によってコピーのスループットが低下するので、Text 形式と比較してコストがかかります。処理フローで使用するファイル形式を選択する場合は、総合的に判断する必要があります。具体的には、ソース データ ストアにデータを格納する際の形式または外部システムからデータを抽出する際の形式、ストレージや分析処理やクエリに最適な形式、データ マートにエクスポートしてレポート ツールおよび視覚化ツールを使用するためのデータの形式などを考慮する必要があります。時々、読み取りおよび書き込みパフォーマンスの点では準最適なファイル形式であっても、分析プロセス全体を考慮すると最適であることが判明する場合があります。

## 圧縮に関する考慮事項
入力データアセットまたは出力データセットがファイルである場合は、宛先へのデータの書き込み時に圧縮または圧縮解除を実行するようにコピー アクティビティを構成することができます。圧縮を有効にして、I/O と CPU のトレードオフを考慮する: データを圧縮すると、コンピューティング リソースのコストは増えますが、その反面、ネットワーク I/O とストレージのコストは減少します。このため、データによっては、圧縮によってコピーのスループットが全体的に押し上げられる可能性があります。

**コーデック:** サポートされている圧縮の種類は、GZIP、BZIP2、および Deflate です。Azure HDInsight では、この 3 種類をすべて利用して処理を行うことができます。各圧縮コーデックには、固有の特徴があります。たとえば、BZIP2 はコピーのスループットが最も低いのですが、分割して処理することができれば、最高の Hive クエリ パフォーマンスを発揮します。GZIP は最もバランスの取れたオプションであり最もよく使用されています。エンド ツー エンドのシナリオに最適なコーデックを選択する必要があります。

**レベル:** 各圧縮コーデックでは、最速圧縮と最適圧縮という 2 つのオプションの中からいずれかを選択できます。最速圧縮オプションでは、可能な限り短時間でデータの圧縮を完了しますが、生成ファイルが最適に圧縮されない場合があります。最適圧縮オプションではデータ圧縮により多くの時間を費やしますが、データ量を最小限まで圧縮します。両方のオプションを実際にテストして、どちらが全体的なパフォーマンスで優れているかを確認することができます。

**重要な考慮事項:** オンプレミスのストアとクラウドとの間でサイズの大きなデータをコピーする場合で、企業ネットワークと Azure の帯域幅が制限要因となることが多く、入力データセットと出力データセットの両方を非圧縮形式にしたい場合は、**中間的な Azure BLOB** と圧縮を組み合わせて使用することを検討できます。具体的には、1 つのコピー アクティビティを 2 つのコピー アクティビティに分割することができます。1 番目のコピー アクティビティで、ソースから中間またはステージング BLOB に圧縮形式でコピーし、2 番目のコピー アクティビティで、圧縮されたデータをステージング環境からコピーし、シンクへの書き込み中に圧縮を解除します。

## 列マッピングに関する考慮事項
コピー アクティビティの "columnMappings" プロパティを使用すれば、入力列のすべてまたはサブセットを出力列にマップすることができます。Data Movement Service は、ソースからデータを読み取った後、そのデータに対して列マッピングを実行してから、データをシンクに書き込む必要があります。この追加の処理により、コピーのスループットが低下します。

ソース データ ストアがクエリ可能な場合 (たとえば、Azure SQL/SQL Server のようなリレーショナル ストアまたは Azure Table/Azure DocumentDB のような NoSQL ストアの場合)、列マッピングを使用するのでなく、列フィルタリング/順序変更ロジックをクエリ プロパティにプッシュダウンすることを検討できます。そうした場合、結果として、ソース データ ストアからのデータ読み取り中にプロジェクションが実行され、効率が向上します。

## Data Management Gateway に関する考慮事項
ゲートウェイのセットアップにおける推奨事項については、「[Data Management Gateway を使用する上で考慮すること](data-factory-move-data-between-onprem-and-cloud.md#Considerations-for-using-Data-Management-Gateway)」を参照してください。

**ゲートウェイ コンピューター環境:** Data Management Gateway をホストする専用のマシンを使用することをお勧めします。ゲートウェイ コンピューター上でのコピー操作中に PerfMon などのツールを使用して、CPU、メモリ、および帯域幅の使用率を確認します。CPU、メモリ、またはネットワーク帯域幅がボトルネックになる場合は、より強力なコンピューターに切り替えます。

**コピー アクティビティの複数の実行の同時処理:** Data Management Gateway の 1 つのインスタンスで、コピー アクティビティの複数の実行を同時に処理することができます。すなわち、ゲートウェイは複数のコピー ジョブを同時に実行することができます (同時実行ジョブ数はゲートウェイ コンピューターのハードウェア構成に基づいて算出されます)。追加のコピー ジョブは、ゲートウェイによって取得されるか、またはジョブがタイムアウトになるかの、どちらかが先に発生するまで、キューに置かれます。ゲートウェイ上でリソースの競合を避けるには、アクティビティのスケジュールをステージングして 1 度にキューに入れるジョブの数量を減らすことも、複数のゲートウェイに負荷を分担することを検討することもできます。


## その他の考慮事項
コピーするデータのサイズが非常に大きい場合は、Azure Data Factory のスライス メカニズムを使用してデータをさらに分割し、コピー アクティビティのスケジュールを頻繁に設定して各コピー アクティビティ実行のデータ サイズを小さくするように、ビジネス ロジックを調整することができます。

同じデータ ストアに到達またはアクセスするデータセットの数とコピー アクティビティの数に常に注意してください。同時コピー ジョブの数が多いと、データ ストアのスロットルが発生し、パフォーマンスの低下、コピー ジョブの内部的な再試行、場合によっては実行の失敗につながるおそれがあります。

## ケース スタディ: オンプレミスの SQL Server から Azure BLOB へのコピー
**シナリオ:** オンプレミスの SQL Server から Azure BLOB に CSV 形式でデータをコピーするパイプラインが構築されています。コピーの高速化を図るために、CSV ファイルが BZIP2 形式で圧縮されるように指定されています。

**テストと分析:** 観察結果によれば、コピー アクティビティのスループットは 2 MB/秒で、パフォーマンスのベンチマークをかなり下回っています。

**パフォーマンスの分析とチューニング:** パフォーマンスの問題を解決するために、まず、データの処理および移動の方法を見ていきます。

1.	**データの読み取り:** ゲートウェイは、SQL Server への接続を開く、クエリを送信します。SQL Server はイントラネット経由でゲートウェイにデータ ストリームを送信することで応答します。
2.	ゲートウェイはデータ ストリームを CSV 形式に**シリアル化**し、データを BZIP2 ストリームに**圧縮**します。
3.	**データの書き込み:** ゲートウェイは BZIP2 ストリームをインターネット経由で Azure BLOB にアップロードします。

ご覧のように、データは SQL Server、LAN、ゲートウェイ、WAN、Azure BLOB の順にストリーミングで処理および移動されており、**全体的なパフォーマンスは、パイプライン全体にわたって最低のスループットで制御されています**。

![データ フロー](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

次に示す要因の 1 つまたは複数がパフォーマンスのボトルネックである可能性があります。

1.	**ソース:** 負荷が大きいため、SQL Server 自体のスループットが低くなっています。
2.	**Data Management Gateway:**
	1.	**LAN:** ゲートウェイが SQL Server から遠く離れた位置にあり、低帯域幅の接続を使用しています。
	2.	次の処理を実行すると、**ゲートウェイ コンピューター上の負荷**がその上限に達します。
		1.	**シリアル化:** CSV へのデータ ストリームのシリアル化のスループットが低い
		2.	**圧縮:** 低速の圧縮コーデックが選択されている (たとえば、BZIP2 は Core i7 の場合に 2.8 MB/秒)。
	3.	**WAN:** 企業ネットワークと Azure との間が低帯域幅 (たとえば、T1 = 1544 kbps、T2 = 6312 kbps)。
4.	**シンク:** Azure BLOB のスループットが低くなっています (ただし、SLA で最低 60 MB/秒が保証さえている場合、可能性は極めて低い)。

この場合、BZIP2 データ圧縮がパイプライン全体を遅くしている可能性があります。GZIP 圧縮コーデックに切り替えると、このボトルネックが緩和される場合があります。

## 付録 – データ ストアのパフォーマンスのチューニングに関するリファレンス
ここでは、サポートされているいくつかのデータ ストアについて、パフォーマンスの監視とチューニングに関するリファレンス情報をいくつか示します。

- Azure Storage (Azure BLOB、Azure Table など): [Azure Storage のスケーラビリティおよびパフォーマンスのターゲット](../storage/storage-scalability-targets.md) と [Microsoft Azure Storage のパフォーマンスとスケーラビリティに対するチェック リスト](../storage//storage-performance-checklist.md)
- Azure SQL Database: [パフォーマンスを監視](../sql-database/sql-database-service-tiers.md#monitoring-performance)し、データベース トランザクション ユニット (DTU) の割合を確認できます。
- Azure SQL Data Warehouse: その機能は、Data Warehouse ユニット (DWU) で測定されます。「[SQL Data Warehouse を使用した弾力的なパフォーマンスとスケール](../sql-data-warehouse/sql-data-warehouse-performance-scale.md)」を参照してください。
- Azure DocumentDB: [Performance level in DocumentDB (DocumentDB のパフォーマンス レベル)](../documentdb/documentdb-performance-levels.md)
- オンプレミスの SQL Server: [パフォーマンスの監視とチューニング](https://msdn.microsoft.com/library/ms189081.aspx)
- オンプレミスのファイル サーバー: [Performance Tuning for File Servers (ファイル サーバーのパフォーマンス チューニング)](https://msdn.microsoft.com/library/dn567661.aspx)

<!---HONumber=AcomDC_0309_2016-->