<properties
	pageTitle="コピー アクティビティのパフォーマンスとチューニングに関するガイド | Microsoft Azure"
	description="コピー アクティビティによる Azure Data Factory でのデータ移動のパフォーマンスに影響する主な要因について説明します。"
	services="data-factory"
	documentationCenter=""
	authors="spelluru"
	manager="jhubbard"
	editor="monicar"/>

<tags
	ms.service="data-factory"
	ms.workload="data-services"
	ms.tgt_pltfrm="na"
	ms.devlang="na"
	ms.topic="article"
	ms.date="06/03/2016"
	ms.author="spelluru"/>


# コピー アクティビティのパフォーマンスとチューニングに関するガイド
この記事では、Azure Data Factory でのデータ移動 (コピー アクティビティ) のパフォーマンスに影響する主な要因について説明します。また、内部テスト実行時の実際のパフォーマンスを一覧表示すると共に、コピー アクティビティのパフォーマンスを最適化するさまざまな方法を説明します。

コピー アクティビティを使用すれば、次の例に示すようにデータ移動の高いスループットが得られます。

- オンプレミスのファイル システムおよび Azure BLOB ストレージから Azure BLOB ストレージへ 1 TB のデータを 3 時間未満 (つまり、@ 100 MBps) で取り込む。
- オンプレミスのファイルシステムおよび Azure BLOB ストレージから Azure Data Lake Store へ 1 TB のデータを 3 時間未満 (つまり、@ 100 MBps) で取り込む。
- Azure BLOB ストレージから Azure SQL Data Warehouse へ 1 TB のデータを 3 時間未満 (つまり、@ 100 MBps) で取り込む。

コピー アクティビティのパフォーマンスとパフォーマンスをさらに向上させるためのチューニングに関するヒントの詳細については、以下のセクションを参照してください。

> [AZURE.NOTE] 一般的にコピー アクティビティに慣れていない場合は、この記事をお読みになる前に「[データ移動アクティビティ](data-factory-data-movement-activities.md)」を参照してください。

## パフォーマンス チューニングの手順
コピー アクティビティを使用した Azure Data Factory ソリューションのパフォーマンスを調整する場合には、以下の一般的な手順を実行することをお勧めします。

1.	**ベースラインの確立。** 開発フェーズでは、代表的なサンプル データに対してコピー アクティビティを使用してパイプラインをテストします。Azure Data Factory の[スライシング モデル](data-factory-scheduling-and-execution.md#time-series-datasets-and-data-slices)を使用することで、操作するデータの量を制限できます。

	**監視と管理アプリ**を使用して、実行時間とパフォーマンス特性を収集します。その場合、Data Factory のホーム ページで **[監視と管理]** タイルをクリックし、ツリー ビューの**出力データセット**を選択してから、**[アクティビティ ウィンドウ]** リストでコピー アクティビティの実行を選択します。**[アクティビティ ウィンドウ]** リストにコピー アクティビティの期間が表示され、右側の **[アクティビティ ウィンドウ エクスプローラー]** ウィンドウにコピーされたデータのサイズとスループットが表示されます。アプリの詳細については、「[新しい監視と管理アプリを使用した Azure Data Factory パイプラインの監視と管理](data-factory-monitor-manage-app.md)」を参照してください。
	
	![アクティビティ実行の詳細](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

	ご使用のシナリオのパフォーマンスと構成は、内部的な観測値に基づいて公開されているコピー アクティビティの[パフォーマンス リファレンス](#performance-reference) (下記参照) と比較することができます。
2. **パフォーマンスの診断と最適化**。パフォーマンスの観測値が期待値を下回った場合は、パフォーマンスのボトルネックを特定し、ボトルネックを除去またはその影響を軽減するために最適化を実行する必要があります。この記事では、パフォーマンスの診断に関する詳細な説明は省略しますが、いくつかの一般的な考慮事項を以下に一覧します。
	- [ソース](#considerations-on-source)
	- [シンク](#considerations-on-sink)
	- [シリアル化/逆シリアル化](#considerations-on-serializationdeserialization)
	- [圧縮](#considerations-on-compression)
	- [列マッピング](#considerations-on-column-mapping)
	- [Data Management Gateway](#considerations-on-data-management-gateway)
	- [その他の考慮事項](#other-considerations)
	- [並列コピー](#parallel-copy)
	- [クラウド データ移動単位](#cloud-data-movement-units)

3. **構成をデータ全体に拡大する**。実行結果とパフォーマンスに問題がなければ、図中のデータ全体を網羅するようにデータセットの定義とパイプラインのアクティブな期間を拡張することができます。

## パフォーマンス リファレンス
> [AZURE.IMPORTANT] **免責事項:** 以下のデータは、ガイダンスとして、また大まかな計画策定用の参考として公開したものです。帯域幅、ハードウェア、構成などがクラス最良の条件であることを前提とします。このデータは参照用としてのみ使用してください。観察するデータ移動のスループットは、さまざまな変数の影響を受けます。データ移動のニーズを満たすようにパフォーマンスをチューニングして向上させることが可能な方法については、後述のセクションを参照してください。パフォーマンス向上のための機能強化が行われた場合、このデータは更新されます。

![パフォーマンス マトリックス](./media/data-factory-copy-activity-performance/CopyPerfRef.png)

注意する点:

- スループットは、次の数式を使用して計算されます。[ソースから読み取られたデータ サイズ]/[コピー アクティビティの実行時間]
- 上記の数値を計算するには、[TPC-H](http://www.tpc.org/tpch/) データ セットが利用されます。
- Microsoft Azure データ ストアの場合、ソースとシンクは同じ Azure リージョンにあります。
- **cloudDataMovementUnits** は 1 に設定され、**parallelCopies** は指定されていません。
- ハイブリッド (オンプレミスからクラウド、またはクラウドからオンプレミス) のデータ移動では、次の構成を使用して、オンプレミスのデータ ストアとは異なるコンピューター上で Data Management Gateway (単一インスタンス) がホストされました。ゲートウェイ上で 1 つアクティビティを実行した場合、コピー操作では、このコンピューターの CPU/メモリ リソースおよびネットワーク帯域幅のごく一部しか消費されませんでした。
	<table>
	<tr>
		<td>CPU</td>
		<td>32 Cores 2.20GHz Intel Xeon® E5-2660 v2</td>
	</tr>
	<tr>
		<td>メモリ</td>
		<td>128 GB</td>
	</tr>
	<tr>
		<td>ネットワーク</td>
		<td>インターネット インターフェイス: 10 Gbps。イントラネット インターフェイス: 40 Gbps</td>
	</tr>
	</table>

## 並列コピー
コピー操作のスループットを向上させ、データの移動時間を短縮する方法の 1 つは、**コピー アクティビティの実行中に並行して**ソースからデータを読み取り、データをターゲットに書き込むことです。
 
この設定は、アクティビティ定義の **concurrency** プロパティとは異なることに注意してください。concurrency プロパティでは、さまざまなアクティビティ ウィンドウ (1-2 AM、2-3 AM、3-4 AM など) のデータを処理するために実行時に一緒に実行される**コピー アクティビティの同時実行**数を決定します。これは、履歴を読み込む場合に非常に役立ちます。一方、ここで説明されている並列コピー機能は、**1 つのアクティビティの実行**に適用されます。

**サンプル シナリオ**を見てみましょう。処理が必要な過去のスライスが複数ある場合の以下の例について考えてみます。Data Factory サービスは、スライスごとにコピー アクティビティのインスタンスを実行します (アクティビティの実行)。

- 1 番目のアクティビティ ウィンドウのデータ スライス (午前 1 時から午前 2 時) ==> アクティビティの実行 1
- 2 番目のアクティビティ ウィンドウのデータ スライス (午前 2 時から午前 3 時) ==> アクティビティの実行 2
- 3 番目のアクティビティ ウィンドウのデータ スライス (午前 3 時から午前 4 時) ==> アクティビティの実行 3
- 同様に続きます。

この例では、**concurrency** が **2** に設定されており、**アクティビティの実行 1** と**アクティビティの実行 2** で 2 つのアクティビティ ウィンドウからデータを**同時に**コピーできるため、データ移動のパフォーマンスが向上します。ただし、アクティビティの実行 1 に関連付けられているファイルが複数ある場合は、1 つのファイルがソースからターゲットに一度にコピーされます。

### parallelCopies
**parallelCopies** プロパティを使用して、コピー アクティビティで使用する並列処理を指定することができます。つまり、このプロパティを、並行してソースからの読み取りまたはシンク データ ストアへの書き込みを行うコピー アクティビティ内のスレッドの最大数と考えます。

コピー アクティビティの実行ごとに、Azure Data Factory は、ソース データ ストアからターゲット データ ストアへのデータ コピーで使用する並列コピーの数をインテリジェントに決定します。使用される並列コピーの既定数は、以下のソースとシンクの種類によって異なります。

ソースとシンク |	サービスによって決定される並列コピーの既定数
------------- | -------------------------------------------------
**ファイル ベース ストア** (Azure BLOB、Azure Data Lake、オンプレミスのファイル システム、オンプレミスの HDFS) 間のデータのコピー | **ファイルのサイズ**と 2 つのクラウド データ ストア間でのデータのコピーで使用される**クラウド データ移動単位の数** (定義については、次のセクションを参照) またはハイブリッド コピー(オンプレミス データ ストア間のデータ コピー) で使用されるゲートウェイ コンピューターの物理構成に基づく **1 ～ 32** の範囲
**任意のソース データ ストアから Azure テーブルへ**のデータのコピー | 4
その他のすべてのソースとシンクのペア | 1

ほとんどの場合、既定の動作で最適なスループットが得られます。ただし、データ ストアを持つコンピューターに対する負荷を制御したり、コピーのパフォーマンスを調整したりする場合は、**parallelCopies** プロパティの値を指定して、既定値をオーバーライドできます。**1 ～ 32** (両端の値を含む) の範囲の値を指定する必要があります。実行時に、コピー アクティビティでは、最適なパフォーマンスが得られるように構成値以下の値が選択されます。

	"activities":[  
	    {
	        "name": "Sample copy activity",
	        "description": "",
	        "type": "Copy",
	        "inputs": [{ "name": "InputDataset" }],
	        "outputs": [{ "name": "OutputDataset" }],
	        "typeProperties": {
	            "source": {
	                "type": "BlobSource",
	            },
	            "sink": {
	                "type": "AzureDataLakeStoreSink"
	            },
	            "parallelCopies": 8
	        }
	    }
	]

以下の点に注意してください。

- ファイル ベースのストア間でのデータ コピーの場合、並列処理はファイル レベルで行われます。つまり、単一ファイル内でチャンクは実行されません。実行時にコピー操作で使用される並列コピーの実際の数は、存在するファイルの数以下となります。コピー動作が mergeFile の場合、並列処理は利用されません。
- ParallelCopies プロパティの値を指定する場合は、ソースおよびシンク データ ストアへの負荷が増えることを考慮してください。ハイブリッド コピーの場合、特に同じデータ ストアに対して実行されているアクティビティが複数ある場合や、同じアクティビティが複数同時に実行されている場合、ゲートウェイへの負荷も増えます。データ ストアまたはゲートウェイの負荷の上限に達したことがわかった場合は、parallelCopies の値を減らし、負荷を軽減してください。
- ファイル ベース以外のストアからファイル ベースのストアにデータをコピーする際に、parallelCopies プロパティは、指定されている場合でも無視され、並列処理は利用されません。

> [AZURE.NOTE] ハイブリッド コピーの実行時に parallelCopies 機能を活用するには、バージョン 1.11 以上の Data Management Gateway を使用する必要があります。

### クラウド データ移動単位
**クラウド データ移動単位**は、クラウド間でコピー操作を実行する場合に使用される Azure Data Factory サービスの 1 つの単位の能力 (CPU、メモリ、ネットワーク リソース割り当ての組み合わせ) を表す測定値です。ハイブリッド コピーには適用されません。既定では、Azure Data Factory サービスは 1 つのクラウド データ移動単位を使用して、1 つのコピー アクティビティを実行します。この既定は、**cloudDataMovementUnits** プロパティの値を指定することでオーバーライドできます。現時点では、cloudDataMovementUnits 設定は、**2 つの Azure BLOB ストレージ間**、または **Azure BLOB ストレージから Azure Data Lake Store へ**のデータ コピー時に**のみサポート**され、各サイズが 16 MB 以上の複数のファイルをコピーする場合に有効です。

多数の比較的大きなファイルをコピーする場合に、**parallelCopies** プロパティに大きい値を設定すると、1 つのクラウド データ移動単位のリソース制限によりパフォーマンスが向上しない可能性があります。このような場合は、より多くのクラウド データ移動単位を使用することで、高スループットで大量のデータをコピーすることができます。コピー アクティビティで使用するクラウド データ移動単位の数を指定するには、以下に示すように **cloudDataMovementUnits** プロパティの値を設定します。

	"activities":[  
	    {
	        "name": "Sample copy activity",
	        "description": "",
	        "type": "Copy",
	        "inputs": [{ "name": "InputDataset" }],
	        "outputs": [{ "name": "OutputDataset" }],
	        "typeProperties": {
	            "source": {
	                "type": "BlobSource",
	            },
	            "sink": {
	                "type": "AzureDataLakeStoreSink"
	            },
	            "cloudDataMovementUnits": 4
	        }
	    }
	]

cloudDataMovementUnits プロパティで**使用できる値**は、1 (既定値)、2、4、および 8 です。スループットをより高めるためにさらにクラウド データ移動単位が必要な場合は、[Azure サポート](https://azure.microsoft.com/blog/2014/06/04/azure-limits-quotas-increase-requests/)にお問い合わせください。実行時にコピー操作で使用される**クラウド データ移動単位の実際の数**は、サイズの条件を満たしているソースからコピーされるファイルの数に応じて、構成値以下になります。

> [AZURE.NOTE] parallelCopies は cloudDataMovementUnits (指定されている場合) 以上である必要があります。cloudDataMovementUnits が 1 より大きい場合、並列データ移動は、そのコピー アクティビティの実行に対する cloudDataMovementUnits に分散されるため、スループットが向上します。

**cloudDataMovementUnits** を 2、4、および 8 として構成して複数の大きなファイルをコピーする場合、パフォーマンスは、「パフォーマンス リファレンス」に示されている参照数の 2 倍、4 倍、および 7 倍に達することができます。

データ移動のスループットを向上させるために上記 2 つのプロパティをより効果的に活用するために、こちらの[ユース ケース サンプル](#case-study---parallel-copy)を参照してください。
 
コピー操作の合計時間を基に料金が請求されることに**注意してください**。これまで 1 回のコピー ジョブに 1 クラウド単位で 1 時間かかっていたのが、4 クラウド単位で 15 分しかかからなくなった場合、全体的な請求金額はほぼ同じになります。別のシナリオを紹介しましょう。たとえば、4 クラウド単位を使っていて、コピー アクティビティの実行に、1 つ目のクラウド単位が 10 分、2 つ目が 10 分、3 つめ目が 5 分、4 つめ目が 5 分を費やす場合、コピー (データ移動) の合計時間は 10 + 10 + 5 + 5 で 30 分になり、その分の料金が発生します。**parallelCopies** を使用しても課金には影響しません。

## ステージング コピー
ソース データ ストアからシンク データ ストアにデータをコピーする場合、中間のステージング ストアとして Azure Blob Storage を使用できます。このステージング機能は、特に次のような場合に役立ちます。

1.	**ネットワーク接続が遅い場合、ハイブリッド データ移動 (オンプレミス データ ストアとクラウド データ ストアの間での移動) の実行に少し時間がかかる場合がある。** このようなデータ移動のパフォーマンスを向上させるために、データをオンプレミスで圧縮し、ネットワークでクラウド上のステージング データ ストアに移動するときの時間を短縮できます。その後、目的のデータ ストアに読み込む前にステージング ストアでデータを展開できます。
2.	**IT ポリシーが理由でファイアウォールのポートを 80 と 443 以外開きたくない。** たとえば、オンプレミスのデータ ストアから Azure SQL Database シンクまたは SQL Data Warehouse シンクにデータをコピーする場合、Windows ファイアウォールと企業ファイアウォールの両方で、ポート 1433 の送信 TCP 通信を有効にする必要があります。このようなシナリオでは、まず Data Management Gateway を利用してデータをステージング Azure Blob Storage にコピーします。これは HTTP(S) (ポート 443) 経由で行われます。その後、ステージング Blob Strage から SQL Database または SQL Data Warehouse にデータを読み込みます。このフローではポート 1433 を有効にする必要はありません。
3.	**PolyBase を使ってさまざまなデータ ストアから Azure SQL Data Warehouse にデータを取り込む。** Azure SQL Data Warehouse には、大量のデータを SQL Data Warehouse に読み込むための高スループットなメカニズムとして PolyBase が用意されています。しかし、これを使用するにはソース データが Azure Blob Storage 内に存在する必要があります。また、その他にもいくつかの条件を満たす必要があります。Azure Blob Storage ではないデータ ストアからデータを読み込む場合、中間ステージング Azure Blob Storage を介したデータのコピーを有効にすることができます。この場合、Azure Data Factory は PolyBase の要件を満たすようにデータに対して必要な変換を実行し、PolyBase を利用して SQL Data Warehouse にデータを読み込みます。詳細とサンプルについては、「[PolyBase を使用して Azure SQL Data Warehouse にデータを読み込む](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse)」を参照してください。

### ステージング コピーのしくみ
ステージング機能を有効にすると、データはまずソース データ ストアから (独自の) ステージング データ ストアにコピーされ、そのうえでステージング データ ストアからシンク データ ストアにコピーされます。Azure Data Factory はこの 2 段階のフローを自動的に管理します。また、データ移動の完了後、ステージング ストレージから一時データをクリーンアップします。

ソース データ ストアとシンク データ ストアの両方がクラウド内にあり、Data Management Gateway を利用しない**クラウド コピーのシナリオ**では、コピー操作は **Azure Data Factory サービス**によって実行されます。

![Staged copy - cloud scenario](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

一方、**ハイブリッド コピーのシナリオ**では、ソースはオンプレミスにあり、シンクはクラウドにあります。ソース データ ストアからステージング データ ストアへのデータ移動は **Data Management Gateway** によって実行され、ステージング データ ストアからシンク データ ストアへのデータ移動は **Azure Data Factory サービス**によって実行されます。

![Staged copy - hybrid scenario](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

ステージング ストアを使用したデータ移動を有効にすると、ソース データ ストアから中間/ステージング データ ストアにデータを移動する前にデータを圧縮し、中間/ステージング データ ストアからシンク データ ストアにデータを移動する前にそのデータを展開するかどうかを指定できます。

クラウド データ ストアからオンプレミス データ ストアへのデータのコピー、またはステージング ストアを利用した 2 つのオンプレミス データ ストア間でのデータのコピーは、現在サポートされていません。これらについては近日中に対応する予定です。

### 構成
コピー アクティビティの **enableStaging** 設定を構成して、目的のデータ ストアに読み込む前にデータを Azure Blob Storage にステージングするかどうかを指定できます。enableStaging を true に設定すると、次の表に記載されている追加のプロパティを指定する必要があります。また、ステージング用の Azure Storage または Azure Storage SAS のリンクされたサービスをまだお持ちでない場合は、作成する必要があります。

プロパティ | 説明 | 既定値 | 必須
--------- | ----------- | ------------ | --------
enableStaging | 中間ステージング ストアを経由してデータをコピーするかどうかを指定します。 | False | いいえ
linkedServiceName | [AzureStoage](data-factory-azure-blob-connector.md#azure-storage-linked-service) または [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) のリンクされたサービスの名前を指定します。これは、中間ステージング ストアとして使用する Azure Storage です。<br/><br/> SAS (Shared Access Signature) を使用した Azure Storage は PolyBase による Azure SQL Data Warehouse へのデータ読み込みには使用できないことに注意してください。それ以外のシナリオでは使用できます。 | 該当なし | はい (enableStaging が true に設定されている場合)。 
path | ステージング データが含まれる Azure Blob Storage 内のパスを指定します。パスを指定しない場合、一時データを格納するコンテナーがサービスによって作成されます。<br/><br/> SAS と共に Azure Storage を使用していない場合、または一時データを格納する場所に関して厳しい要件がない場合は、パスを指定する必要はありません。 | 該当なし | なし
enableCompression | ネットワークで転送されるデータの量を減らすために、ソース データ ストアからシンク データ ストアに移動する際にデータを圧縮するかどうかを指定します。 | False | なし

次に、上記のプロパティを使用したコピー アクティビティのサンプル定義を示します。

	"activities":[  
	{
		"name": "Sample copy activity",
		"type": "Copy",
		"inputs": [{ "name": "OnpremisesSQLServerInput" }],
		"outputs": [{ "name": "AzureSQLDBOutput" }],
		"typeProperties": {
			"source": {
				"type": "SqlSource",
			},
			"sink": {
				"type": "SqlSink"
			},
	    	"enableStaging": true,
			"stagingSettings": {
				"linkedServiceName": "MyStagingBlob",
				"path": "stagingcontainer/path",
				"enableCompression": true
			}
		}
	}
	]


### 課金への影響
それぞれ 2 段階のコピー時間とコピーの種類に基づいて課金が行われることに注意してください。つまり、次のようになります。

- クラウド コピー (クラウド データ ストアから別のクラウド データ ストアへのデータのコピー (たとえば Azure Data Lake から Azure SQL Data Warehouse)) でステージングを使用する場合、料金は、"ステップ 1 とステップ 2 のコピー時間の合計" x "クラウド コピーの単価" で計算されます。
- ハイブリッド コピー (オンプレミス データ ストアからクラウド データ ストアへのデータのコピー (たとえばオンプレミスの SQL Server データベースから Azure SQL Data Warehouse)) でステージングを使用する場合、料金は、"ハイブリッド コピーの時間" x "ハイブリッド コピーの単価" + "クラウド コピーの時間" x "クラウド コピーの単価" で計算されます。


## ソースに関する考慮事項
### 全般
基になるデータ ストアが、コピー アクティビティ (ただし、これに限定されない) に対して実行されるその他のワークロードに圧倒されないことを確認します。

Microsoft データ ストアの場合は、データ ストアに限定した[監視とチューニングに関するトピック](#appendix-data-store-performance-tuning-reference)を参照してください。データ ストアのパフォーマンス特性に関する説明と、応答時間を短縮しスループットを最大限に高める方法が記載されています。

**Azure Blob Storage** から **Azure SQL Data Warehouse** にデータをコピーする場合は、パフォーマンスを向上させるために **PolyBase** を有効にすることを検討してください。詳細については、「[PolyBase を使用して Azure SQL Data Warehouse にデータを読み込む](data-factory-azure-sql-data-warehouse-connector.md###use-polybase-to-load-data-into-azure-sql-data-warehouse)」を参照してください。


### ファイル ベースのデータ ストア
*(Azure BLOB、Azure Data Lake、オンプレミスのファイル システムなど)*

- **ファイル サイズとファイル数の平均**: コピー アクティビティはデータをファイルごとに転送します。移動するデータ量は同じで、データを少数の大きなファイルで構成するのでなく多数の小さなファイルで構成した場合、ファイルごとにブートス トラップ フェーズが存在するため、全体的なスループットは低下します。したがって、可能であれば、小さなファイルをまとめて大きなファイルとすることで、スループットを高めてください。
- **ファイルの形式と圧縮**: パフォーマンスを向上させるその他の方法については、「[シリアル化/逆シリアル化に関する考慮事項](#considerations-on-serializationdeserialization)」と「[圧縮に関する考慮事項](#considerations-on-compression)」を参照してください。
- さらに、**Data Management Gateway** を使用する必要がある**オンプレミスのファイル システム**のシナリオについては、「[ゲートウェイに関する考慮事項](#considerations-on-data-management-gateway)」を参照してください。

### リレーショナル データ ストア
*(Azure SQL Database、Azure SQL Data Warehouse、SQL Server データベース、Oracle データベース、MySQL データベース、DB2 データベース、Teradata データベース、Sybase データベース、PostgreSQL データベースなど)*

- **データ パターン**: テーブル スキーマは、コピーのスループットに影響を与えます。同じ量のデータをコピーする場合、行のサイズが小さいよりも行のサイズが大きい方がパフォーマンスは高くなります。これは、データベースは行数が少なくバッチが少なくなれば、それだけ効率的にデータを取得できるからです。
- **クエリまたはストアド プロシージャ**: データをより効率的にフェッチできるように、コピー アクティビティ ソースで指定するクエリまたはストアド プロシージャのロジックを最適化します。
- さらに、SQL Server や Oracle など、**Data Management Gateway** を使用する必要ある**オンプレミスのリレーショナル データベース**の場合は、「[ゲートウェイに関する考慮事項](#considerations-on-data-management-gateway)」を参照してください。

## シンクに関する考慮事項

### 全般
基になるデータ ストアが、コピー アクティビティ (ただし、これに限定されない) に対して実行されるその他のワークロードに圧倒されないことを確認します。

Microsoft データ ストアの場合は、データ ストアに限定した[監視とチューニングに関するトピック](#appendix-data-store-performance-tuning-reference)を参照してください。データ ストアのパフォーマンス特性に関する説明と、応答時間を短縮しスループットを最大限に高める方法が記載されています。

**Azure Blob Storage** から **Azure SQL Data Warehouse** にデータをコピーする場合は、パフォーマンスを向上させるために **PolyBase** を有効にすることを検討してください。詳細については、「[PolyBase を使用して Azure SQL Data Warehouse にデータを読み込む](data-factory-azure-sql-data-warehouse-connector.md###use-polybase-to-load-data-into-azure-sql-data-warehouse)」を参照してください。


### ファイル ベースのデータ ストア
*(Azure BLOB、Azure Data Lake、オンプレミスのファイル システムなど)*

- **コピー動作**: 別のファイル ベースのデータ ストアからデータをコピーする場合、コピー アクティビティは "copyBehavior" プロパティを介して、階層の維持、階層の平坦化、ファイルのマージという 3 種類の動作を提供します。階層の維持または階層の平坦化では、パフォーマンス オーバーヘッドはほとんどありませんが、ファイルのマージでは余分にパフォーマンス オーバーヘッドが発生します。
- **ファイルの形式と圧縮**: パフォーマンスを向上させるその他の方法については、「[シリアル化/逆シリアル化に関する考慮事項](#considerations-on-serializationdeserialization)」と「[圧縮に関する考慮事項](#considerations-on-compression)」を参照してください。
- **Azure BLOB** では、現在のところ、最適化されたデータ転送およびスループットに対してブロック BLOB をサポートしているだけです。
- さらに、**Data Management Gateway** を使用する必要がある**オンプレミスのファイル システム**のシナリオについては、「[ゲートウェイに関する考慮事項](#considerations-on-data-management-gateway)」を参照してください。

### リレーショナル データ ストア
*(Azure SQL Database、Azure SQL Data Warehouse、SQL Server データベースなど)*

- **コピー動作**: コピー アクティビティは、"sqlSink"用に構成されたプロパティに応じて、以下に示すさまざまな方法でデータを宛先データベースに書き込みます。
	- 既定では、Data Movement Service は、一括コピー API を使用して、データを追加モードで挿入します。この場合、最高のパフォーマンスが得られます。
	- シンク内でストアド プロシージャを構成した場合、データベースでは、一括読み込みではなく、行ごとにデータが適用されます。このため、パフォーマンスは大幅に低下します。データのサイズが大きい場合、適用できるときは、代わりに "sqlWriterCleanupScript" プロパティ (下記参照) の使用を検討してください。
	- "sqlWriterCleanupScript" プロパティを構成すると、サービスはコピー アクティビティの実行のたびに、まずスクリプトをトリガーし、次に一括コピー API を使用してデータを挿入します。たとえば、テーブル全体を最新のデータで上書きするには、ソースから新しいデータを一括で読み込む前に、まず、すべてのレコードを削除するスクリプトを指定することができます。
- **データのパターンとバッチ サイズ**:
	- テーブル スキーマは、コピーのスループットに影響を及ぼします。同じ量のデータをコピーする場合、行のサイズが小さいよりも行のサイズが大きい方がパフォーマンスは高くなります。これは、データベースが、バッチがより少ないデータを効率的にコミットできることに理由があります。
	- コピー アクティビティは、データを一連のバッチで挿入します。この場合、バッチに含まれる行数は "writeBatchSize" プロパティを使用して設定できます。データの行のサイズが小さい場合は、"writeBatchSize" プロパティをより大きな値に設定することで、バッチ オーバーヘッドの縮小の利点を生かし、スループットを向上させることができます。データの行のサイズが大きい場合に、writeBatchSize の値を大きくするときは注意してください。値が大きいと、データベースのオーバー ロードによってコピー障害が発生するおそれがあります。
- さらに、SQL Server や Oracle など、**Data Management Gateway** を使用する必要ある**オンプレミスのリレーショナル データベース**の場合は、「[ゲートウェイに関する考慮事項](#considerations-on-data-management-gateway)」を参照してください。


### NoSQL ストア
*(Azure テーブル、Azure DocumentDB など)*

- **Azure テーブル**の場合:
	- **パーティション**: インターリーブされたパーティションへのデータ書き込みを行うと、パフォーマンスが大幅に低下します。データが複数のパーティションに順次、効率的に挿入されるようにパーティション キーでソース データを並び替えることも、データを単一のパーティションに書き込むようにロジックを調整することもできます。
- **Azure DocumentDB** の場合:
	- **バッチ サイズ**: "writeBatchSize" プロパティは、ドキュメントを作成する DocumentDB サービスへの並列要求の数を示します。"writeBatchSize" を増やすとパフォーマンスがよくなります。DocumentDB に送信される並列要求の数が増えるためです。ただし、DocumentDB に書き込む際はスロットルに注意してください (エラー メッセージ "要求処理率が大きい")。スロットルは、ドキュメントのサイズ、ドキュメント内の語句の数、ターゲット コレクションの索引作成ポリシーなど、複数の要因によって発生する可能性があります。コピーのスループットを高めるには、より適切なコレクション (S3 など) の使用を検討してください。

## シリアル化/逆シリアル化に関する考慮事項
入力データセットまたは出力データセットがファイルであると、シリアル化および逆シリアル化が実行されることがあります。現在、コピー アクティビティでは Avro および Text (CSV や TSV など) データ形式をサポートしています。

**コピー動作:**

- ファイル ベースのデータ ストア間でファイルをコピーする場合:
	- 入力データセットと出力データセットが両方とも、同じファイル形式を持っているか、またはファイル形式が設定されていない場合、Data Movement Service は、シリアル化/逆シリアル化を実行することなく、バイナリ コピーを実行します。そのため、ソースとシンクとのファイル形式設定が異なるシナリオの場合と比較して、良好なスループットが示されます。
	- 入力データセットと出力データセットは両方とも Text 形式で、エンコードの種類のみが異なる場合、Data Movement Service はシリアル化/逆シリアル化を実行することなく、エンコード変換のみを行います。結果、バイナリ コピーの場合と比較していくらかのパフォーマンス オーバーヘッドが発生します。
	- 入力データセットと出力データセットのファイル形式が異なるか、または構成が異なる場合 (区切り記号のように)、Data Movement Service は、ソース データをストリームに逆シリアル化し、変換し、望ましい出力形式にシリアル化します。この場合、前のシナリオと比較してはるかに大きなパフォーマンス オーバーヘッドが発生します。
- ファイルとファイル ベース以外のデータ ストアとの間でコピーを行う場合 (たとえば、ファイル ベースのストアとリレーショナル ストアとの間)、シリアル化または逆シリアル化の手順が必要であり、その結果、大幅なパフォーマンス オーバーヘッドが発生します。

**ファイルの形式:** ファイル形式の選択は、コピーのパフォーマンスに影響を与えます。たとえば、Avro は、データと一緒にメタデータを格納するコンパクトなバイナリ形式であり、Hadoop エコシステムでの処理とクエリで幅広くサポートされています。ただし、Avro の場合は、シリアル化/逆シリアル化によってコピーのスループットが低下するので、Text 形式と比較してコストがかかります。処理フローで使用するファイル形式を選択する場合は、総合的に判断する必要があります。具体的には、ソース データ ストアにデータを格納する際の形式または外部システムからデータを抽出する際の形式、ストレージや分析処理やクエリに最適な形式、データ マートにエクスポートしてレポート ツールおよび視覚化ツールを使用するためのデータの形式などを考慮する必要があります。時々、読み取りおよび書き込みパフォーマンスの点では準最適なファイル形式であっても、分析プロセス全体を考慮すると最適であることが判明する場合があります。

## 圧縮に関する考慮事項
入力データアセットまたは出力データセットがファイルである場合は、宛先へのデータの書き込み時に圧縮または圧縮解除を実行するようにコピー アクティビティを構成することができます。圧縮を有効にして、I/O と CPU のトレードオフを考慮する: データを圧縮すると、コンピューティング リソースのコストは増えますが、その反面、ネットワーク I/O とストレージのコストは減少します。このため、データによっては、圧縮によってコピーのスループットが全体的に押し上げられる可能性があります。

**コーデック:** サポートされている圧縮の種類は、GZIP、BZIP2、および Deflate です。Azure HDInsight では、この 3 種類をすべて利用して処理を行うことができます。各圧縮コーデックには、固有の特徴があります。たとえば、BZIP2 はコピーのスループットが最も低いのですが、分割して処理することができれば、最高の Hive クエリ パフォーマンスを発揮します。GZIP は最もバランスの取れたオプションであり最もよく使用されています。エンド ツー エンドのシナリオに最適なコーデックを選択する必要があります。

**レベル:** 各圧縮コーデックでは、最速圧縮と最適圧縮という 2 つのオプションの中からいずれかを選択できます。最速圧縮オプションでは、可能な限り短時間でデータの圧縮を完了しますが、生成ファイルが最適に圧縮されない場合があります。最適圧縮オプションではデータ圧縮により多くの時間を費やしますが、データ量を最小限まで圧縮します。両方のオプションを実際にテストして、どちらが全体的なパフォーマンスで優れているかを確認することができます。

**重要な考慮事項:** オンプレミスのストアとクラウドとの間でサイズの大きなデータをコピーする場合で、企業ネットワークと Azure の帯域幅が制限要因となることが多く、入力データセットと出力データセットの両方を非圧縮形式にしたい場合は、**中間的な Azure BLOB** と圧縮を組み合わせて使用することを検討できます。具体的には、1 つのコピー アクティビティを 2 つのコピー アクティビティに分割することができます。1 番目のコピー アクティビティで、ソースから中間またはステージング BLOB に圧縮形式でコピーし、2 番目のコピー アクティビティで、圧縮されたデータをステージング環境からコピーし、シンクへの書き込み中に圧縮を解除します。

## 列マッピングに関する考慮事項
コピー アクティビティの "columnMappings" プロパティを使用すれば、入力列のすべてまたはサブセットを出力列にマップすることができます。Data Movement Service は、ソースからデータを読み取った後、そのデータに対して列マッピングを実行してから、データをシンクに書き込む必要があります。この追加の処理により、コピーのスループットが低下します。

ソース データ ストアがクエリ可能な場合 (たとえば、Azure SQL/SQL Server のようなリレーショナル ストアまたは Azure Table/Azure DocumentDB のような NoSQL ストアの場合)、列マッピングを使用するのでなく、列フィルタリング/順序変更ロジックをクエリ プロパティにプッシュダウンすることを検討できます。そうした場合、結果として、ソース データ ストアからのデータ読み取り中にプロジェクションが実行され、効率が向上します。

## Data Management Gateway に関する考慮事項
ゲートウェイのセットアップにおける推奨事項については、「[Data Management Gateway を使用する上で考慮すること](data-factory-move-data-between-onprem-and-cloud.md#Considerations-for-using-Data-Management-Gateway)」を参照してください。

**ゲートウェイ コンピューター環境:** Data Management Gateway をホストする専用のマシンを使用することをお勧めします。ゲートウェイ コンピューター上でのコピー操作中に PerfMon などのツールを使用して、CPU、メモリ、および帯域幅の使用率を確認します。CPU、メモリ、またはネットワーク帯域幅がボトルネックになる場合は、より強力なコンピューターに切り替えます。

**コピー アクティビティの複数の実行の同時処理:** Data Management Gateway の 1 つのインスタンスで、コピー アクティビティの複数の実行を同時に処理することができます。すなわち、ゲートウェイは複数のコピー ジョブを同時に実行することができます (同時実行ジョブ数はゲートウェイ コンピューターのハードウェア構成に基づいて算出されます)。追加のコピー ジョブは、ゲートウェイによって取得されるか、またはジョブがタイムアウトになるかの、どちらかが先に発生するまで、キューに置かれます。ゲートウェイ上でリソースの競合を避けるには、アクティビティのスケジュールをステージングして 1 度にキューに入れるジョブの数量を減らすことも、複数のゲートウェイに負荷を分担することを検討することもできます。


## その他の考慮事項
コピーするデータのサイズが非常に大きい場合は、Azure Data Factory のスライス メカニズムを使用してデータをさらに分割し、コピー アクティビティのスケジュールを頻繁に設定して各コピー アクティビティ実行のデータ サイズを小さくするように、ビジネス ロジックを調整することができます。

同じデータ ストアに到達またはアクセスするデータセットの数とコピー アクティビティの数に常に注意してください。同時コピー ジョブの数が多いと、データ ストアのスロットルが発生し、パフォーマンスの低下、コピー ジョブの内部的な再試行、場合によっては実行の失敗につながるおそれがあります。

## ケース スタディ: オンプレミスの SQL Server から Azure BLOB へのコピー
**シナリオ:** オンプレミスの SQL Server から Azure BLOB に CSV 形式でデータをコピーするパイプラインが構築されています。コピーの高速化を図るために、CSV ファイルが BZIP2 形式で圧縮されるように指定されています。

**テストと分析:** 観察結果によれば、コピー アクティビティのスループットは 2 MB/秒で、パフォーマンスのベンチマークをかなり下回っています。

**パフォーマンスの分析とチューニング:** パフォーマンスの問題を解決するために、まず、データの処理および移動の方法を見ていきます。

1.	**データの読み取り:** ゲートウェイは、SQL Server への接続を開く、クエリを送信します。SQL Server はイントラネット経由でゲートウェイにデータ ストリームを送信することで応答します。
2.	ゲートウェイはデータ ストリームを CSV 形式に**シリアル化**し、データを BZIP2 ストリームに**圧縮**します。
3.	**データの書き込み:** ゲートウェイは BZIP2 ストリームをインターネット経由で Azure BLOB にアップロードします。

ご覧のように、データは SQL Server、LAN、ゲートウェイ、WAN、Azure BLOB の順にストリーミングで処理および移動されており、**全体的なパフォーマンスは、パイプライン全体にわたって最低のスループットで制御されています**。

![データ フロー](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

次に示す要因の 1 つまたは複数がパフォーマンスのボトルネックである可能性があります。

1.	**ソース:** 負荷が大きいため、SQL Server 自体のスループットが低くなっています。
2.	**Data Management Gateway:**
	1.	**LAN:** ゲートウェイが SQL Server から遠く離れた位置にあり、低帯域幅の接続を使用しています。
	2.	次の処理を実行すると、**ゲートウェイ コンピューター上の負荷**がその上限に達します。
		1.	**シリアル化:** CSV へのデータ ストリームのシリアル化のスループットが低い
		2.	**圧縮:** 低速の圧縮コーデックが選択されている (たとえば、BZIP2 は Core i7 の場合に 2.8 MB/秒)。
	3.	**WAN:** 企業ネットワークと Azure との間が低帯域幅 (たとえば、T1 = 1544 kbps、T2 = 6312 kbps)。
4.	**シンク:** Azure BLOB のスループットが低くなっています (ただし、SLA で最低 60 MB/秒が保証さえている場合、可能性は極めて低い)。

この場合、BZIP2 データ圧縮がパイプライン全体を遅くしている可能性があります。GZIP 圧縮コーデックに切り替えると、このボトルネックが緩和される場合があります。


## ケース スタディ - 並列コピー  

**シナリオ l:** オンプレミスのファイル システムから Azure Blob Storage に 1 MB のファイルを 1,000 個コピーする。

**分析とパフォーマンスのチューニング**: クアッド コア マシン上に Data Management Gateway をインストールしており、Data Factory が既定で 16 の並列コピーを使用して、ファイル システムから Azure BLOB に同時にファイルを移動するとします。この場合、適切なスループットが得られます。必要に応じて、並列コピーの数を明示的に指定することもできます。多数の小さなファイルをコピーする場合、並列コピーでは関連するリソースがより効果的に活用されるため、スループットが大幅に向上します。

![シナリオ 1](./media/data-factory-copy-activity-performance/scenario-1.png)

**シナリオ II:** Azure Blob Storage から Azure Data Lake Store Analysis にそれぞれ 500 MB の BLOB を 20 個コピーして、パフォーマンスを調整する。

**分析とパフォーマンスのチューニング:** このシナリオの場合、既定では、Data Factory は 1 つのコピー (parallelCopies: 1) と 1 つのクラウド データ移動単位を使用して、Azure BLOB から Azure Data Lake にデータをコピーします。監視対象のスループットは、上記の「[パフォーマンス リファレンス](#performance-reference)」に示されているものに近くなります。

![シナリオ 2](./media/data-factory-copy-activity-performance/scenario-2.png)

個々 のファイル サイズが数十 MB を超え、合計量が多い場合に、parallelCopies を増やしても、1 つのクラウド データ移動単位のリソース制限により、コピーのパフォーマンスは向上しません。代わりに、さらにクラウド データ移動単位を指定し、データ移動を実行するリソースをさらに取得する必要があります。Data Factory で自動的に並行処理が行われるため、parallelCopies プロパティの値は指定しないでください。この場合、cloudDataMovementUnits を 4 に指定すると、スループットが約 4 倍になります。

![シナリオ 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## データ ストアのパフォーマンスのチューニングに関するリファレンス
ここでは、サポートされているいくつかのデータ ストアについて、パフォーマンスの監視とチューニングに関するリファレンス情報をいくつか示します。

- Azure Storage (Azure BLOB、Azure Table など): [Azure Storage のスケーラビリティおよびパフォーマンスのターゲット](../storage/storage-scalability-targets.md) と [Microsoft Azure Storage のパフォーマンスとスケーラビリティに対するチェック リスト](../storage//storage-performance-checklist.md)
- Azure SQL Database: [パフォーマンスを監視](../sql-database/sql-database-service-tiers.md#monitoring-performance)し、データベース トランザクション ユニット (DTU) の割合を確認できます。
- Azure SQL Data Warehouse: その機能は、Data Warehouse ユニット (DWU) で測定されます。「[SQL Data Warehouse を使用した弾力的なパフォーマンスとスケール](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)」を参照してください。
- Azure DocumentDB: [Performance level in DocumentDB (DocumentDB のパフォーマンス レベル)](../documentdb/documentdb-performance-levels.md)
- オンプレミスの SQL Server: [パフォーマンスの監視とチューニング](https://msdn.microsoft.com/library/ms189081.aspx)
- オンプレミスのファイル サーバー: [Performance Tuning for File Servers (ファイル サーバーのパフォーマンス チューニング)](https://msdn.microsoft.com/library/dn567661.aspx)

<!---HONumber=AcomDC_0706_2016-->