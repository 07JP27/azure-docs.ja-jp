---
title: Azure Machine Learning データ準備の使用方法に関する詳細ガイド | Microsoft Docs
description: このドキュメントでは、Azure Machine Learning データ準備に関するデータの問題を解決する方法の概要と詳細について説明します
services: machine-learning
author: euangMS
ms.author: euang
manager: lanceo
ms.reviewer: jmartens, jasonwhowell, mldocs
ms.service: machine-learning
ms.component: core
ms.workload: data-services
ms.custom: ''
ms.devlang: ''
ms.topic: article
ms.date: 02/01/2018
ROBOTS: NOINDEX
ms.openlocfilehash: 7536e67d0ae4973008c8acc91a99a7d0d286f9b8
ms.sourcegitcommit: 32d218f5bd74f1cd106f4248115985df631d0a8c
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 09/24/2018
ms.locfileid: "46988735"
---
# <a name="data-preparations-user-guide"></a>データ準備ユーザー ガイド 

[!INCLUDE [workbench-deprecated](../../../includes/aml-deprecating-preview-2017.md)] 


Azure Machine Learning データ準備には豊富な機能が搭載されています。 この記事では、その操作方法について深く掘り下げます。

### <a name="step-execution-history-and-caching"></a>ステップ実行、履歴、およびキャッシュ 
データ準備のステップ履歴には、パフォーマンスのために一連のキャッシュが保持されます。 ステップを選択してキャッシュがヒットした場合、そのステップは再実行されません。 ステップ履歴の最後に書き込みブロックがあり、そのステップを前後に入れ替えても変更を加えない場合、2 回目以降は書き込みはトリガーされません。 次を行うと、新しい書き込みが発生し、前の書き込みを上書きします。

- 書き込みブロックに変更を加える。
- 新しい変換ブロックを追加し、それを書き込みブロックより上に移動させることで、キャッシュの無効化を発生させる。
- 書き込みブロックより上のブロックのプロパティを変更することで、キャッシュの無効化を発生させる。
- サンプルの更新を選択する (これによりすべてのキャッシュを無効にする)。

### <a name="error-values"></a>エラー値

入力値を適切に処理できないことが原因で、その値のデータ変換が失敗することがあります。 たとえば、強制型変換操作のために、指定されたターゲットの型に入力文字列値をキャストできない場合、強制型変換が失敗します。 強制型変換操作が、文字列型の列を数値またはブール値の型に変換している、または存在しない列の複製を試行している可能性があります。 (このエラーは、"*列 X の削除*" 操作を "*列 X の複製*" 操作の前に移動した結果、発生します。)

このような場合は、データ準備によりエラー値が出力として生成されます。 エラー値は、前の操作が指定された値のために失敗したことを示します。 内部的には、これらは第 1 位の値の型として扱われますが、それが存在していても列の根本的な型は変更されず、列全体がエラー値から構成されている場合でも変更されません。

エラー値の識別は簡単です。 赤色で強調表示され、"Error" と示されます。 エラーの理由を特定するには、エラー値の上にマウスを移動すると、エラーの説明テキストが表示されます。

エラー値は伝播されます。 エラー値が発生すると、ほとんどの場合、操作の大部分でエラーとして伝播されます。 エラーは次の 3 つの方法で置換または削除できます。

* Replace
    -  列を右クリックして、**[Replace Error Values]\(エラー値の置換\)** を選択します。 続いて、列で見つかったエラー値ごとに置換値を選択できます。

* Remove
    - データ準備には、エラー値を保持または削除するための対話型のフィルターが用意されています。
    - 列を右クリックして、**[Filter Column]\(列のフィルター\)** を選択します。 エラー値を保持または削除するには、*"is error"* または *"is not error"* の条件を含む条件文を作成します。

* Python の式を使用して、条件付きでエラー値を処理します。 詳しくは、[Python の拡張機能に関するセクション](data-prep-python-extensibility-overview.md)をご覧ください。

### <a name="sampling"></a>サンプリング
データ ソース ファイルは、ローカル ファイル システムまたはリモートの場所にある 1 つまたは複数のソースから生データを取得します。 サンプル ブロックを使用すると、サンプルを生成することによって、データのサブセットを操作するかどうかを指定できます。 大規模なデータセットではなくデータのサンプルを操作すると、多くの場合、後の手順で操作を実行するときにパフォーマンスが向上します。

データ ソース ファイルごとに、複数のサンプルを生成および保存できます。 ただし、アクティブなサンプルとして設定できるサンプルは 1 つだけです。 データ ソース ウィザードで、またはサンプル ブロックを編集することにより、サンプルを作成、編集、または削除できます。 データ ソースを参照するすべてのデータ準備ファイルは本質的に、データ ソースファイルで指定されたサンプルを使用します。

さまざまな構成可能なパラメーターのそれぞれで使用できるサンプリング方法は多数あります。

#### <a name="top"></a>Top (上位)
この方法は、ローカル ファイルまたはリモート ファイルのどちらかに適用できます。 最初の N 行 (カウントで指定) をデータ ソースに取得します。

#### <a name="random-n"></a>ランダム N 
この方法は、ローカル ファイルにのみ適用できます。 ランダムな N 行 (カウントで指定) をデータ ソースに取得します。 特定のシードを指定して、カウントも同じであれば同じサンプルが生成されるように設定できます。

#### <a name="random-"></a>ランダム % 
この方法は、ローカル ファイルまたはリモート ファイルのどちらかに適用できます。 どちらの場合でも、ランダム N の方法と同様に、確率とシードを指定する必要があります。

リモート ファイルのサンプルについては、追加のパラメーターを指定する必要があります。

- サンプル ジェネレーター 
  - サンプルの生成に使用する Spark クラスターまたはリモート Docker コンピューティング ターゲットを選択します。 プロジェクト用のコンピューティング ターゲットをこの一覧に表示する前に、作成しておく必要があります。 「[Azure Machine Learning で GPU を使用する方法](how-to-use-gpu.md)」の「新しい計算ターゲットを作成する」の手順に従って、コンピューティング ターゲットを作成します。
- サンプル記憶域 
  - リモートのサンプルを格納する中間記憶域の場所を指定します。 このパスは、入力ファイルの場所とは別のディレクトリにする必要があります。

#### <a name="full-file"></a>ファイル全体 
この方法は、ローカル ファイルにのみ適用可能で、ファイル全体をデータ ソースに取得します。 ファイルが大きすぎる場合、このオプションによりアプリの今後の処理速度が低下することがあります。 このため、別のサンプリング方法を使用したほうがよいこともあります。


### <a name="fork-merge-and-append"></a>フォーク、マージ、および追加

フィルターをデータセットに適用すると、この操作によってデータは 2 つの結果セットに分割されます。一方のセットは、フィルターを通ったレコードを表し、もう一方のセットは通らなかったレコードを表します。 どちらの場合も、ユーザーは表示する結果セットを選択できます。 他方のデータセットは破棄することも、新しいデータ フローに配置することもできます。 後者のオプションをフォークと呼びます。

フォークを実行するには: 
1. 列を選択し、右クリックして、**[フィルター]** 列を選択します。

2. フィルターを通った結果セットを表示するには、**[I Want To]\(目的の操作\)** の下で、**[Keep Rows]\(行の保持\)** を選択します。

3. 通らなかったセットを表示するには、**[Remove Rows]\(行の削除\)** を選択します。

4. **[Conditions]\(条件\)** の後で、**[Create Dataflow Containing the Filtered Out Rows]\(フィルターで除去された行を含むデータ フローの作成\)** を選択して、表示されない結果セットを新しいデータ フローにフォークします。


この手法は多くの場合、追加の準備を必要とするデータのセットを分割するために使用します。 フォークしたデータ セットを準備した後、そのデータを元のデータ フロー内の結果セットとマージすることが一般的です。 マージ (フォーク操作の逆) を実行するには、次のいずれかのアクションを使用します。

- **行の追加**。 2 つ以上のデータ フローを垂直方向 (行方向) にマージします。 
- **列の追加**。 2 つ以上のデータ フローを水平方向 (列方向) にマージします。


>[!NOTE]
>列の追加は、列の競合が発生すると失敗します。


マージ操作の後、1 つまたは複数のデータ フローがソース データ フローで参照されます。 データ準備は、アプリの右下、ステップの一覧の下に通知を表示します。


参照先のデータ フローを操作すると、参照先のデータ フローから使用されるサンプルを更新するように親データ フローが要求されます。 その場合、確認のダイアログ ボックスが、右下のデータ フロー参照通知に置き換わります。 そのダイアログ ボックスには、すべての依存関係データ フローへの変更を同期するにはデータ フローを更新する必要がある、と表示されます。

### <a name="list-of-appendices"></a>付録の一覧 
* [サポートされるデータ ソース](data-prep-appendix2-supported-data-sources.md)  
* [サポートされる変換](data-prep-appendix3-supported-transforms.md)  
* [サポートされるインスペクター](data-prep-appendix4-supported-inspectors.md)  
* [サポートされる変換先](data-prep-appendix5-supported-destinations.md)  
* [Python のフィルター式のサンプル](data-prep-appendix6-sample-filter-expressions-python.md)  
* [Python の変換データ フロー式のサンプル](data-prep-appendix7-sample-transform-data-flow-python.md)  
* [Python のデータ ソースのサンプル](data-prep-appendix8-sample-source-connections-python.md)  
* [Python の変換先接続のサンプル](data-prep-appendix9-sample-destination-connections-python.md)  
* [Python の列変換のサンプル](data-prep-appendix10-sample-custom-column-transforms-python.md)  
